"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
import dateutil.parser
from ..shared import certificatereference as shared_certificatereference
from ..shared import computenodeerror as shared_computenodeerror
from ..shared import starttask as shared_starttask
from ..shared import starttaskinformation as shared_starttaskinformation
from ..shared import taskinformation as shared_taskinformation
from dataclasses_json import Undefined, dataclass_json
from datetime import datetime
from enum import Enum
from marshmallow import fields
from sdk import utils
from typing import Optional

class ComputeNodeSchedulingStateEnum(str, Enum):
    r"""Whether the compute node should be available for task scheduling."""
    ENABLED = 'enabled'
    DISABLED = 'disabled'

class ComputeNodeStateEnum(str, Enum):
    r"""The current state of the compute node."""
    IDLE = 'idle'
    REBOOTING = 'rebooting'
    REIMAGING = 'reimaging'
    RUNNING = 'running'
    UNUSABLE = 'unusable'
    CREATING = 'creating'
    STARTING = 'starting'
    WAITINGFORSTARTTASK = 'waitingforstarttask'
    STARTTASKFAILED = 'starttaskfailed'
    UNKNOWN = 'unknown'
    LEAVINGPOOL = 'leavingpool'
    OFFLINE = 'offline'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class ComputeNode:
    r"""A compute node in the Batch service."""
    
    affinity_id: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('affinityId'), 'exclude': lambda f: f is None }})
    r"""An identifier which can be passed in the Add Task API to request that the task be scheduled close to this compute node."""  
    allocation_time: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('allocationTime'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})
    r"""The time at which this compute node was allocated to the pool."""  
    certificate_references: Optional[list[shared_certificatereference.CertificateReference]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('certificateReferences'), 'exclude': lambda f: f is None }})
    r"""The list of certificates installed on the compute node."""  
    errors: Optional[list[shared_computenodeerror.ComputeNodeError]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('errors'), 'exclude': lambda f: f is None }})
    r"""The list of errors that are currently being encountered by the compute node."""  
    id: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('id'), 'exclude': lambda f: f is None }})
    r"""The id of the compute node."""  
    ip_address: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ipAddress'), 'exclude': lambda f: f is None }})
    r"""The IP address that other compute nodes can use to communicate with this compute node."""  
    last_boot_time: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('lastBootTime'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})
    r"""The time at which the compute node was started."""  
    recent_tasks: Optional[list[shared_taskinformation.TaskInformation]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('recentTasks'), 'exclude': lambda f: f is None }})
    r"""The list of tasks that are currently running on the compute node."""  
    running_tasks_count: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('runningTasksCount'), 'exclude': lambda f: f is None }})
    r"""The total number of currently running job tasks on the compute node. This includes Job Preparation, Job Release, and Job Manager tasks, but not the pool start task."""  
    scheduling_state: Optional[ComputeNodeSchedulingStateEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('schedulingState'), 'exclude': lambda f: f is None }})
    r"""Whether the compute node should be available for task scheduling."""  
    start_task: Optional[shared_starttask.StartTask] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('startTask'), 'exclude': lambda f: f is None }})
    r"""A task which is run when a compute node joins a pool in the Azure Batch service, or when the compute node is rebooted or reimaged."""  
    start_task_info: Optional[shared_starttaskinformation.StartTaskInformation] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('startTaskInfo'), 'exclude': lambda f: f is None }})
    r"""Information about a start task running on a compute node."""  
    state: Optional[ComputeNodeStateEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('state'), 'exclude': lambda f: f is None }})
    r"""The current state of the compute node."""  
    state_transition_time: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('stateTransitionTime'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})
    r"""The time at which the compute node entered its current state."""  
    total_tasks_run: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('totalTasksRun'), 'exclude': lambda f: f is None }})
    r"""The total number of job tasks completed on the compute node. This includes Job Preparation, Job Release and Job Manager tasks, but not the pool start task."""  
    total_tasks_succeeded: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('totalTasksSucceeded'), 'exclude': lambda f: f is None }})
    r"""The total number of job tasks which completed successfully (with exitCode 0) on the compute node. This includes Job Preparation, Job Release, and Job Manager tasks, but not the pool start task."""  
    url: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('url'), 'exclude': lambda f: f is None }})
    r"""The URL of the compute node."""  
    vm_size: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('vmSize'), 'exclude': lambda f: f is None }})
    r"""The size of the virtual machine hosting the compute node."""  
    