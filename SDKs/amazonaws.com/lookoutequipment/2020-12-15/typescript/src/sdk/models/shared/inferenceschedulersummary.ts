/*
 * Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.
 */

import { SpeakeasyBase, SpeakeasyMetadata } from "../../../internal/utils";
import { DataUploadFrequencyEnum } from "./datauploadfrequencyenum";
import { InferenceSchedulerStatusEnum } from "./inferenceschedulerstatusenum";
import { LatestInferenceResultEnum } from "./latestinferenceresultenum";
import { Expose } from "class-transformer";

/**
 * Contains information about the specific inference scheduler, including data delay offset, model name and ARN, status, and so on.
 */
export class InferenceSchedulerSummary extends SpeakeasyBase {
  @SpeakeasyMetadata()
  @Expose({ name: "DataDelayOffsetInMinutes" })
  dataDelayOffsetInMinutes?: number;

  @SpeakeasyMetadata()
  @Expose({ name: "DataUploadFrequency" })
  dataUploadFrequency?: DataUploadFrequencyEnum;

  @SpeakeasyMetadata()
  @Expose({ name: "InferenceSchedulerArn" })
  inferenceSchedulerArn?: string;

  @SpeakeasyMetadata()
  @Expose({ name: "InferenceSchedulerName" })
  inferenceSchedulerName?: string;

  @SpeakeasyMetadata()
  @Expose({ name: "LatestInferenceResult" })
  latestInferenceResult?: LatestInferenceResultEnum;

  @SpeakeasyMetadata()
  @Expose({ name: "ModelArn" })
  modelArn?: string;

  @SpeakeasyMetadata()
  @Expose({ name: "ModelName" })
  modelName?: string;

  @SpeakeasyMetadata()
  @Expose({ name: "Status" })
  status?: InferenceSchedulerStatusEnum;
}
