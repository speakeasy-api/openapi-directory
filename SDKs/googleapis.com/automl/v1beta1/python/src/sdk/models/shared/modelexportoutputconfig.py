"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import gcrdestination as shared_gcrdestination
from ..shared import gcsdestination as shared_gcsdestination
from dataclasses_json import Undefined, dataclass_json
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class ModelExportOutputConfig:
    r"""Output configuration for ModelExport Action."""
    
    gcr_destination: Optional[shared_gcrdestination.GcrDestination] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('gcrDestination'), 'exclude': lambda f: f is None }})
    r"""The GCR location where the image must be pushed to."""  
    gcs_destination: Optional[shared_gcsdestination.GcsDestination] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('gcsDestination'), 'exclude': lambda f: f is None }})
    r"""The Google Cloud Storage location where the output is to be written to."""  
    model_format: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('modelFormat'), 'exclude': lambda f: f is None }})
    r"""The format in which the model must be exported. The available, and default, formats depend on the problem and model type (if given problem and type combination doesn't have a format listed, it means its models are not exportable): * For Image Classification mobile-low-latency-1, mobile-versatile-1, mobile-high-accuracy-1: \\"tflite\\" (default), \\"edgetpu_tflite\\", \\"tf_saved_model\\", \\"tf_js\\", \\"docker\\". * For Image Classification mobile-core-ml-low-latency-1, mobile-core-ml-versatile-1, mobile-core-ml-high-accuracy-1: \\"core_ml\\" (default). * For Image Object Detection mobile-low-latency-1, mobile-versatile-1, mobile-high-accuracy-1: \\"tflite\\", \\"tf_saved_model\\", \\"tf_js\\". * For Video Classification cloud, \\"tf_saved_model\\". * For Video Object Tracking cloud, \\"tf_saved_model\\". * For Video Object Tracking mobile-versatile-1: \\"tflite\\", \\"edgetpu_tflite\\", \\"tf_saved_model\\", \\"docker\\". * For Video Object Tracking mobile-coral-versatile-1: \\"tflite\\", \\"edgetpu_tflite\\", \\"docker\\". * For Video Object Tracking mobile-coral-low-latency-1: \\"tflite\\", \\"edgetpu_tflite\\", \\"docker\\". * For Video Object Tracking mobile-jetson-versatile-1: \\"tf_saved_model\\", \\"docker\\". * For Tables: \\"docker\\". Formats description: * tflite - Used for Android mobile devices. * edgetpu_tflite - Used for [Edge TPU](https://cloud.google.com/edge-tpu/) devices. * tf_saved_model - A tensorflow model in SavedModel format. * tf_js - A [TensorFlow.js](https://www.tensorflow.org/js) model that can be used in the browser and in Node.js using JavaScript. * docker - Used for Docker containers. Use the params field to customize the container. The container is verified to work correctly on ubuntu 16.04 operating system. See more at [containers quickstart](https: //cloud.google.com/vision/automl/docs/containers-gcs-quickstart) * core_ml - Used for iOS mobile devices."""  
    params: Optional[dict[str, str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('params'), 'exclude': lambda f: f is None }})
    r"""Additional model-type and format specific parameters describing the requirements for the to be exported model files, any string must be up to 25000 characters long. * For `docker` format: `cpu_architecture` - (string) \\"x86_64\\" (default). `gpu_architecture` - (string) \\"none\\" (default), \\"nvidia\\"."""  
    