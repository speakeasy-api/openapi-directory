"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
import dateutil.parser
from ..shared import jobschedulefrequency as shared_jobschedulefrequency
from ..shared import jobstatus_enum as shared_jobstatus_enum
from ..shared import jobtype_enum as shared_jobtype_enum
from ..shared import lastrunerrorstatus as shared_lastrunerrorstatus
from ..shared import manageddataidentifierselector_enum as shared_manageddataidentifierselector_enum
from ..shared import s3jobdefinition as shared_s3jobdefinition
from ..shared import statistics as shared_statistics
from ..shared import userpauseddetails as shared_userpauseddetails
from dataclasses_json import Undefined, dataclass_json
from datetime import datetime
from marshmallow import fields
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class DescribeClassificationJobResponse:
    r"""Success"""
    
    allow_list_ids: Optional[list[str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('allowListIds'), 'exclude': lambda f: f is None }})  
    client_token: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('clientToken'), 'exclude': lambda f: f is None }})  
    created_at: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('createdAt'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})  
    custom_data_identifier_ids: Optional[list[str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('customDataIdentifierIds'), 'exclude': lambda f: f is None }})  
    description: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('description'), 'exclude': lambda f: f is None }})  
    initial_run: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('initialRun'), 'exclude': lambda f: f is None }})  
    job_arn: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('jobArn'), 'exclude': lambda f: f is None }})  
    job_id: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('jobId'), 'exclude': lambda f: f is None }})  
    job_status: Optional[shared_jobstatus_enum.JobStatusEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('jobStatus'), 'exclude': lambda f: f is None }})  
    job_type: Optional[shared_jobtype_enum.JobTypeEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('jobType'), 'exclude': lambda f: f is None }})  
    last_run_error_status: Optional[shared_lastrunerrorstatus.LastRunErrorStatus] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('lastRunErrorStatus'), 'exclude': lambda f: f is None }})  
    last_run_time: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('lastRunTime'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})  
    managed_data_identifier_ids: Optional[list[str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('managedDataIdentifierIds'), 'exclude': lambda f: f is None }})  
    managed_data_identifier_selector: Optional[shared_manageddataidentifierselector_enum.ManagedDataIdentifierSelectorEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('managedDataIdentifierSelector'), 'exclude': lambda f: f is None }})  
    name: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('name'), 'exclude': lambda f: f is None }})  
    s3_job_definition: Optional[shared_s3jobdefinition.S3JobDefinition] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('s3JobDefinition'), 'exclude': lambda f: f is None }})  
    sampling_percentage: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('samplingPercentage'), 'exclude': lambda f: f is None }})  
    schedule_frequency: Optional[shared_jobschedulefrequency.JobScheduleFrequency] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('scheduleFrequency'), 'exclude': lambda f: f is None }})  
    statistics: Optional[shared_statistics.Statistics] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('statistics'), 'exclude': lambda f: f is None }})  
    tags: Optional[dict[str, str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('tags'), 'exclude': lambda f: f is None }})  
    user_paused_details: Optional[shared_userpauseddetails.UserPausedDetails] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('userPausedDetails'), 'exclude': lambda f: f is None }})  
    