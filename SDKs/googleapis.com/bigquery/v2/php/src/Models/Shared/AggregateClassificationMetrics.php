<?php

/**
 * Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.
 */

declare(strict_types=1);

namespace OpenAPI\OpenAPI\Models\Shared;


/**
 * AggregateClassificationMetrics - Aggregate metrics for classification/classifier models. For multi-class models, the metrics are either macro-averaged or micro-averaged. When macro-averaged, the metrics are calculated for each label and then an unweighted average is taken of those values. When micro-averaged, the metric is calculated globally by counting the total number of correctly predicted rows.
 * 
 * @package OpenAPI\OpenAPI\Models\Shared
 * @access public
 */
class AggregateClassificationMetrics
{
    /**
     * Accuracy is the fraction of predictions given the correct label. For multiclass this is a micro-averaged metric.
     * 
     * @var ?float $accuracy
     */
	#[\JMS\Serializer\Annotation\SerializedName('accuracy')]
    #[\JMS\Serializer\Annotation\Type('float')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public ?float $accuracy = null;
    
    /**
     * The F1 score is an average of recall and precision. For multiclass this is a macro-averaged metric.
     * 
     * @var ?float $f1Score
     */
	#[\JMS\Serializer\Annotation\SerializedName('f1Score')]
    #[\JMS\Serializer\Annotation\Type('float')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public ?float $f1Score = null;
    
    /**
     * Logarithmic Loss. For multiclass this is a macro-averaged metric.
     * 
     * @var ?float $logLoss
     */
	#[\JMS\Serializer\Annotation\SerializedName('logLoss')]
    #[\JMS\Serializer\Annotation\Type('float')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public ?float $logLoss = null;
    
    /**
     * Precision is the fraction of actual positive predictions that had positive actual labels. For multiclass this is a macro-averaged metric treating each class as a binary classifier.
     * 
     * @var ?float $precision
     */
	#[\JMS\Serializer\Annotation\SerializedName('precision')]
    #[\JMS\Serializer\Annotation\Type('float')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public ?float $precision = null;
    
    /**
     * Recall is the fraction of actual positive labels that were given a positive prediction. For multiclass this is a macro-averaged metric.
     * 
     * @var ?float $recall
     */
	#[\JMS\Serializer\Annotation\SerializedName('recall')]
    #[\JMS\Serializer\Annotation\Type('float')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public ?float $recall = null;
    
    /**
     * Area Under a ROC Curve. For multiclass this is a macro-averaged metric.
     * 
     * @var ?float $rocAuc
     */
	#[\JMS\Serializer\Annotation\SerializedName('rocAuc')]
    #[\JMS\Serializer\Annotation\Type('float')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public ?float $rocAuc = null;
    
    /**
     * Threshold at which the metrics are computed. For binary classification models this is the positive class threshold. For multi-class classfication models this is the confidence threshold.
     * 
     * @var ?float $threshold
     */
	#[\JMS\Serializer\Annotation\SerializedName('threshold')]
    #[\JMS\Serializer\Annotation\Type('float')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public ?float $threshold = null;
    
	public function __construct()
	{
		$this->accuracy = null;
		$this->f1Score = null;
		$this->logLoss = null;
		$this->precision = null;
		$this->recall = null;
		$this->rocAuc = null;
		$this->threshold = null;
	}
}
