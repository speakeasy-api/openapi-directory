/*
 * Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.
 */

import { SpeakeasyBase, SpeakeasyMetadata } from "../../../internal/utils";
import { Expose } from "class-transformer";

/**
 * Config for video event human labeling task.
 */
export class GoogleCloudDatalabelingV1beta1EventConfig extends SpeakeasyBase {
  /**
   * Required. The list of annotation spec set resource name. Similar to video classification, we support selecting event from multiple AnnotationSpecSet at the same time.
   */
  @SpeakeasyMetadata()
  @Expose({ name: "annotationSpecSets" })
  annotationSpecSets?: string[];

  /**
   * Videos will be cut to smaller clips to make it easier for labelers to work on. Users can configure is field in seconds, if not set, default value is 60s.
   */
  @SpeakeasyMetadata()
  @Expose({ name: "clipLength" })
  clipLength?: number;

  /**
   * The overlap length between different video clips. Users can configure is field in seconds, if not set, default value is 1s.
   */
  @SpeakeasyMetadata()
  @Expose({ name: "overlapLength" })
  overlapLength?: number;
}
