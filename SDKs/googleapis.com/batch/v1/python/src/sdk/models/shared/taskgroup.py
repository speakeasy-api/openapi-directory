"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import environment as shared_environment
from ..shared import taskspec as shared_taskspec
from dataclasses_json import Undefined, dataclass_json
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class TaskGroup:
    r"""A TaskGroup contains one or multiple Tasks that share the same Runnable but with different runtime parameters."""
    
    name: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('name'), 'exclude': lambda f: f is None }})
    r"""Output only. TaskGroup name. The system generates this field based on parent Job name. For example: \\"projects/123456/locations/us-west1/jobs/job01/taskGroups/group01\\"."""  
    parallelism: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('parallelism'), 'exclude': lambda f: f is None }})
    r"""Max number of tasks that can run in parallel. Default to min(task_count, 1000). Field parallelism must be 1 if the scheduling_policy is IN_ORDER."""  
    permissive_ssh: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('permissiveSsh'), 'exclude': lambda f: f is None }})
    r"""When true, Batch will configure SSH to allow passwordless login between VMs running the Batch tasks in the same TaskGroup."""  
    require_hosts_file: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('requireHostsFile'), 'exclude': lambda f: f is None }})
    r"""When true, Batch will populate a file with a list of all VMs assigned to the TaskGroup and set the BATCH_HOSTS_FILE environment variable to the path of that file. Defaults to false."""  
    task_count: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('taskCount'), 'exclude': lambda f: f is None }})
    r"""Number of Tasks in the TaskGroup. Default is 1."""  
    task_count_per_node: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('taskCountPerNode'), 'exclude': lambda f: f is None }})
    r"""Max number of tasks that can be run on a VM at the same time. If not specified, the system will decide a value based on available compute resources on a VM and task requirements."""  
    task_environments: Optional[list[shared_environment.Environment]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('taskEnvironments'), 'exclude': lambda f: f is None }})
    r"""An array of environment variable mappings, which are passed to Tasks with matching indices. If task_environments is used then task_count should not be specified in the request (and will be ignored). Task count will be the length of task_environments. Tasks get a BATCH_TASK_INDEX and BATCH_TASK_COUNT environment variable, in addition to any environment variables set in task_environments, specifying the number of Tasks in the Task's parent TaskGroup, and the specific Task's index in the TaskGroup (0 through BATCH_TASK_COUNT - 1). task_environments supports up to 200 entries."""  
    task_spec: Optional[shared_taskspec.TaskSpec] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('taskSpec'), 'exclude': lambda f: f is None }})
    r"""Spec of a task"""  
    

@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class TaskGroupInput:
    r"""A TaskGroup contains one or multiple Tasks that share the same Runnable but with different runtime parameters."""
    
    parallelism: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('parallelism'), 'exclude': lambda f: f is None }})
    r"""Max number of tasks that can run in parallel. Default to min(task_count, 1000). Field parallelism must be 1 if the scheduling_policy is IN_ORDER."""  
    permissive_ssh: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('permissiveSsh'), 'exclude': lambda f: f is None }})
    r"""When true, Batch will configure SSH to allow passwordless login between VMs running the Batch tasks in the same TaskGroup."""  
    require_hosts_file: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('requireHostsFile'), 'exclude': lambda f: f is None }})
    r"""When true, Batch will populate a file with a list of all VMs assigned to the TaskGroup and set the BATCH_HOSTS_FILE environment variable to the path of that file. Defaults to false."""  
    task_count: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('taskCount'), 'exclude': lambda f: f is None }})
    r"""Number of Tasks in the TaskGroup. Default is 1."""  
    task_count_per_node: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('taskCountPerNode'), 'exclude': lambda f: f is None }})
    r"""Max number of tasks that can be run on a VM at the same time. If not specified, the system will decide a value based on available compute resources on a VM and task requirements."""  
    task_environments: Optional[list[shared_environment.Environment]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('taskEnvironments'), 'exclude': lambda f: f is None }})
    r"""An array of environment variable mappings, which are passed to Tasks with matching indices. If task_environments is used then task_count should not be specified in the request (and will be ignored). Task count will be the length of task_environments. Tasks get a BATCH_TASK_INDEX and BATCH_TASK_COUNT environment variable, in addition to any environment variables set in task_environments, specifying the number of Tasks in the Task's parent TaskGroup, and the specific Task's index in the TaskGroup (0 through BATCH_TASK_COUNT - 1). task_environments supports up to 200 entries."""  
    task_spec: Optional[shared_taskspec.TaskSpec] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('taskSpec'), 'exclude': lambda f: f is None }})
    r"""Spec of a task"""  
    