"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from dataclasses_json import Undefined, dataclass_json
from enum import Enum
from sdk import utils
from typing import Optional

class GoogleCloudMlV1AcceleratorConfigTypeEnum(str, Enum):
    r"""The type of accelerator to use."""
    ACCELERATOR_TYPE_UNSPECIFIED = 'ACCELERATOR_TYPE_UNSPECIFIED'
    NVIDIA_TESLA_K80 = 'NVIDIA_TESLA_K80'
    NVIDIA_TESLA_P100 = 'NVIDIA_TESLA_P100'
    NVIDIA_TESLA_V100 = 'NVIDIA_TESLA_V100'
    NVIDIA_TESLA_P4 = 'NVIDIA_TESLA_P4'
    NVIDIA_TESLA_T4 = 'NVIDIA_TESLA_T4'
    NVIDIA_TESLA_A100 = 'NVIDIA_TESLA_A100'
    TPU_V2 = 'TPU_V2'
    TPU_V3 = 'TPU_V3'
    TPU_V4 = 'TPU_V4'
    TPU_V2_POD = 'TPU_V2_POD'
    TPU_V3_POD = 'TPU_V3_POD'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class GoogleCloudMlV1AcceleratorConfig:
    r"""Represents a hardware accelerator request config. Note that the AcceleratorConfig can be used in both Jobs and Versions. Learn more about [accelerators for training](/ml-engine/docs/using-gpus) and [accelerators for online prediction](/ml-engine/docs/machine-types-online-prediction#gpus)."""
    
    count: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('count'), 'exclude': lambda f: f is None }})
    r"""The number of accelerators to attach to each machine running the job."""  
    type: Optional[GoogleCloudMlV1AcceleratorConfigTypeEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('type'), 'exclude': lambda f: f is None }})
    r"""The type of accelerator to use."""  
    