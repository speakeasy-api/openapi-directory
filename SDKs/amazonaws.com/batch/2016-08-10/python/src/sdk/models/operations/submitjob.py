"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
import requests as requests_http
from ..shared import ekspodpropertiesoverride as shared_ekspodpropertiesoverride
from ..shared import evaluateonexit as shared_evaluateonexit
from ..shared import jobdependency as shared_jobdependency
from ..shared import keyvaluepair as shared_keyvaluepair
from ..shared import nodepropertyoverride as shared_nodepropertyoverride
from ..shared import resourcerequirement as shared_resourcerequirement
from ..shared import submitjobresponse as shared_submitjobresponse
from dataclasses_json import Undefined, dataclass_json
from sdk import utils
from typing import Any, Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class SubmitJobRequestBodyArrayProperties:
    r"""An object that represents an Batch array job."""
    
    size: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('size'), 'exclude': lambda f: f is None }})  
    

@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class SubmitJobRequestBodyContainerOverrides:
    r"""The overrides that should be sent to a container."""
    
    command: Optional[list[str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('command'), 'exclude': lambda f: f is None }})  
    environment: Optional[list[shared_keyvaluepair.KeyValuePair]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('environment'), 'exclude': lambda f: f is None }})  
    instance_type: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('instanceType'), 'exclude': lambda f: f is None }})  
    memory: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('memory'), 'exclude': lambda f: f is None }})  
    resource_requirements: Optional[list[shared_resourcerequirement.ResourceRequirement]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('resourceRequirements'), 'exclude': lambda f: f is None }})  
    vcpus: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('vcpus'), 'exclude': lambda f: f is None }})  
    

@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class SubmitJobRequestBodyEksPropertiesOverride:
    r"""An object that contains overrides for the Kubernetes resources of a job."""
    
    pod_properties: Optional[shared_ekspodpropertiesoverride.EksPodPropertiesOverride] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('podProperties'), 'exclude': lambda f: f is None }})  
    

@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class SubmitJobRequestBodyNodeOverrides:
    r"""<p>An object that represents any node overrides to a job definition that's used in a <a>SubmitJob</a> API operation.</p> <note> <p>This parameter isn't applicable to jobs that are running on Fargate resources. Don't provide it for these jobs. Rather, use <code>containerOverrides</code> instead.</p> </note>"""
    
    node_property_overrides: Optional[list[shared_nodepropertyoverride.NodePropertyOverride]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('nodePropertyOverrides'), 'exclude': lambda f: f is None }})  
    num_nodes: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('numNodes'), 'exclude': lambda f: f is None }})  
    

@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class SubmitJobRequestBodyRetryStrategy:
    r"""The retry strategy that's associated with a job. For more information, see <a href=\\"https://docs.aws.amazon.com/batch/latest/userguide/job_retries.html\\">Automated job retries</a> in the <i>Batch User Guide</i>."""
    
    attempts: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('attempts'), 'exclude': lambda f: f is None }})  
    evaluate_on_exit: Optional[list[shared_evaluateonexit.EvaluateOnExit]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('evaluateOnExit'), 'exclude': lambda f: f is None }})  
    

@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class SubmitJobRequestBodyTimeout:
    r"""An object that represents a job timeout configuration."""
    
    attempt_duration_seconds: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('attemptDurationSeconds'), 'exclude': lambda f: f is None }})  
    

@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class SubmitJobRequestBody:
    
    job_definition: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('jobDefinition') }})
    r"""<p>The job definition used by this job. This value can be one of <code>definition-name</code>, <code>definition-name:revision</code>, or the Amazon Resource Name (ARN) for the job definition, with or without the revision (<code>arn:aws:batch:<i>region</i>:<i>account</i>:job-definition/<i>definition-name</i>:<i>revision</i> </code>, or <code>arn:aws:batch:<i>region</i>:<i>account</i>:job-definition/<i>definition-name</i> </code>).</p> <p>If the revision is not specified, then the latest active revision is used.</p>"""  
    job_name: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('jobName') }})
    r"""The name of the job. It can be up to 128 letters long. The first character must be alphanumeric, can contain uppercase and lowercase letters, numbers, hyphens (-), and underscores (_)."""  
    job_queue: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('jobQueue') }})
    r"""The job queue where the job is submitted. You can specify either the name or the Amazon Resource Name (ARN) of the queue."""  
    array_properties: Optional[SubmitJobRequestBodyArrayProperties] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('arrayProperties'), 'exclude': lambda f: f is None }})
    r"""An object that represents an Batch array job."""  
    container_overrides: Optional[SubmitJobRequestBodyContainerOverrides] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('containerOverrides'), 'exclude': lambda f: f is None }})
    r"""The overrides that should be sent to a container."""  
    depends_on: Optional[list[shared_jobdependency.JobDependency]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('dependsOn'), 'exclude': lambda f: f is None }})
    r"""A list of dependencies for the job. A job can depend upon a maximum of 20 jobs. You can specify a <code>SEQUENTIAL</code> type dependency without specifying a job ID for array jobs so that each child array job completes sequentially, starting at index 0. You can also specify an <code>N_TO_N</code> type dependency with a job ID for array jobs. In that case, each index child of this job must wait for the corresponding index child of each dependency to complete before it can begin."""  
    eks_properties_override: Optional[SubmitJobRequestBodyEksPropertiesOverride] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('eksPropertiesOverride'), 'exclude': lambda f: f is None }})
    r"""An object that contains overrides for the Kubernetes resources of a job."""  
    node_overrides: Optional[SubmitJobRequestBodyNodeOverrides] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('nodeOverrides'), 'exclude': lambda f: f is None }})
    r"""<p>An object that represents any node overrides to a job definition that's used in a <a>SubmitJob</a> API operation.</p> <note> <p>This parameter isn't applicable to jobs that are running on Fargate resources. Don't provide it for these jobs. Rather, use <code>containerOverrides</code> instead.</p> </note>"""  
    parameters: Optional[dict[str, str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('parameters'), 'exclude': lambda f: f is None }})
    r"""Additional parameters passed to the job that replace parameter substitution placeholders that are set in the job definition. Parameters are specified as a key and value pair mapping. Parameters in a <code>SubmitJob</code> request override any corresponding parameter defaults from the job definition."""  
    propagate_tags: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('propagateTags'), 'exclude': lambda f: f is None }})
    r"""Specifies whether to propagate the tags from the job or job definition to the corresponding Amazon ECS task. If no value is specified, the tags aren't propagated. Tags can only be propagated to the tasks during task creation. For tags with the same name, job tags are given priority over job definitions tags. If the total number of combined tags from the job and job definition is over 50, the job is moved to the <code>FAILED</code> state. When specified, this overrides the tag propagation setting in the job definition."""  
    retry_strategy: Optional[SubmitJobRequestBodyRetryStrategy] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('retryStrategy'), 'exclude': lambda f: f is None }})
    r"""The retry strategy that's associated with a job. For more information, see <a href=\\"https://docs.aws.amazon.com/batch/latest/userguide/job_retries.html\\">Automated job retries</a> in the <i>Batch User Guide</i>."""  
    scheduling_priority_override: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('schedulingPriorityOverride'), 'exclude': lambda f: f is None }})
    r"""<p>The scheduling priority for the job. This only affects jobs in job queues with a fair share policy. Jobs with a higher scheduling priority are scheduled before jobs with a lower scheduling priority. This overrides any scheduling priority in the job definition.</p> <p>The minimum supported value is 0 and the maximum supported value is 9999.</p>"""  
    share_identifier: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('shareIdentifier'), 'exclude': lambda f: f is None }})
    r"""The share identifier for the job. If the job queue doesn't have a scheduling policy, then this parameter must not be specified. If the job queue has a scheduling policy, then this parameter must be specified."""  
    tags: Optional[dict[str, str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('tags'), 'exclude': lambda f: f is None }})
    r"""The tags that you apply to the job request to help you categorize and organize your resources. Each tag consists of a key and an optional value. For more information, see <a href=\\"https://docs.aws.amazon.com/general/latest/gr/aws_tagging.html\\">Tagging Amazon Web Services Resources</a> in <i>Amazon Web Services General Reference</i>."""  
    timeout: Optional[SubmitJobRequestBodyTimeout] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('timeout'), 'exclude': lambda f: f is None }})
    r"""An object that represents a job timeout configuration."""  
    

@dataclasses.dataclass
class SubmitJobRequest:
    
    request_body: SubmitJobRequestBody = dataclasses.field(metadata={'request': { 'media_type': 'application/json' }})  
    x_amz_algorithm: Optional[str] = dataclasses.field(default=None, metadata={'header': { 'field_name': 'X-Amz-Algorithm', 'style': 'simple', 'explode': False }})  
    x_amz_content_sha256: Optional[str] = dataclasses.field(default=None, metadata={'header': { 'field_name': 'X-Amz-Content-Sha256', 'style': 'simple', 'explode': False }})  
    x_amz_credential: Optional[str] = dataclasses.field(default=None, metadata={'header': { 'field_name': 'X-Amz-Credential', 'style': 'simple', 'explode': False }})  
    x_amz_date: Optional[str] = dataclasses.field(default=None, metadata={'header': { 'field_name': 'X-Amz-Date', 'style': 'simple', 'explode': False }})  
    x_amz_security_token: Optional[str] = dataclasses.field(default=None, metadata={'header': { 'field_name': 'X-Amz-Security-Token', 'style': 'simple', 'explode': False }})  
    x_amz_signature: Optional[str] = dataclasses.field(default=None, metadata={'header': { 'field_name': 'X-Amz-Signature', 'style': 'simple', 'explode': False }})  
    x_amz_signed_headers: Optional[str] = dataclasses.field(default=None, metadata={'header': { 'field_name': 'X-Amz-SignedHeaders', 'style': 'simple', 'explode': False }})  
    

@dataclasses.dataclass
class SubmitJobResponse:
    
    content_type: str = dataclasses.field()  
    status_code: int = dataclasses.field()  
    client_exception: Optional[Any] = dataclasses.field(default=None)
    r"""ClientException"""  
    raw_response: Optional[requests_http.Response] = dataclasses.field(default=None)  
    server_exception: Optional[Any] = dataclasses.field(default=None)
    r"""ServerException"""  
    submit_job_response: Optional[shared_submitjobresponse.SubmitJobResponse] = dataclasses.field(default=None)
    r"""Success"""  
    