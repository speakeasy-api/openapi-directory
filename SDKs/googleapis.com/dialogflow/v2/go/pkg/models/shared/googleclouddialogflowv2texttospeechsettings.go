// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
)

// GoogleCloudDialogflowV2TextToSpeechSettingsOutputAudioEncodingEnum - Required. Audio encoding of the synthesized audio content.
type GoogleCloudDialogflowV2TextToSpeechSettingsOutputAudioEncodingEnum string

const (
	GoogleCloudDialogflowV2TextToSpeechSettingsOutputAudioEncodingEnumOutputAudioEncodingUnspecified GoogleCloudDialogflowV2TextToSpeechSettingsOutputAudioEncodingEnum = "OUTPUT_AUDIO_ENCODING_UNSPECIFIED"
	GoogleCloudDialogflowV2TextToSpeechSettingsOutputAudioEncodingEnumOutputAudioEncodingLinear16    GoogleCloudDialogflowV2TextToSpeechSettingsOutputAudioEncodingEnum = "OUTPUT_AUDIO_ENCODING_LINEAR_16"
	GoogleCloudDialogflowV2TextToSpeechSettingsOutputAudioEncodingEnumOutputAudioEncodingMp3         GoogleCloudDialogflowV2TextToSpeechSettingsOutputAudioEncodingEnum = "OUTPUT_AUDIO_ENCODING_MP3"
	GoogleCloudDialogflowV2TextToSpeechSettingsOutputAudioEncodingEnumOutputAudioEncodingMp364Kbps   GoogleCloudDialogflowV2TextToSpeechSettingsOutputAudioEncodingEnum = "OUTPUT_AUDIO_ENCODING_MP3_64_KBPS"
	GoogleCloudDialogflowV2TextToSpeechSettingsOutputAudioEncodingEnumOutputAudioEncodingOggOpus     GoogleCloudDialogflowV2TextToSpeechSettingsOutputAudioEncodingEnum = "OUTPUT_AUDIO_ENCODING_OGG_OPUS"
	GoogleCloudDialogflowV2TextToSpeechSettingsOutputAudioEncodingEnumOutputAudioEncodingMulaw       GoogleCloudDialogflowV2TextToSpeechSettingsOutputAudioEncodingEnum = "OUTPUT_AUDIO_ENCODING_MULAW"
)

func (e *GoogleCloudDialogflowV2TextToSpeechSettingsOutputAudioEncodingEnum) UnmarshalJSON(data []byte) error {
	var s string
	if err := json.Unmarshal(data, &s); err != nil {
		return err
	}
	switch s {
	case "OUTPUT_AUDIO_ENCODING_UNSPECIFIED":
		fallthrough
	case "OUTPUT_AUDIO_ENCODING_LINEAR_16":
		fallthrough
	case "OUTPUT_AUDIO_ENCODING_MP3":
		fallthrough
	case "OUTPUT_AUDIO_ENCODING_MP3_64_KBPS":
		fallthrough
	case "OUTPUT_AUDIO_ENCODING_OGG_OPUS":
		fallthrough
	case "OUTPUT_AUDIO_ENCODING_MULAW":
		*e = GoogleCloudDialogflowV2TextToSpeechSettingsOutputAudioEncodingEnum(s)
		return nil
	default:
		return fmt.Errorf("invalid value for GoogleCloudDialogflowV2TextToSpeechSettingsOutputAudioEncodingEnum: %s", s)
	}
}

// GoogleCloudDialogflowV2TextToSpeechSettings - Instructs the speech synthesizer on how to generate the output audio content.
type GoogleCloudDialogflowV2TextToSpeechSettings struct {
	// Optional. Indicates whether text to speech is enabled. Even when this field is false, other settings in this proto are still retained.
	EnableTextToSpeech *bool `json:"enableTextToSpeech,omitempty"`
	// Required. Audio encoding of the synthesized audio content.
	OutputAudioEncoding *GoogleCloudDialogflowV2TextToSpeechSettingsOutputAudioEncodingEnum `json:"outputAudioEncoding,omitempty"`
	// Optional. The synthesis sample rate (in hertz) for this audio. If not provided, then the synthesizer will use the default sample rate based on the audio encoding. If this is different from the voice's natural sample rate, then the synthesizer will honor this request by converting to the desired sample rate (which might result in worse audio quality).
	SampleRateHertz *int `json:"sampleRateHertz,omitempty"`
	// Optional. Configuration of how speech should be synthesized, mapping from language (https://cloud.google.com/dialogflow/docs/reference/language) to SynthesizeSpeechConfig.
	SynthesizeSpeechConfigs map[string]GoogleCloudDialogflowV2SynthesizeSpeechConfig `json:"synthesizeSpeechConfigs,omitempty"`
}
