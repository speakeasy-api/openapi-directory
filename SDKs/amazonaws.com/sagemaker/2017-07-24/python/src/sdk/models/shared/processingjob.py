"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
import dateutil.parser
from ..shared import appspecification as shared_appspecification
from ..shared import experimentconfig as shared_experimentconfig
from ..shared import networkconfig as shared_networkconfig
from ..shared import processinginput as shared_processinginput
from ..shared import processingjobstatus_enum as shared_processingjobstatus_enum
from ..shared import processingoutputconfig as shared_processingoutputconfig
from ..shared import processingresources as shared_processingresources
from ..shared import processingstoppingcondition as shared_processingstoppingcondition
from ..shared import tag as shared_tag
from dataclasses_json import Undefined, dataclass_json
from datetime import datetime
from marshmallow import fields
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class ProcessingJob:
    r"""An Amazon SageMaker processing job that is used to analyze data and evaluate models. For more information, see <a href=\\"https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job.html\\">Process Data and Evaluate Models</a>."""
    
    app_specification: Optional[shared_appspecification.AppSpecification] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('AppSpecification'), 'exclude': lambda f: f is None }})
    r"""Configuration to run a processing job in a specified container image."""  
    auto_ml_job_arn: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('AutoMLJobArn'), 'exclude': lambda f: f is None }})  
    creation_time: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('CreationTime'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})  
    environment: Optional[dict[str, str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('Environment'), 'exclude': lambda f: f is None }})  
    exit_message: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ExitMessage'), 'exclude': lambda f: f is None }})  
    experiment_config: Optional[shared_experimentconfig.ExperimentConfig] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ExperimentConfig'), 'exclude': lambda f: f is None }})
    r"""<p>Associates a SageMaker job as a trial component with an experiment and trial. Specified when you call the following APIs:</p> <ul> <li> <p> <a>CreateProcessingJob</a> </p> </li> <li> <p> <a>CreateTrainingJob</a> </p> </li> <li> <p> <a>CreateTransformJob</a> </p> </li> </ul>"""  
    failure_reason: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('FailureReason'), 'exclude': lambda f: f is None }})  
    last_modified_time: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('LastModifiedTime'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})  
    monitoring_schedule_arn: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('MonitoringScheduleArn'), 'exclude': lambda f: f is None }})  
    network_config: Optional[shared_networkconfig.NetworkConfig] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('NetworkConfig'), 'exclude': lambda f: f is None }})
    r"""Networking options for a job, such as network traffic encryption between containers, whether to allow inbound and outbound network calls to and from containers, and the VPC subnets and security groups to use for VPC-enabled jobs."""  
    processing_end_time: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ProcessingEndTime'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})  
    processing_inputs: Optional[list[shared_processinginput.ProcessingInput]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ProcessingInputs'), 'exclude': lambda f: f is None }})  
    processing_job_arn: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ProcessingJobArn'), 'exclude': lambda f: f is None }})  
    processing_job_name: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ProcessingJobName'), 'exclude': lambda f: f is None }})  
    processing_job_status: Optional[shared_processingjobstatus_enum.ProcessingJobStatusEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ProcessingJobStatus'), 'exclude': lambda f: f is None }})  
    processing_output_config: Optional[shared_processingoutputconfig.ProcessingOutputConfig] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ProcessingOutputConfig'), 'exclude': lambda f: f is None }})
    r"""Configuration for uploading output from the processing container."""  
    processing_resources: Optional[shared_processingresources.ProcessingResources] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ProcessingResources'), 'exclude': lambda f: f is None }})
    r"""Identifies the resources, ML compute instances, and ML storage volumes to deploy for a processing job. In distributed training, you specify more than one instance."""  
    processing_start_time: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ProcessingStartTime'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})  
    role_arn: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('RoleArn'), 'exclude': lambda f: f is None }})  
    stopping_condition: Optional[shared_processingstoppingcondition.ProcessingStoppingCondition] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('StoppingCondition'), 'exclude': lambda f: f is None }})
    r"""Configures conditions under which the processing job should be stopped, such as how long the processing job has been running. After the condition is met, the processing job is stopped."""  
    tags: Optional[list[shared_tag.Tag]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('Tags'), 'exclude': lambda f: f is None }})  
    training_job_arn: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('TrainingJobArn'), 'exclude': lambda f: f is None }})  
    