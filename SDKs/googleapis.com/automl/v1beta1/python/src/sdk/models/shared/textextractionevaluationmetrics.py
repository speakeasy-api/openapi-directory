"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import textextractionevaluationmetricsconfidencemetricsentry as shared_textextractionevaluationmetricsconfidencemetricsentry
from dataclasses_json import Undefined, dataclass_json
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class TextExtractionEvaluationMetrics:
    r"""Model evaluation metrics for text extraction problems."""
    
    au_prc: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('auPrc'), 'exclude': lambda f: f is None }})
    r"""Output only. The Area under precision recall curve metric."""  
    confidence_metrics_entries: Optional[list[shared_textextractionevaluationmetricsconfidencemetricsentry.TextExtractionEvaluationMetricsConfidenceMetricsEntry]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('confidenceMetricsEntries'), 'exclude': lambda f: f is None }})
    r"""Output only. Metrics that have confidence thresholds. Precision-recall curve can be derived from it."""  
    