// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
)

// ExecutionTemplateJobTypeEnum - The type of Job to be used on this execution.
type ExecutionTemplateJobTypeEnum string

const (
	ExecutionTemplateJobTypeEnumJobTypeUnspecified ExecutionTemplateJobTypeEnum = "JOB_TYPE_UNSPECIFIED"
	ExecutionTemplateJobTypeEnumVertexAi           ExecutionTemplateJobTypeEnum = "VERTEX_AI"
	ExecutionTemplateJobTypeEnumDataproc           ExecutionTemplateJobTypeEnum = "DATAPROC"
)

func (e ExecutionTemplateJobTypeEnum) ToPointer() *ExecutionTemplateJobTypeEnum {
	return &e
}

func (e *ExecutionTemplateJobTypeEnum) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "JOB_TYPE_UNSPECIFIED":
		fallthrough
	case "VERTEX_AI":
		fallthrough
	case "DATAPROC":
		*e = ExecutionTemplateJobTypeEnum(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ExecutionTemplateJobTypeEnum: %v", v)
	}
}

// ExecutionTemplateScaleTierEnum - Required. Scale tier of the hardware used for notebook execution. DEPRECATED Will be discontinued. As right now only CUSTOM is supported.
type ExecutionTemplateScaleTierEnum string

const (
	ExecutionTemplateScaleTierEnumScaleTierUnspecified ExecutionTemplateScaleTierEnum = "SCALE_TIER_UNSPECIFIED"
	ExecutionTemplateScaleTierEnumBasic                ExecutionTemplateScaleTierEnum = "BASIC"
	ExecutionTemplateScaleTierEnumStandard1            ExecutionTemplateScaleTierEnum = "STANDARD_1"
	ExecutionTemplateScaleTierEnumPremium1             ExecutionTemplateScaleTierEnum = "PREMIUM_1"
	ExecutionTemplateScaleTierEnumBasicGpu             ExecutionTemplateScaleTierEnum = "BASIC_GPU"
	ExecutionTemplateScaleTierEnumBasicTpu             ExecutionTemplateScaleTierEnum = "BASIC_TPU"
	ExecutionTemplateScaleTierEnumCustom               ExecutionTemplateScaleTierEnum = "CUSTOM"
)

func (e ExecutionTemplateScaleTierEnum) ToPointer() *ExecutionTemplateScaleTierEnum {
	return &e
}

func (e *ExecutionTemplateScaleTierEnum) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "SCALE_TIER_UNSPECIFIED":
		fallthrough
	case "BASIC":
		fallthrough
	case "STANDARD_1":
		fallthrough
	case "PREMIUM_1":
		fallthrough
	case "BASIC_GPU":
		fallthrough
	case "BASIC_TPU":
		fallthrough
	case "CUSTOM":
		*e = ExecutionTemplateScaleTierEnum(v)
		return nil
	default:
		return fmt.Errorf("invalid value for ExecutionTemplateScaleTierEnum: %v", v)
	}
}

// ExecutionTemplate - The description a notebook execution workload.
type ExecutionTemplate struct {
	// Definition of a hardware accelerator. Note that not all combinations of `type` and `core_count` are valid. Check [GPUs on Compute Engine](https://cloud.google.com/compute/docs/gpus) to find a valid combination. TPUs are not supported.
	AcceleratorConfig *SchedulerAcceleratorConfig `json:"acceleratorConfig,omitempty"`
	// Container Image URI to a DLVM Example: 'gcr.io/deeplearning-platform-release/base-cu100' More examples can be found at: https://cloud.google.com/ai-platform/deep-learning-containers/docs/choosing-container
	ContainerImageURI *string `json:"containerImageUri,omitempty"`
	// Parameters used in Dataproc JobType executions.
	DataprocParameters *DataprocParameters `json:"dataprocParameters,omitempty"`
	// Path to the notebook file to execute. Must be in a Google Cloud Storage bucket. Format: `gs://{bucket_name}/{folder}/{notebook_file_name}` Ex: `gs://notebook_user/scheduled_notebooks/sentiment_notebook.ipynb`
	InputNotebookFile *string `json:"inputNotebookFile,omitempty"`
	// The type of Job to be used on this execution.
	JobType *ExecutionTemplateJobTypeEnum `json:"jobType,omitempty"`
	// Name of the kernel spec to use. This must be specified if the kernel spec name on the execution target does not match the name in the input notebook file.
	KernelSpec *string `json:"kernelSpec,omitempty"`
	// Labels for execution. If execution is scheduled, a field included will be 'nbs-scheduled'. Otherwise, it is an immediate execution, and an included field will be 'nbs-immediate'. Use fields to efficiently index between various types of executions.
	Labels map[string]string `json:"labels,omitempty"`
	// Specifies the type of virtual machine to use for your training job's master worker. You must specify this field when `scaleTier` is set to `CUSTOM`. You can use certain Compute Engine machine types directly in this field. The following types are supported: - `n1-standard-4` - `n1-standard-8` - `n1-standard-16` - `n1-standard-32` - `n1-standard-64` - `n1-standard-96` - `n1-highmem-2` - `n1-highmem-4` - `n1-highmem-8` - `n1-highmem-16` - `n1-highmem-32` - `n1-highmem-64` - `n1-highmem-96` - `n1-highcpu-16` - `n1-highcpu-32` - `n1-highcpu-64` - `n1-highcpu-96` Alternatively, you can use the following legacy machine types: - `standard` - `large_model` - `complex_model_s` - `complex_model_m` - `complex_model_l` - `standard_gpu` - `complex_model_m_gpu` - `complex_model_l_gpu` - `standard_p100` - `complex_model_m_p100` - `standard_v100` - `large_model_v100` - `complex_model_m_v100` - `complex_model_l_v100` Finally, if you want to use a TPU for training, specify `cloud_tpu` in this field. Learn more about the [special configuration options for training with TPU](https://cloud.google.com/ai-platform/training/docs/using-tpus#configuring_a_custom_tpu_machine).
	MasterType *string `json:"masterType,omitempty"`
	// Path to the notebook folder to write to. Must be in a Google Cloud Storage bucket path. Format: `gs://{bucket_name}/{folder}` Ex: `gs://notebook_user/scheduled_notebooks`
	OutputNotebookFolder *string `json:"outputNotebookFolder,omitempty"`
	// Parameters used within the 'input_notebook_file' notebook.
	Parameters *string `json:"parameters,omitempty"`
	// Parameters to be overridden in the notebook during execution. Ref https://papermill.readthedocs.io/en/latest/usage-parameterize.html on how to specifying parameters in the input notebook and pass them here in an YAML file. Ex: `gs://notebook_user/scheduled_notebooks/sentiment_notebook_params.yaml`
	ParamsYamlFile *string `json:"paramsYamlFile,omitempty"`
	// Required. Scale tier of the hardware used for notebook execution. DEPRECATED Will be discontinued. As right now only CUSTOM is supported.
	ScaleTier *ExecutionTemplateScaleTierEnum `json:"scaleTier,omitempty"`
	// The email address of a service account to use when running the execution. You must have the `iam.serviceAccounts.actAs` permission for the specified service account.
	ServiceAccount *string `json:"serviceAccount,omitempty"`
	// The name of a Vertex AI [Tensorboard] resource to which this execution will upload Tensorboard logs. Format: `projects/{project}/locations/{location}/tensorboards/{tensorboard}`
	Tensorboard *string `json:"tensorboard,omitempty"`
	// Parameters used in Vertex AI JobType executions.
	VertexAiParameters *VertexAIParameters `json:"vertexAiParameters,omitempty"`
}
