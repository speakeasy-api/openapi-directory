// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
)

// MetricMetricSourceEnum - Required. A standard set of metrics is collected unless metricOverrides are specified for the metric source (see Custom metrics (https://cloud.google.com/dataproc/docs/guides/dataproc-metrics#custom_metrics) for more information).
type MetricMetricSourceEnum string

const (
	MetricMetricSourceEnumMetricSourceUnspecified MetricMetricSourceEnum = "METRIC_SOURCE_UNSPECIFIED"
	MetricMetricSourceEnumMonitoringAgentDefaults MetricMetricSourceEnum = "MONITORING_AGENT_DEFAULTS"
	MetricMetricSourceEnumHdfs                    MetricMetricSourceEnum = "HDFS"
	MetricMetricSourceEnumSpark                   MetricMetricSourceEnum = "SPARK"
	MetricMetricSourceEnumYarn                    MetricMetricSourceEnum = "YARN"
	MetricMetricSourceEnumSparkHistoryServer      MetricMetricSourceEnum = "SPARK_HISTORY_SERVER"
	MetricMetricSourceEnumHiveserver2             MetricMetricSourceEnum = "HIVESERVER2"
	MetricMetricSourceEnumHivemetastore           MetricMetricSourceEnum = "HIVEMETASTORE"
)

func (e MetricMetricSourceEnum) ToPointer() *MetricMetricSourceEnum {
	return &e
}

func (e *MetricMetricSourceEnum) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "METRIC_SOURCE_UNSPECIFIED":
		fallthrough
	case "MONITORING_AGENT_DEFAULTS":
		fallthrough
	case "HDFS":
		fallthrough
	case "SPARK":
		fallthrough
	case "YARN":
		fallthrough
	case "SPARK_HISTORY_SERVER":
		fallthrough
	case "HIVESERVER2":
		fallthrough
	case "HIVEMETASTORE":
		*e = MetricMetricSourceEnum(v)
		return nil
	default:
		return fmt.Errorf("invalid value for MetricMetricSourceEnum: %v", v)
	}
}

// Metric - A Dataproc custom metric.
type Metric struct {
	// Optional. Specify one or more Custom metrics (https://cloud.google.com/dataproc/docs/guides/dataproc-metrics#custom_metrics) to collect for the metric course (for the SPARK metric source (any Spark metric (https://spark.apache.org/docs/latest/monitoring.html#metrics) can be specified).Provide metrics in the following format: METRIC_SOURCE: INSTANCE:GROUP:METRIC Use camelcase as appropriate.Examples: yarn:ResourceManager:QueueMetrics:AppsCompleted spark:driver:DAGScheduler:job.allJobs sparkHistoryServer:JVM:Memory:NonHeapMemoryUsage.committed hiveserver2:JVM:Memory:NonHeapMemoryUsage.used Notes: Only the specified overridden metrics are collected for the metric source. For example, if one or more spark:executive metrics are listed as metric overrides, other SPARK metrics are not collected. The collection of the metrics for other enabled custom metric sources is unaffected. For example, if both SPARK andd YARN metric sources are enabled, and overrides are provided for Spark metrics only, all YARN metrics are collected.
	MetricOverrides []string `json:"metricOverrides,omitempty"`
	// Required. A standard set of metrics is collected unless metricOverrides are specified for the metric source (see Custom metrics (https://cloud.google.com/dataproc/docs/guides/dataproc-metrics#custom_metrics) for more information).
	MetricSource *MetricMetricSourceEnum `json:"metricSource,omitempty"`
}
