// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
)

// TransferConfigInput - Represents a data transfer configuration. A transfer configuration contains all metadata needed to perform a data transfer. For example, `destination_dataset_id` specifies where data should be stored. When a new transfer configuration is created, the specified `destination_dataset_id` is created when needed and shared with the appropriate data source service account.
type TransferConfigInput struct {
	// The number of days to look back to automatically refresh the data. For example, if `data_refresh_window_days = 10`, then every day BigQuery reingests data for [today-10, today-1], rather than ingesting data for just [today-1]. Only valid if the data source supports the feature. Set the value to 0 to use the default value.
	DataRefreshWindowDays *int `json:"dataRefreshWindowDays,omitempty"`
	// Data source ID. This cannot be changed once data transfer is created. The full list of available data source IDs can be returned through an API call: https://cloud.google.com/bigquery-transfer/docs/reference/datatransfer/rest/v1/projects.locations.dataSources/list
	DataSourceID *string `json:"dataSourceId,omitempty"`
	// The BigQuery target dataset id.
	DestinationDatasetID *string `json:"destinationDatasetId,omitempty"`
	// Is this config disabled. When set to true, no runs are scheduled for a given transfer.
	Disabled *bool `json:"disabled,omitempty"`
	// User specified display name for the data transfer.
	DisplayName *string `json:"displayName,omitempty"`
	// Represents preferences for sending email notifications for transfer run events.
	EmailPreferences *EmailPreferences `json:"emailPreferences,omitempty"`
	// The resource name of the transfer config. Transfer config names have the form `projects/{project_id}/locations/{region}/transferConfigs/{config_id}`. Where `config_id` is usually a uuid, even though it is not guaranteed or required. The name is ignored when creating a transfer config.
	Name *string `json:"name,omitempty"`
	// Pub/Sub topic where notifications will be sent after transfer runs associated with this transfer config finish. The format for specifying a pubsub topic is: `projects/{project}/topics/{topic}`
	NotificationPubsubTopic *string `json:"notificationPubsubTopic,omitempty"`
	// Information about a user.
	OwnerInfo *UserInfo `json:"ownerInfo,omitempty"`
	// Parameters specific to each data source. For more information see the bq tab in the 'Setting up a data transfer' section for each data source. For example the parameters for Cloud Storage transfers are listed here: https://cloud.google.com/bigquery-transfer/docs/cloud-storage-transfer#bq
	Params map[string]interface{} `json:"params,omitempty"`
	// Data transfer schedule. If the data source does not support a custom schedule, this should be empty. If it is empty, the default value for the data source will be used. The specified times are in UTC. Examples of valid format: `1st,3rd monday of month 15:30`, `every wed,fri of jan,jun 13:15`, and `first sunday of quarter 00:00`. See more explanation about the format here: https://cloud.google.com/appengine/docs/flexible/python/scheduling-jobs-with-cron-yaml#the_schedule_format NOTE: The minimum interval time between recurring transfers depends on the data source; refer to the documentation for your data source.
	Schedule *string `json:"schedule,omitempty"`
	// Options customizing the data transfer schedule.
	ScheduleOptions *ScheduleOptions `json:"scheduleOptions,omitempty"`
	// Deprecated. Unique ID of the user on whose behalf transfer is done.
	UserID *string `json:"userId,omitempty"`
}

// TransferConfigStateEnum - Output only. State of the most recently updated transfer run.
type TransferConfigStateEnum string

const (
	TransferConfigStateEnumTransferStateUnspecified TransferConfigStateEnum = "TRANSFER_STATE_UNSPECIFIED"
	TransferConfigStateEnumPending                  TransferConfigStateEnum = "PENDING"
	TransferConfigStateEnumRunning                  TransferConfigStateEnum = "RUNNING"
	TransferConfigStateEnumSucceeded                TransferConfigStateEnum = "SUCCEEDED"
	TransferConfigStateEnumFailed                   TransferConfigStateEnum = "FAILED"
	TransferConfigStateEnumCancelled                TransferConfigStateEnum = "CANCELLED"
)

func (e TransferConfigStateEnum) ToPointer() *TransferConfigStateEnum {
	return &e
}

func (e *TransferConfigStateEnum) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "TRANSFER_STATE_UNSPECIFIED":
		fallthrough
	case "PENDING":
		fallthrough
	case "RUNNING":
		fallthrough
	case "SUCCEEDED":
		fallthrough
	case "FAILED":
		fallthrough
	case "CANCELLED":
		*e = TransferConfigStateEnum(v)
		return nil
	default:
		return fmt.Errorf("invalid value for TransferConfigStateEnum: %v", v)
	}
}

// TransferConfig - Represents a data transfer configuration. A transfer configuration contains all metadata needed to perform a data transfer. For example, `destination_dataset_id` specifies where data should be stored. When a new transfer configuration is created, the specified `destination_dataset_id` is created when needed and shared with the appropriate data source service account.
type TransferConfig struct {
	// The number of days to look back to automatically refresh the data. For example, if `data_refresh_window_days = 10`, then every day BigQuery reingests data for [today-10, today-1], rather than ingesting data for just [today-1]. Only valid if the data source supports the feature. Set the value to 0 to use the default value.
	DataRefreshWindowDays *int `json:"dataRefreshWindowDays,omitempty"`
	// Data source ID. This cannot be changed once data transfer is created. The full list of available data source IDs can be returned through an API call: https://cloud.google.com/bigquery-transfer/docs/reference/datatransfer/rest/v1/projects.locations.dataSources/list
	DataSourceID *string `json:"dataSourceId,omitempty"`
	// Output only. Region in which BigQuery dataset is located.
	DatasetRegion *string `json:"datasetRegion,omitempty"`
	// The BigQuery target dataset id.
	DestinationDatasetID *string `json:"destinationDatasetId,omitempty"`
	// Is this config disabled. When set to true, no runs are scheduled for a given transfer.
	Disabled *bool `json:"disabled,omitempty"`
	// User specified display name for the data transfer.
	DisplayName *string `json:"displayName,omitempty"`
	// Represents preferences for sending email notifications for transfer run events.
	EmailPreferences *EmailPreferences `json:"emailPreferences,omitempty"`
	// The resource name of the transfer config. Transfer config names have the form `projects/{project_id}/locations/{region}/transferConfigs/{config_id}`. Where `config_id` is usually a uuid, even though it is not guaranteed or required. The name is ignored when creating a transfer config.
	Name *string `json:"name,omitempty"`
	// Output only. Next time when data transfer will run.
	NextRunTime *string `json:"nextRunTime,omitempty"`
	// Pub/Sub topic where notifications will be sent after transfer runs associated with this transfer config finish. The format for specifying a pubsub topic is: `projects/{project}/topics/{topic}`
	NotificationPubsubTopic *string `json:"notificationPubsubTopic,omitempty"`
	// Information about a user.
	OwnerInfo *UserInfo `json:"ownerInfo,omitempty"`
	// Parameters specific to each data source. For more information see the bq tab in the 'Setting up a data transfer' section for each data source. For example the parameters for Cloud Storage transfers are listed here: https://cloud.google.com/bigquery-transfer/docs/cloud-storage-transfer#bq
	Params map[string]interface{} `json:"params,omitempty"`
	// Data transfer schedule. If the data source does not support a custom schedule, this should be empty. If it is empty, the default value for the data source will be used. The specified times are in UTC. Examples of valid format: `1st,3rd monday of month 15:30`, `every wed,fri of jan,jun 13:15`, and `first sunday of quarter 00:00`. See more explanation about the format here: https://cloud.google.com/appengine/docs/flexible/python/scheduling-jobs-with-cron-yaml#the_schedule_format NOTE: The minimum interval time between recurring transfers depends on the data source; refer to the documentation for your data source.
	Schedule *string `json:"schedule,omitempty"`
	// Options customizing the data transfer schedule.
	ScheduleOptions *ScheduleOptions `json:"scheduleOptions,omitempty"`
	// Output only. State of the most recently updated transfer run.
	State *TransferConfigStateEnum `json:"state,omitempty"`
	// Output only. Data transfer modification time. Ignored by server on input.
	UpdateTime *string `json:"updateTime,omitempty"`
	// Deprecated. Unique ID of the user on whose behalf transfer is done.
	UserID *string `json:"userId,omitempty"`
}
