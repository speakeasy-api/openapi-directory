"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import imageclassificationdatasetmetadata as shared_imageclassificationdatasetmetadata
from ..shared import tablesdatasetmetadata as shared_tablesdatasetmetadata
from ..shared import textclassificationdatasetmetadata as shared_textclassificationdatasetmetadata
from ..shared import textsentimentdatasetmetadata as shared_textsentimentdatasetmetadata
from ..shared import translationdatasetmetadata as shared_translationdatasetmetadata
from dataclasses_json import Undefined, dataclass_json
from sdk import utils
from typing import Any, Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class Dataset:
    r"""A workspace for solving a single, particular machine learning (ML) problem. A workspace contains examples that may be annotated."""
    
    create_time: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('createTime'), 'exclude': lambda f: f is None }})
    r"""Output only. Timestamp when this dataset was created."""  
    description: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('description'), 'exclude': lambda f: f is None }})
    r"""User-provided description of the dataset. The description can be up to 25000 characters long."""  
    display_name: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('displayName'), 'exclude': lambda f: f is None }})
    r"""Required. The name of the dataset to show in the interface. The name can be up to 32 characters long and can consist only of ASCII Latin letters A-Z and a-z, underscores (_), and ASCII digits 0-9."""  
    etag: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('etag'), 'exclude': lambda f: f is None }})
    r"""Used to perform consistent read-modify-write updates. If not set, a blind \\"overwrite\\" update happens."""  
    example_count: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('exampleCount'), 'exclude': lambda f: f is None }})
    r"""Output only. The number of examples in the dataset."""  
    image_classification_dataset_metadata: Optional[shared_imageclassificationdatasetmetadata.ImageClassificationDatasetMetadata] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('imageClassificationDatasetMetadata'), 'exclude': lambda f: f is None }})
    r"""Dataset metadata that is specific to image classification."""  
    image_object_detection_dataset_metadata: Optional[dict[str, Any]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('imageObjectDetectionDatasetMetadata'), 'exclude': lambda f: f is None }})
    r"""Dataset metadata specific to image object detection."""  
    name: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('name'), 'exclude': lambda f: f is None }})
    r"""Output only. The resource name of the dataset. Form: `projects/{project_id}/locations/{location_id}/datasets/{dataset_id}`"""  
    tables_dataset_metadata: Optional[shared_tablesdatasetmetadata.TablesDatasetMetadata] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('tablesDatasetMetadata'), 'exclude': lambda f: f is None }})
    r"""Metadata for a dataset used for AutoML Tables."""  
    text_classification_dataset_metadata: Optional[shared_textclassificationdatasetmetadata.TextClassificationDatasetMetadata] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('textClassificationDatasetMetadata'), 'exclude': lambda f: f is None }})
    r"""Dataset metadata for classification."""  
    text_extraction_dataset_metadata: Optional[dict[str, Any]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('textExtractionDatasetMetadata'), 'exclude': lambda f: f is None }})
    r"""Dataset metadata that is specific to text extraction"""  
    text_sentiment_dataset_metadata: Optional[shared_textsentimentdatasetmetadata.TextSentimentDatasetMetadata] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('textSentimentDatasetMetadata'), 'exclude': lambda f: f is None }})
    r"""Dataset metadata for text sentiment."""  
    translation_dataset_metadata: Optional[shared_translationdatasetmetadata.TranslationDatasetMetadata] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('translationDatasetMetadata'), 'exclude': lambda f: f is None }})
    r"""Dataset metadata that is specific to translation."""  
    video_classification_dataset_metadata: Optional[dict[str, Any]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('videoClassificationDatasetMetadata'), 'exclude': lambda f: f is None }})
    r"""Dataset metadata specific to video classification. All Video Classification datasets are treated as multi label."""  
    video_object_tracking_dataset_metadata: Optional[dict[str, Any]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('videoObjectTrackingDatasetMetadata'), 'exclude': lambda f: f is None }})
    r"""Dataset metadata specific to video object tracking."""  
    