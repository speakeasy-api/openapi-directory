"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import s3bucketcriteriaforjob as shared_s3bucketcriteriaforjob
from ..shared import s3bucketdefinitionforjob as shared_s3bucketdefinitionforjob
from ..shared import scoping as shared_scoping
from dataclasses_json import Undefined, dataclass_json
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class S3JobDefinition:
    r"""Specifies which S3 buckets contain the objects that a classification job analyzes, and the scope of that analysis. The bucket specification can be static (bucketDefinitions) or dynamic (bucketCriteria). If it's static, the job analyzes objects in the same predefined set of buckets each time the job runs. If it's dynamic, the job analyzes objects in any buckets that match the specified criteria each time the job starts to run."""
    
    bucket_criteria: Optional[shared_s3bucketcriteriaforjob.S3BucketCriteriaForJob] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('bucketCriteria'), 'exclude': lambda f: f is None }})  
    bucket_definitions: Optional[list[shared_s3bucketdefinitionforjob.S3BucketDefinitionForJob]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('bucketDefinitions'), 'exclude': lambda f: f is None }})  
    scoping: Optional[shared_scoping.Scoping] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('scoping'), 'exclude': lambda f: f is None }})  
    