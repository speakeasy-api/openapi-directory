/*
 * Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.
 */

import { SpeakeasyBase, SpeakeasyMetadata } from "../../../internal/utils";
import { AggregateClassificationMetrics } from "./aggregateclassificationmetrics";
import { BinaryConfusionMatrix } from "./binaryconfusionmatrix";
import { Expose, Type } from "class-transformer";

/**
 * Evaluation metrics for binary classification/classifier models.
 */
export class BinaryClassificationMetrics extends SpeakeasyBase {
  /**
   * Aggregate metrics for classification/classifier models. For multi-class models, the metrics are either macro-averaged or micro-averaged. When macro-averaged, the metrics are calculated for each label and then an unweighted average is taken of those values. When micro-averaged, the metric is calculated globally by counting the total number of correctly predicted rows.
   */
  @SpeakeasyMetadata()
  @Expose({ name: "aggregateClassificationMetrics" })
  @Type(() => AggregateClassificationMetrics)
  aggregateClassificationMetrics?: AggregateClassificationMetrics;

  /**
   * Binary confusion matrix at multiple thresholds.
   */
  @SpeakeasyMetadata({ elemType: BinaryConfusionMatrix })
  @Expose({ name: "binaryConfusionMatrixList" })
  @Type(() => BinaryConfusionMatrix)
  binaryConfusionMatrixList?: BinaryConfusionMatrix[];

  /**
   * Label representing the negative class.
   */
  @SpeakeasyMetadata()
  @Expose({ name: "negativeLabel" })
  negativeLabel?: string;

  /**
   * Label representing the positive class.
   */
  @SpeakeasyMetadata()
  @Expose({ name: "positiveLabel" })
  positiveLabel?: string;
}
