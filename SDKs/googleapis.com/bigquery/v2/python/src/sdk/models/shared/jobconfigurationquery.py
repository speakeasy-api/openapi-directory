"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import clustering as shared_clustering
from ..shared import connectionproperty as shared_connectionproperty
from ..shared import datasetreference as shared_datasetreference
from ..shared import encryptionconfiguration as shared_encryptionconfiguration
from ..shared import externaldataconfiguration as shared_externaldataconfiguration
from ..shared import queryparameter as shared_queryparameter
from ..shared import rangepartitioning as shared_rangepartitioning
from ..shared import tablereference as shared_tablereference
from ..shared import timepartitioning as shared_timepartitioning
from ..shared import userdefinedfunctionresource as shared_userdefinedfunctionresource
from dataclasses_json import Undefined, dataclass_json
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class JobConfigurationQuery:
    
    allow_large_results: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('allowLargeResults'), 'exclude': lambda f: f is None }})
    r"""[Optional] If true and query uses legacy SQL dialect, allows the query to produce arbitrarily large result tables at a slight cost in performance. Requires destinationTable to be set. For standard SQL queries, this flag is ignored and large results are always allowed. However, you must still set destinationTable when result size exceeds the allowed maximum response size."""  
    clustering: Optional[shared_clustering.Clustering] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('clustering'), 'exclude': lambda f: f is None }})  
    connection_properties: Optional[list[shared_connectionproperty.ConnectionProperty]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('connectionProperties'), 'exclude': lambda f: f is None }})
    r"""Connection properties."""  
    continuous: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('continuous'), 'exclude': lambda f: f is None }})
    r"""[Optional] Specifies whether the query should be executed as a continuous query. The default value is false."""  
    create_disposition: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('createDisposition'), 'exclude': lambda f: f is None }})
    r"""[Optional] Specifies whether the job is allowed to create new tables. The following values are supported: CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table. CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result. The default value is CREATE_IF_NEEDED. Creation, truncation and append actions occur as one atomic update upon job completion."""  
    create_session: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('createSession'), 'exclude': lambda f: f is None }})
    r"""If true, creates a new session, where session id will be a server generated random id. If false, runs query with an existing session_id passed in ConnectionProperty, otherwise runs query in non-session mode."""  
    default_dataset: Optional[shared_datasetreference.DatasetReference] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('defaultDataset'), 'exclude': lambda f: f is None }})  
    destination_encryption_configuration: Optional[shared_encryptionconfiguration.EncryptionConfiguration] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('destinationEncryptionConfiguration'), 'exclude': lambda f: f is None }})  
    destination_table: Optional[shared_tablereference.TableReference] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('destinationTable'), 'exclude': lambda f: f is None }})  
    flatten_results: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('flattenResults'), 'exclude': lambda f: f is None }})
    r"""[Optional] If true and query uses legacy SQL dialect, flattens all nested and repeated fields in the query results. allowLargeResults must be true if this is set to false. For standard SQL queries, this flag is ignored and results are never flattened."""  
    maximum_billing_tier: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('maximumBillingTier'), 'exclude': lambda f: f is None }})
    r"""[Optional] Limits the billing tier for this job. Queries that have resource usage beyond this tier will fail (without incurring a charge). If unspecified, this will be set to your project default."""  
    maximum_bytes_billed: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('maximumBytesBilled'), 'exclude': lambda f: f is None }})
    r"""[Optional] Limits the bytes billed for this job. Queries that will have bytes billed beyond this limit will fail (without incurring a charge). If unspecified, this will be set to your project default."""  
    parameter_mode: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('parameterMode'), 'exclude': lambda f: f is None }})
    r"""Standard SQL only. Set to POSITIONAL to use positional (?) query parameters or to NAMED to use named (@myparam) query parameters in this query."""  
    preserve_nulls: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('preserveNulls'), 'exclude': lambda f: f is None }})
    r"""[Deprecated] This property is deprecated."""  
    priority: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('priority'), 'exclude': lambda f: f is None }})
    r"""[Optional] Specifies a priority for the query. Possible values include INTERACTIVE and BATCH. The default value is INTERACTIVE."""  
    query: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('query'), 'exclude': lambda f: f is None }})
    r"""[Required] SQL query text to execute. The useLegacySql field can be used to indicate whether the query uses legacy SQL or standard SQL."""  
    query_parameters: Optional[list[shared_queryparameter.QueryParameter]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('queryParameters'), 'exclude': lambda f: f is None }})
    r"""Query parameters for standard SQL queries."""  
    range_partitioning: Optional[shared_rangepartitioning.RangePartitioning] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('rangePartitioning'), 'exclude': lambda f: f is None }})  
    schema_update_options: Optional[list[str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('schemaUpdateOptions'), 'exclude': lambda f: f is None }})
    r"""Allows the schema of the destination table to be updated as a side effect of the query job. Schema update options are supported in two cases: when writeDisposition is WRITE_APPEND; when writeDisposition is WRITE_TRUNCATE and the destination table is a partition of a table, specified by partition decorators. For normal tables, WRITE_TRUNCATE will always overwrite the schema. One or more of the following values are specified: ALLOW_FIELD_ADDITION: allow adding a nullable field to the schema. ALLOW_FIELD_RELAXATION: allow relaxing a required field in the original schema to nullable."""  
    table_definitions: Optional[dict[str, shared_externaldataconfiguration.ExternalDataConfiguration]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('tableDefinitions'), 'exclude': lambda f: f is None }})
    r"""[Optional] If querying an external data source outside of BigQuery, describes the data format, location and other properties of the data source. By defining these properties, the data source can then be queried as if it were a standard BigQuery table."""  
    time_partitioning: Optional[shared_timepartitioning.TimePartitioning] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('timePartitioning'), 'exclude': lambda f: f is None }})  
    use_legacy_sql: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('useLegacySql'), 'exclude': lambda f: f is None }})
    r"""Specifies whether to use BigQuery's legacy SQL dialect for this query. The default value is true. If set to false, the query will use BigQuery's standard SQL: https://cloud.google.com/bigquery/sql-reference/ When useLegacySql is set to false, the value of flattenResults is ignored; query will be run as if flattenResults is false."""  
    use_query_cache: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('useQueryCache'), 'exclude': lambda f: f is None }})
    r"""[Optional] Whether to look for the result in the query cache. The query cache is a best-effort cache that will be flushed whenever tables in the query are modified. Moreover, the query cache is only available when a query does not have a destination table specified. The default value is true."""  
    user_defined_function_resources: Optional[list[shared_userdefinedfunctionresource.UserDefinedFunctionResource]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('userDefinedFunctionResources'), 'exclude': lambda f: f is None }})
    r"""Describes user-defined function resources used in the query."""  
    write_disposition: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('writeDisposition'), 'exclude': lambda f: f is None }})
    r"""[Optional] Specifies the action that occurs if the destination table already exists. The following values are supported: WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data and uses the schema from the query result. WRITE_APPEND: If the table already exists, BigQuery appends the data to the table. WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result. The default value is WRITE_EMPTY. Each action is atomic and only occurs if BigQuery is able to complete the job successfully. Creation, truncation and append actions occur as one atomic update upon job completion."""  
    