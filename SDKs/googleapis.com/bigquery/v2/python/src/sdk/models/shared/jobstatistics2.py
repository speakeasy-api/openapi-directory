"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import bienginestatistics as shared_bienginestatistics
from ..shared import bigquerymodeltraining as shared_bigquerymodeltraining
from ..shared import datasetreference as shared_datasetreference
from ..shared import dmlstatistics as shared_dmlstatistics
from ..shared import explainquerystage as shared_explainquerystage
from ..shared import mlstatistics as shared_mlstatistics
from ..shared import queryparameter as shared_queryparameter
from ..shared import querytimelinesample as shared_querytimelinesample
from ..shared import routinereference as shared_routinereference
from ..shared import rowaccesspolicyreference as shared_rowaccesspolicyreference
from ..shared import searchstatistics as shared_searchstatistics
from ..shared import sparkstatistics as shared_sparkstatistics
from ..shared import tablereference as shared_tablereference
from ..shared import tableschema as shared_tableschema
from dataclasses_json import Undefined, dataclass_json
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class JobStatistics2ReservationUsage:
    
    name: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('name'), 'exclude': lambda f: f is None }})
    r"""[Output only] Reservation name or \\"unreserved\\" for on-demand resources usage."""  
    slot_ms: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('slotMs'), 'exclude': lambda f: f is None }})
    r"""[Output only] Slot-milliseconds the job spent in the given reservation."""  
    

@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class JobStatistics2:
    
    bi_engine_statistics: Optional[shared_bienginestatistics.BiEngineStatistics] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('biEngineStatistics'), 'exclude': lambda f: f is None }})  
    billing_tier: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('billingTier'), 'exclude': lambda f: f is None }})
    r"""[Output only] Billing tier for the job."""  
    cache_hit: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('cacheHit'), 'exclude': lambda f: f is None }})
    r"""[Output only] Whether the query result was fetched from the query cache."""  
    ddl_affected_row_access_policy_count: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ddlAffectedRowAccessPolicyCount'), 'exclude': lambda f: f is None }})
    r"""[Output only] [Preview] The number of row access policies affected by a DDL statement. Present only for DROP ALL ROW ACCESS POLICIES queries."""  
    ddl_destination_table: Optional[shared_tablereference.TableReference] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ddlDestinationTable'), 'exclude': lambda f: f is None }})  
    ddl_operation_performed: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ddlOperationPerformed'), 'exclude': lambda f: f is None }})
    r"""The DDL operation performed, possibly dependent on the pre-existence of the DDL target. Possible values (new values might be added in the future): \\"CREATE\\": The query created the DDL target. \\"SKIP\\": No-op. Example cases: the query is CREATE TABLE IF NOT EXISTS while the table already exists, or the query is DROP TABLE IF EXISTS while the table does not exist. \\"REPLACE\\": The query replaced the DDL target. Example case: the query is CREATE OR REPLACE TABLE, and the table already exists. \\"DROP\\": The query deleted the DDL target."""  
    ddl_target_dataset: Optional[shared_datasetreference.DatasetReference] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ddlTargetDataset'), 'exclude': lambda f: f is None }})  
    ddl_target_routine: Optional[shared_routinereference.RoutineReference] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ddlTargetRoutine'), 'exclude': lambda f: f is None }})  
    ddl_target_row_access_policy: Optional[shared_rowaccesspolicyreference.RowAccessPolicyReference] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ddlTargetRowAccessPolicy'), 'exclude': lambda f: f is None }})  
    ddl_target_table: Optional[shared_tablereference.TableReference] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ddlTargetTable'), 'exclude': lambda f: f is None }})  
    dml_stats: Optional[shared_dmlstatistics.DmlStatistics] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('dmlStats'), 'exclude': lambda f: f is None }})  
    estimated_bytes_processed: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('estimatedBytesProcessed'), 'exclude': lambda f: f is None }})
    r"""[Output only] The original estimate of bytes processed for the job."""  
    ml_statistics: Optional[shared_mlstatistics.MlStatistics] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('mlStatistics'), 'exclude': lambda f: f is None }})  
    model_training: Optional[shared_bigquerymodeltraining.BigQueryModelTraining] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('modelTraining'), 'exclude': lambda f: f is None }})  
    model_training_current_iteration: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('modelTrainingCurrentIteration'), 'exclude': lambda f: f is None }})
    r"""[Output only, Beta] Deprecated; do not use."""  
    model_training_expected_total_iteration: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('modelTrainingExpectedTotalIteration'), 'exclude': lambda f: f is None }})
    r"""[Output only, Beta] Deprecated; do not use."""  
    num_dml_affected_rows: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('numDmlAffectedRows'), 'exclude': lambda f: f is None }})
    r"""[Output only] The number of rows affected by a DML statement. Present only for DML statements INSERT, UPDATE or DELETE."""  
    query_plan: Optional[list[shared_explainquerystage.ExplainQueryStage]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('queryPlan'), 'exclude': lambda f: f is None }})
    r"""[Output only] Describes execution plan for the query."""  
    referenced_routines: Optional[list[shared_routinereference.RoutineReference]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('referencedRoutines'), 'exclude': lambda f: f is None }})
    r"""[Output only] Referenced routines (persistent user-defined functions and stored procedures) for the job."""  
    referenced_tables: Optional[list[shared_tablereference.TableReference]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('referencedTables'), 'exclude': lambda f: f is None }})
    r"""[Output only] Referenced tables for the job. Queries that reference more than 50 tables will not have a complete list."""  
    reservation_usage: Optional[list[JobStatistics2ReservationUsage]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('reservationUsage'), 'exclude': lambda f: f is None }})
    r"""[Output only] Job resource usage breakdown by reservation."""  
    schema: Optional[shared_tableschema.TableSchema] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('schema'), 'exclude': lambda f: f is None }})  
    search_statistics: Optional[shared_searchstatistics.SearchStatistics] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('searchStatistics'), 'exclude': lambda f: f is None }})  
    spark_statistics: Optional[shared_sparkstatistics.SparkStatistics] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('sparkStatistics'), 'exclude': lambda f: f is None }})  
    statement_type: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('statementType'), 'exclude': lambda f: f is None }})
    r"""The type of query statement, if valid. Possible values (new values might be added in the future): \\"SELECT\\": SELECT query. \\"INSERT\\": INSERT query; see https://cloud.google.com/bigquery/docs/reference/standard-sql/data-manipulation-language. \\"UPDATE\\": UPDATE query; see https://cloud.google.com/bigquery/docs/reference/standard-sql/data-manipulation-language. \\"DELETE\\": DELETE query; see https://cloud.google.com/bigquery/docs/reference/standard-sql/data-manipulation-language. \\"MERGE\\": MERGE query; see https://cloud.google.com/bigquery/docs/reference/standard-sql/data-manipulation-language. \\"ALTER_TABLE\\": ALTER TABLE query. \\"ALTER_VIEW\\": ALTER VIEW query. \\"ASSERT\\": ASSERT condition AS 'description'. \\"CREATE_FUNCTION\\": CREATE FUNCTION query. \\"CREATE_MODEL\\": CREATE [OR REPLACE] MODEL ... AS SELECT ... . \\"CREATE_PROCEDURE\\": CREATE PROCEDURE query. \\"CREATE_TABLE\\": CREATE [OR REPLACE] TABLE without AS SELECT. \\"CREATE_TABLE_AS_SELECT\\": CREATE [OR REPLACE] TABLE ... AS SELECT ... . \\"CREATE_VIEW\\": CREATE [OR REPLACE] VIEW ... AS SELECT ... . \\"DROP_FUNCTION\\" : DROP FUNCTION query. \\"DROP_PROCEDURE\\": DROP PROCEDURE query. \\"DROP_TABLE\\": DROP TABLE query. \\"DROP_VIEW\\": DROP VIEW query."""  
    timeline: Optional[list[shared_querytimelinesample.QueryTimelineSample]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('timeline'), 'exclude': lambda f: f is None }})
    r"""[Output only] [Beta] Describes a timeline of job execution."""  
    total_bytes_billed: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('totalBytesBilled'), 'exclude': lambda f: f is None }})
    r"""[Output only] Total bytes billed for the job."""  
    total_bytes_processed: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('totalBytesProcessed'), 'exclude': lambda f: f is None }})
    r"""[Output only] Total bytes processed for the job."""  
    total_bytes_processed_accuracy: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('totalBytesProcessedAccuracy'), 'exclude': lambda f: f is None }})
    r"""[Output only] For dry-run jobs, totalBytesProcessed is an estimate and this field specifies the accuracy of the estimate. Possible values can be: UNKNOWN: accuracy of the estimate is unknown. PRECISE: estimate is precise. LOWER_BOUND: estimate is lower bound of what the query would cost. UPPER_BOUND: estimate is upper bound of what the query would cost."""  
    total_partitions_processed: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('totalPartitionsProcessed'), 'exclude': lambda f: f is None }})
    r"""[Output only] Total number of partitions processed from all partitioned tables referenced in the job."""  
    total_slot_ms: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('totalSlotMs'), 'exclude': lambda f: f is None }})
    r"""[Output only] Slot-milliseconds for the job."""  
    transferred_bytes: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('transferredBytes'), 'exclude': lambda f: f is None }})
    r"""[Output-only] Total bytes transferred for cross-cloud queries such as Cross Cloud Transfer and CREATE TABLE AS SELECT (CTAS)."""  
    undeclared_query_parameters: Optional[list[shared_queryparameter.QueryParameter]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('undeclaredQueryParameters'), 'exclude': lambda f: f is None }})
    r"""Standard SQL only: list of undeclared query parameters detected during a dry run validation."""  
    