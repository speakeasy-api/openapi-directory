"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
import dateutil.parser
from ..shared import categoricalvalues as shared_categoricalvalues
from ..shared import countpercent as shared_countpercent
from ..shared import largetimestampgaps as shared_largetimestampgaps
from ..shared import monotonicvalues as shared_monotonicvalues
from ..shared import multipleoperatingmodes as shared_multipleoperatingmodes
from dataclasses_json import Undefined, dataclass_json
from datetime import datetime
from marshmallow import fields
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class SensorStatisticsSummary:
    r"""Summary of ingestion statistics like whether data exists, number of missing values, number of invalid values and so on related to the particular sensor."""
    
    categorical_values: Optional[shared_categoricalvalues.CategoricalValues] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('CategoricalValues'), 'exclude': lambda f: f is None }})  
    component_name: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ComponentName'), 'exclude': lambda f: f is None }})  
    data_end_time: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('DataEndTime'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})  
    data_exists: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('DataExists'), 'exclude': lambda f: f is None }})  
    data_start_time: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('DataStartTime'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})  
    duplicate_timestamps: Optional[shared_countpercent.CountPercent] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('DuplicateTimestamps'), 'exclude': lambda f: f is None }})  
    invalid_date_entries: Optional[shared_countpercent.CountPercent] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('InvalidDateEntries'), 'exclude': lambda f: f is None }})  
    invalid_values: Optional[shared_countpercent.CountPercent] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('InvalidValues'), 'exclude': lambda f: f is None }})  
    large_timestamp_gaps: Optional[shared_largetimestampgaps.LargeTimestampGaps] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('LargeTimestampGaps'), 'exclude': lambda f: f is None }})  
    missing_values: Optional[shared_countpercent.CountPercent] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('MissingValues'), 'exclude': lambda f: f is None }})  
    monotonic_values: Optional[shared_monotonicvalues.MonotonicValues] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('MonotonicValues'), 'exclude': lambda f: f is None }})  
    multiple_operating_modes: Optional[shared_multipleoperatingmodes.MultipleOperatingModes] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('MultipleOperatingModes'), 'exclude': lambda f: f is None }})  
    sensor_name: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('SensorName'), 'exclude': lambda f: f is None }})  
    