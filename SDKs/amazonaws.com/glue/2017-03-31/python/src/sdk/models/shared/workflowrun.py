"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
import dateutil.parser
from ..shared import startingeventbatchcondition as shared_startingeventbatchcondition
from ..shared import workflowgraph as shared_workflowgraph
from ..shared import workflowrunstatistics as shared_workflowrunstatistics
from ..shared import workflowrunstatus_enum as shared_workflowrunstatus_enum
from dataclasses_json import Undefined, dataclass_json
from datetime import datetime
from marshmallow import fields
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class WorkflowRun:
    r"""A workflow run is an execution of a workflow providing all the runtime information."""
    
    completed_on: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('CompletedOn'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})  
    error_message: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ErrorMessage'), 'exclude': lambda f: f is None }})  
    graph: Optional[shared_workflowgraph.WorkflowGraph] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('Graph'), 'exclude': lambda f: f is None }})  
    name: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('Name'), 'exclude': lambda f: f is None }})  
    previous_run_id: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('PreviousRunId'), 'exclude': lambda f: f is None }})  
    started_on: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('StartedOn'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})  
    starting_event_batch_condition: Optional[shared_startingeventbatchcondition.StartingEventBatchCondition] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('StartingEventBatchCondition'), 'exclude': lambda f: f is None }})  
    statistics: Optional[shared_workflowrunstatistics.WorkflowRunStatistics] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('Statistics'), 'exclude': lambda f: f is None }})  
    status: Optional[shared_workflowrunstatus_enum.WorkflowRunStatusEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('Status'), 'exclude': lambda f: f is None }})  
    workflow_run_id: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('WorkflowRunId'), 'exclude': lambda f: f is None }})  
    workflow_run_properties: Optional[dict[str, str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('WorkflowRunProperties'), 'exclude': lambda f: f is None }})  
    