"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import exportablelambdafunctionfield_enum as shared_exportablelambdafunctionfield_enum
from ..shared import fileformat_enum as shared_fileformat_enum
from ..shared import lambdafunctionrecommendationfilter as shared_lambdafunctionrecommendationfilter
from ..shared import s3destinationconfig as shared_s3destinationconfig
from dataclasses_json import Undefined, dataclass_json
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class ExportLambdaFunctionRecommendationsRequest:
    
    s3_destination_config: shared_s3destinationconfig.S3DestinationConfig = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('s3DestinationConfig') }})
    r"""<p>Describes the destination Amazon Simple Storage Service (Amazon S3) bucket name and key prefix for a recommendations export job.</p> <p>You must create the destination Amazon S3 bucket for your recommendations export before you create the export job. Compute Optimizer does not create the S3 bucket for you. After you create the S3 bucket, ensure that it has the required permission policy to allow Compute Optimizer to write the export file to it. If you plan to specify an object prefix when you create the export job, you must include the object prefix in the policy that you add to the S3 bucket. For more information, see <a href=\\"https://docs.aws.amazon.com/compute-optimizer/latest/ug/create-s3-bucket-policy-for-compute-optimizer.html\\">Amazon S3 Bucket Policy for Compute Optimizer</a> in the <i>Compute Optimizer User Guide</i>.</p>"""  
    account_ids: Optional[list[str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('accountIds'), 'exclude': lambda f: f is None }})  
    fields_to_export: Optional[list[shared_exportablelambdafunctionfield_enum.ExportableLambdaFunctionFieldEnum]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('fieldsToExport'), 'exclude': lambda f: f is None }})  
    file_format: Optional[shared_fileformat_enum.FileFormatEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('fileFormat'), 'exclude': lambda f: f is None }})  
    filters: Optional[list[shared_lambdafunctionrecommendationfilter.LambdaFunctionRecommendationFilter]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('filters'), 'exclude': lambda f: f is None }})  
    include_member_accounts: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('includeMemberAccounts'), 'exclude': lambda f: f is None }})  
    