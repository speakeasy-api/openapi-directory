// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
)

// GoogleCloudMlV1AcceleratorConfigTypeEnum - The type of accelerator to use.
type GoogleCloudMlV1AcceleratorConfigTypeEnum string

const (
	GoogleCloudMlV1AcceleratorConfigTypeEnumAcceleratorTypeUnspecified GoogleCloudMlV1AcceleratorConfigTypeEnum = "ACCELERATOR_TYPE_UNSPECIFIED"
	GoogleCloudMlV1AcceleratorConfigTypeEnumNvidiaTeslaK80             GoogleCloudMlV1AcceleratorConfigTypeEnum = "NVIDIA_TESLA_K80"
	GoogleCloudMlV1AcceleratorConfigTypeEnumNvidiaTeslaP100            GoogleCloudMlV1AcceleratorConfigTypeEnum = "NVIDIA_TESLA_P100"
	GoogleCloudMlV1AcceleratorConfigTypeEnumNvidiaTeslaV100            GoogleCloudMlV1AcceleratorConfigTypeEnum = "NVIDIA_TESLA_V100"
	GoogleCloudMlV1AcceleratorConfigTypeEnumNvidiaTeslaP4              GoogleCloudMlV1AcceleratorConfigTypeEnum = "NVIDIA_TESLA_P4"
	GoogleCloudMlV1AcceleratorConfigTypeEnumNvidiaTeslaT4              GoogleCloudMlV1AcceleratorConfigTypeEnum = "NVIDIA_TESLA_T4"
	GoogleCloudMlV1AcceleratorConfigTypeEnumNvidiaTeslaA100            GoogleCloudMlV1AcceleratorConfigTypeEnum = "NVIDIA_TESLA_A100"
	GoogleCloudMlV1AcceleratorConfigTypeEnumTpuV2                      GoogleCloudMlV1AcceleratorConfigTypeEnum = "TPU_V2"
	GoogleCloudMlV1AcceleratorConfigTypeEnumTpuV3                      GoogleCloudMlV1AcceleratorConfigTypeEnum = "TPU_V3"
	GoogleCloudMlV1AcceleratorConfigTypeEnumTpuV4                      GoogleCloudMlV1AcceleratorConfigTypeEnum = "TPU_V4"
	GoogleCloudMlV1AcceleratorConfigTypeEnumTpuV2Pod                   GoogleCloudMlV1AcceleratorConfigTypeEnum = "TPU_V2_POD"
	GoogleCloudMlV1AcceleratorConfigTypeEnumTpuV3Pod                   GoogleCloudMlV1AcceleratorConfigTypeEnum = "TPU_V3_POD"
)

func (e *GoogleCloudMlV1AcceleratorConfigTypeEnum) UnmarshalJSON(data []byte) error {
	var s string
	if err := json.Unmarshal(data, &s); err != nil {
		return err
	}
	switch s {
	case "ACCELERATOR_TYPE_UNSPECIFIED":
		fallthrough
	case "NVIDIA_TESLA_K80":
		fallthrough
	case "NVIDIA_TESLA_P100":
		fallthrough
	case "NVIDIA_TESLA_V100":
		fallthrough
	case "NVIDIA_TESLA_P4":
		fallthrough
	case "NVIDIA_TESLA_T4":
		fallthrough
	case "NVIDIA_TESLA_A100":
		fallthrough
	case "TPU_V2":
		fallthrough
	case "TPU_V3":
		fallthrough
	case "TPU_V4":
		fallthrough
	case "TPU_V2_POD":
		fallthrough
	case "TPU_V3_POD":
		*e = GoogleCloudMlV1AcceleratorConfigTypeEnum(s)
		return nil
	default:
		return fmt.Errorf("invalid value for GoogleCloudMlV1AcceleratorConfigTypeEnum: %s", s)
	}
}

// GoogleCloudMlV1AcceleratorConfig - Represents a hardware accelerator request config. Note that the AcceleratorConfig can be used in both Jobs and Versions. Learn more about [accelerators for training](/ml-engine/docs/using-gpus) and [accelerators for online prediction](/ml-engine/docs/machine-types-online-prediction#gpus).
type GoogleCloudMlV1AcceleratorConfig struct {
	// The number of accelerators to attach to each machine running the job.
	Count *string `json:"count,omitempty"`
	// The type of accelerator to use.
	Type *GoogleCloudMlV1AcceleratorConfigTypeEnum `json:"type,omitempty"`
}
