// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

// EvaluationMetrics - Evaluation metrics of a model. These are either computed on all training data or just the eval data based on whether eval data was used during training. These are not present for imported models.
type EvaluationMetrics struct {
	// Model evaluation metrics for ARIMA forecasting models.
	ArimaForecastingMetrics *ArimaForecastingMetrics `json:"arimaForecastingMetrics,omitempty"`
	// Evaluation metrics for binary classification/classifier models.
	BinaryClassificationMetrics *BinaryClassificationMetrics `json:"binaryClassificationMetrics,omitempty"`
	// Evaluation metrics for clustering models.
	ClusteringMetrics *ClusteringMetrics `json:"clusteringMetrics,omitempty"`
	// Model evaluation metrics for dimensionality reduction models.
	DimensionalityReductionMetrics *DimensionalityReductionMetrics `json:"dimensionalityReductionMetrics,omitempty"`
	// Evaluation metrics for multi-class classification/classifier models.
	MultiClassClassificationMetrics *MultiClassClassificationMetrics `json:"multiClassClassificationMetrics,omitempty"`
	// Evaluation metrics used by weighted-ALS models specified by feedback_type=implicit.
	RankingMetrics *RankingMetrics `json:"rankingMetrics,omitempty"`
	// Evaluation metrics for regression and explicit feedback type matrix factorization models.
	RegressionMetrics *RegressionMetrics `json:"regressionMetrics,omitempty"`
}
