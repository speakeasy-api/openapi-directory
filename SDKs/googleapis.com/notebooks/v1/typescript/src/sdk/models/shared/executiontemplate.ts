/*
 * Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.
 */

import { SpeakeasyBase, SpeakeasyMetadata } from "../../../internal/utils";
import { DataprocParameters } from "./dataprocparameters";
import { SchedulerAcceleratorConfig } from "./scheduleracceleratorconfig";
import { VertexAIParameters } from "./vertexaiparameters";
import { Expose, Type } from "class-transformer";

/**
 * The type of Job to be used on this execution.
 */
export enum ExecutionTemplateJobTypeEnum {
  JobTypeUnspecified = "JOB_TYPE_UNSPECIFIED",
  VertexAi = "VERTEX_AI",
  Dataproc = "DATAPROC",
}

/**
 * Required. Scale tier of the hardware used for notebook execution. DEPRECATED Will be discontinued. As right now only CUSTOM is supported.
 */
export enum ExecutionTemplateScaleTierEnum {
  ScaleTierUnspecified = "SCALE_TIER_UNSPECIFIED",
  Basic = "BASIC",
  Standard1 = "STANDARD_1",
  Premium1 = "PREMIUM_1",
  BasicGpu = "BASIC_GPU",
  BasicTpu = "BASIC_TPU",
  Custom = "CUSTOM",
}

/**
 * The description a notebook execution workload.
 */
export class ExecutionTemplate extends SpeakeasyBase {
  /**
   * Definition of a hardware accelerator. Note that not all combinations of `type` and `core_count` are valid. Check [GPUs on Compute Engine](https://cloud.google.com/compute/docs/gpus) to find a valid combination. TPUs are not supported.
   */
  @SpeakeasyMetadata()
  @Expose({ name: "acceleratorConfig" })
  @Type(() => SchedulerAcceleratorConfig)
  acceleratorConfig?: SchedulerAcceleratorConfig;

  /**
   * Container Image URI to a DLVM Example: 'gcr.io/deeplearning-platform-release/base-cu100' More examples can be found at: https://cloud.google.com/ai-platform/deep-learning-containers/docs/choosing-container
   */
  @SpeakeasyMetadata()
  @Expose({ name: "containerImageUri" })
  containerImageUri?: string;

  /**
   * Parameters used in Dataproc JobType executions.
   */
  @SpeakeasyMetadata()
  @Expose({ name: "dataprocParameters" })
  @Type(() => DataprocParameters)
  dataprocParameters?: DataprocParameters;

  /**
   * Path to the notebook file to execute. Must be in a Google Cloud Storage bucket. Format: `gs://{bucket_name}/{folder}/{notebook_file_name}` Ex: `gs://notebook_user/scheduled_notebooks/sentiment_notebook.ipynb`
   */
  @SpeakeasyMetadata()
  @Expose({ name: "inputNotebookFile" })
  inputNotebookFile?: string;

  /**
   * The type of Job to be used on this execution.
   */
  @SpeakeasyMetadata()
  @Expose({ name: "jobType" })
  jobType?: ExecutionTemplateJobTypeEnum;

  /**
   * Name of the kernel spec to use. This must be specified if the kernel spec name on the execution target does not match the name in the input notebook file.
   */
  @SpeakeasyMetadata()
  @Expose({ name: "kernelSpec" })
  kernelSpec?: string;

  /**
   * Labels for execution. If execution is scheduled, a field included will be 'nbs-scheduled'. Otherwise, it is an immediate execution, and an included field will be 'nbs-immediate'. Use fields to efficiently index between various types of executions.
   */
  @SpeakeasyMetadata()
  @Expose({ name: "labels" })
  labels?: Record<string, string>;

  /**
   * Specifies the type of virtual machine to use for your training job's master worker. You must specify this field when `scaleTier` is set to `CUSTOM`. You can use certain Compute Engine machine types directly in this field. The following types are supported: - `n1-standard-4` - `n1-standard-8` - `n1-standard-16` - `n1-standard-32` - `n1-standard-64` - `n1-standard-96` - `n1-highmem-2` - `n1-highmem-4` - `n1-highmem-8` - `n1-highmem-16` - `n1-highmem-32` - `n1-highmem-64` - `n1-highmem-96` - `n1-highcpu-16` - `n1-highcpu-32` - `n1-highcpu-64` - `n1-highcpu-96` Alternatively, you can use the following legacy machine types: - `standard` - `large_model` - `complex_model_s` - `complex_model_m` - `complex_model_l` - `standard_gpu` - `complex_model_m_gpu` - `complex_model_l_gpu` - `standard_p100` - `complex_model_m_p100` - `standard_v100` - `large_model_v100` - `complex_model_m_v100` - `complex_model_l_v100` Finally, if you want to use a TPU for training, specify `cloud_tpu` in this field. Learn more about the [special configuration options for training with TPU](https://cloud.google.com/ai-platform/training/docs/using-tpus#configuring_a_custom_tpu_machine).
   */
  @SpeakeasyMetadata()
  @Expose({ name: "masterType" })
  masterType?: string;

  /**
   * Path to the notebook folder to write to. Must be in a Google Cloud Storage bucket path. Format: `gs://{bucket_name}/{folder}` Ex: `gs://notebook_user/scheduled_notebooks`
   */
  @SpeakeasyMetadata()
  @Expose({ name: "outputNotebookFolder" })
  outputNotebookFolder?: string;

  /**
   * Parameters used within the 'input_notebook_file' notebook.
   */
  @SpeakeasyMetadata()
  @Expose({ name: "parameters" })
  parameters?: string;

  /**
   * Parameters to be overridden in the notebook during execution. Ref https://papermill.readthedocs.io/en/latest/usage-parameterize.html on how to specifying parameters in the input notebook and pass them here in an YAML file. Ex: `gs://notebook_user/scheduled_notebooks/sentiment_notebook_params.yaml`
   */
  @SpeakeasyMetadata()
  @Expose({ name: "paramsYamlFile" })
  paramsYamlFile?: string;

  /**
   * Required. Scale tier of the hardware used for notebook execution. DEPRECATED Will be discontinued. As right now only CUSTOM is supported.
   */
  @SpeakeasyMetadata()
  @Expose({ name: "scaleTier" })
  scaleTier?: ExecutionTemplateScaleTierEnum;

  /**
   * The email address of a service account to use when running the execution. You must have the `iam.serviceAccounts.actAs` permission for the specified service account.
   */
  @SpeakeasyMetadata()
  @Expose({ name: "serviceAccount" })
  serviceAccount?: string;

  /**
   * The name of a Vertex AI [Tensorboard] resource to which this execution will upload Tensorboard logs. Format: `projects/{project}/locations/{location}/tensorboards/{tensorboard}`
   */
  @SpeakeasyMetadata()
  @Expose({ name: "tensorboard" })
  tensorboard?: string;

  /**
   * Parameters used in Vertex AI JobType executions.
   */
  @SpeakeasyMetadata()
  @Expose({ name: "vertexAiParameters" })
  @Type(() => VertexAIParameters)
  vertexAiParameters?: VertexAIParameters;
}
