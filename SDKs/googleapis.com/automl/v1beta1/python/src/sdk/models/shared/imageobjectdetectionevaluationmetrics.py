"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import boundingboxmetricsentry as shared_boundingboxmetricsentry
from dataclasses_json import Undefined, dataclass_json
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class ImageObjectDetectionEvaluationMetrics:
    r"""Model evaluation metrics for image object detection problems. Evaluates prediction quality of labeled bounding boxes."""
    
    bounding_box_mean_average_precision: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('boundingBoxMeanAveragePrecision'), 'exclude': lambda f: f is None }})
    r"""Output only. The single metric for bounding boxes evaluation: the mean_average_precision averaged over all bounding_box_metrics_entries."""  
    bounding_box_metrics_entries: Optional[list[shared_boundingboxmetricsentry.BoundingBoxMetricsEntry]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('boundingBoxMetricsEntries'), 'exclude': lambda f: f is None }})
    r"""Output only. The bounding boxes match metrics for each Intersection-over-union threshold 0.05,0.10,...,0.95,0.96,0.97,0.98,0.99 and each label confidence threshold 0.05,0.10,...,0.95,0.96,0.97,0.98,0.99 pair."""  
    evaluated_bounding_box_count: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('evaluatedBoundingBoxCount'), 'exclude': lambda f: f is None }})
    r"""Output only. The total number of bounding boxes (i.e. summed over all images) the ground truth used to create this evaluation had."""  
    