"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import jobdriver as shared_jobdriver
from ..shared import parametricconfigurationoverrides as shared_parametricconfigurationoverrides
from ..shared import templateparameterconfiguration as shared_templateparameterconfiguration
from dataclasses_json import Undefined, dataclass_json
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class JobTemplateData:
    r"""The values of StartJobRun API requests used in job runs started using the job template."""
    
    execution_role_arn: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('executionRoleArn') }})  
    job_driver: shared_jobdriver.JobDriver = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('jobDriver') }})
    r"""Specify the driver that the job runs on. Exactly one of the two available job drivers is required, either sparkSqlJobDriver or sparkSubmitJobDriver."""  
    release_label: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('releaseLabel') }})  
    configuration_overrides: Optional[shared_parametricconfigurationoverrides.ParametricConfigurationOverrides] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('configurationOverrides'), 'exclude': lambda f: f is None }})  
    job_tags: Optional[dict[str, str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('jobTags'), 'exclude': lambda f: f is None }})  
    parameter_configuration: Optional[dict[str, shared_templateparameterconfiguration.TemplateParameterConfiguration]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('parameterConfiguration'), 'exclude': lambda f: f is None }})  
    