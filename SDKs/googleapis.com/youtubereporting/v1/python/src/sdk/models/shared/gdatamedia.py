"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import gdatablobstore2info as shared_gdatablobstore2info
from ..shared import gdatacompositemedia as shared_gdatacompositemedia
from ..shared import gdatacontenttypeinfo as shared_gdatacontenttypeinfo
from ..shared import gdatadiffchecksumsresponse as shared_gdatadiffchecksumsresponse
from ..shared import gdatadiffdownloadresponse as shared_gdatadiffdownloadresponse
from ..shared import gdatadiffuploadrequest as shared_gdatadiffuploadrequest
from ..shared import gdatadiffuploadresponse as shared_gdatadiffuploadresponse
from ..shared import gdatadiffversionresponse as shared_gdatadiffversionresponse
from ..shared import gdatadownloadparameters as shared_gdatadownloadparameters
from ..shared import gdataobjectid as shared_gdataobjectid
from dataclasses_json import Undefined, dataclass_json
from enum import Enum
from sdk import utils
from typing import Optional

class GdataMediaReferenceTypeEnum(str, Enum):
    r"""gdata"""
    PATH = 'PATH'
    BLOB_REF = 'BLOB_REF'
    INLINE = 'INLINE'
    GET_MEDIA = 'GET_MEDIA'
    COMPOSITE_MEDIA = 'COMPOSITE_MEDIA'
    BIGSTORE_REF = 'BIGSTORE_REF'
    DIFF_VERSION_RESPONSE = 'DIFF_VERSION_RESPONSE'
    DIFF_CHECKSUMS_RESPONSE = 'DIFF_CHECKSUMS_RESPONSE'
    DIFF_DOWNLOAD_RESPONSE = 'DIFF_DOWNLOAD_RESPONSE'
    DIFF_UPLOAD_REQUEST = 'DIFF_UPLOAD_REQUEST'
    DIFF_UPLOAD_RESPONSE = 'DIFF_UPLOAD_RESPONSE'
    COSMO_BINARY_REFERENCE = 'COSMO_BINARY_REFERENCE'
    ARBITRARY_BYTES = 'ARBITRARY_BYTES'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class GdataMedia:
    r"""gdata"""
    
    algorithm: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('algorithm'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    bigstore_object_ref: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('bigstoreObjectRef'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    blob_ref: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('blobRef'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    blobstore2_info: Optional[shared_gdatablobstore2info.GdataBlobstore2Info] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('blobstore2Info'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    composite_media: Optional[list[shared_gdatacompositemedia.GdataCompositeMedia]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('compositeMedia'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    content_type: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('contentType'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    content_type_info: Optional[shared_gdatacontenttypeinfo.GdataContentTypeInfo] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('contentTypeInfo'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    cosmo_binary_reference: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('cosmoBinaryReference'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    crc32c_hash: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('crc32cHash'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    diff_checksums_response: Optional[shared_gdatadiffchecksumsresponse.GdataDiffChecksumsResponse] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('diffChecksumsResponse'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    diff_download_response: Optional[shared_gdatadiffdownloadresponse.GdataDiffDownloadResponse] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('diffDownloadResponse'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    diff_upload_request: Optional[shared_gdatadiffuploadrequest.GdataDiffUploadRequest] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('diffUploadRequest'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    diff_upload_response: Optional[shared_gdatadiffuploadresponse.GdataDiffUploadResponse] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('diffUploadResponse'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    diff_version_response: Optional[shared_gdatadiffversionresponse.GdataDiffVersionResponse] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('diffVersionResponse'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    download_parameters: Optional[shared_gdatadownloadparameters.GdataDownloadParameters] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('downloadParameters'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    filename: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('filename'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    hash: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('hash'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    hash_verified: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('hashVerified'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    inline: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('inline'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    is_potential_retry: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('isPotentialRetry'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    length: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('length'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    md5_hash: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('md5Hash'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    media_id: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('mediaId'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    object_id: Optional[shared_gdataobjectid.GdataObjectID] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('objectId'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    path: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('path'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    reference_type: Optional[GdataMediaReferenceTypeEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('referenceType'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    sha1_hash: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('sha1Hash'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    sha256_hash: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('sha256Hash'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    timestamp: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('timestamp'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    token: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('token'), 'exclude': lambda f: f is None }})
    r"""gdata"""  
    