"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import diskencryptionconfiguration as shared_diskencryptionconfiguration
from ..shared import diskencryptionstatus as shared_diskencryptionstatus
from ..shared import operationerror as shared_operationerror
from dataclasses_json import Undefined, dataclass_json
from enum import Enum
from sdk import utils
from typing import Optional

class BackupRunBackupKindEnum(str, Enum):
    r"""Specifies the kind of backup, PHYSICAL or DEFAULT_SNAPSHOT."""
    SQL_BACKUP_KIND_UNSPECIFIED = 'SQL_BACKUP_KIND_UNSPECIFIED'
    SNAPSHOT = 'SNAPSHOT'
    PHYSICAL = 'PHYSICAL'

class BackupRunStatusEnum(str, Enum):
    r"""The status of this run."""
    SQL_BACKUP_RUN_STATUS_UNSPECIFIED = 'SQL_BACKUP_RUN_STATUS_UNSPECIFIED'
    ENQUEUED = 'ENQUEUED'
    OVERDUE = 'OVERDUE'
    RUNNING = 'RUNNING'
    FAILED = 'FAILED'
    SUCCESSFUL = 'SUCCESSFUL'
    SKIPPED = 'SKIPPED'
    DELETION_PENDING = 'DELETION_PENDING'
    DELETION_FAILED = 'DELETION_FAILED'
    DELETED = 'DELETED'

class BackupRunTypeEnum(str, Enum):
    r"""The type of this run; can be either \\"AUTOMATED\\" or \\"ON_DEMAND\\" or \\"FINAL\\". This field defaults to \\"ON_DEMAND\\" and is ignored, when specified for insert requests."""
    SQL_BACKUP_RUN_TYPE_UNSPECIFIED = 'SQL_BACKUP_RUN_TYPE_UNSPECIFIED'
    AUTOMATED = 'AUTOMATED'
    ON_DEMAND = 'ON_DEMAND'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class BackupRun:
    r"""A BackupRun resource."""
    
    backup_kind: Optional[BackupRunBackupKindEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('backupKind'), 'exclude': lambda f: f is None }})
    r"""Specifies the kind of backup, PHYSICAL or DEFAULT_SNAPSHOT."""  
    description: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('description'), 'exclude': lambda f: f is None }})
    r"""The description of this run, only applicable to on-demand backups."""  
    disk_encryption_configuration: Optional[shared_diskencryptionconfiguration.DiskEncryptionConfiguration] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('diskEncryptionConfiguration'), 'exclude': lambda f: f is None }})
    r"""Disk encryption configuration for an instance."""  
    disk_encryption_status: Optional[shared_diskencryptionstatus.DiskEncryptionStatus] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('diskEncryptionStatus'), 'exclude': lambda f: f is None }})
    r"""Disk encryption status for an instance."""  
    end_time: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('endTime'), 'exclude': lambda f: f is None }})
    r"""The time the backup operation completed in UTC timezone in [RFC 3339](https://tools.ietf.org/html/rfc3339) format, for example `2012-11-15T16:19:00.094Z`."""  
    enqueued_time: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('enqueuedTime'), 'exclude': lambda f: f is None }})
    r"""The time the run was enqueued in UTC timezone in [RFC 3339](https://tools.ietf.org/html/rfc3339) format, for example `2012-11-15T16:19:00.094Z`."""  
    error: Optional[shared_operationerror.OperationError] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('error'), 'exclude': lambda f: f is None }})
    r"""Database instance operation error."""  
    id: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('id'), 'exclude': lambda f: f is None }})
    r"""The identifier for this backup run. Unique only for a specific Cloud SQL instance."""  
    instance: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('instance'), 'exclude': lambda f: f is None }})
    r"""Name of the database instance."""  
    kind: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('kind'), 'exclude': lambda f: f is None }})
    r"""This is always `sql#backupRun`."""  
    location: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('location'), 'exclude': lambda f: f is None }})
    r"""Location of the backups."""  
    self_link: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('selfLink'), 'exclude': lambda f: f is None }})
    r"""The URI of this resource."""  
    start_time: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('startTime'), 'exclude': lambda f: f is None }})
    r"""The time the backup operation actually started in UTC timezone in [RFC 3339](https://tools.ietf.org/html/rfc3339) format, for example `2012-11-15T16:19:00.094Z`."""  
    status: Optional[BackupRunStatusEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('status'), 'exclude': lambda f: f is None }})
    r"""The status of this run."""  
    time_zone: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('timeZone'), 'exclude': lambda f: f is None }})
    r"""Backup time zone to prevent restores to an instance with a different time zone. Now relevant only for SQL Server."""  
    type: Optional[BackupRunTypeEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('type'), 'exclude': lambda f: f is None }})
    r"""The type of this run; can be either \\"AUTOMATED\\" or \\"ON_DEMAND\\" or \\"FINAL\\". This field defaults to \\"ON_DEMAND\\" and is ignored, when specified for insert requests."""  
    window_start_time: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('windowStartTime'), 'exclude': lambda f: f is None }})
    r"""The start time of the backup window during which this the backup was attempted in [RFC 3339](https://tools.ietf.org/html/rfc3339) format, for example `2012-11-15T16:19:00.094Z`."""  
    