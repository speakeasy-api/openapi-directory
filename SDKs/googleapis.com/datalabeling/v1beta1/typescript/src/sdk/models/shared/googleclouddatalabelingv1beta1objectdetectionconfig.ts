/*
 * Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.
 */

import { SpeakeasyBase, SpeakeasyMetadata } from "../../../internal/utils";
import { Expose } from "class-transformer";

/**
 * Config for video object detection human labeling task. Object detection will be conducted on the images extracted from the video, and those objects will be labeled with bounding boxes. User need to specify the number of images to be extracted per second as the extraction frame rate.
 */
export class GoogleCloudDatalabelingV1beta1ObjectDetectionConfig extends SpeakeasyBase {
  /**
   * Required. Annotation spec set resource name.
   */
  @SpeakeasyMetadata()
  @Expose({ name: "annotationSpecSet" })
  annotationSpecSet?: string;

  /**
   * Required. Number of frames per second to be extracted from the video.
   */
  @SpeakeasyMetadata()
  @Expose({ name: "extractionFrameRate" })
  extractionFrameRate?: number;
}
