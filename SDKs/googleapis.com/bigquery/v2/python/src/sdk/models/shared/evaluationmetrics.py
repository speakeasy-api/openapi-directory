"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import arimaforecastingmetrics as shared_arimaforecastingmetrics
from ..shared import binaryclassificationmetrics as shared_binaryclassificationmetrics
from ..shared import clusteringmetrics as shared_clusteringmetrics
from ..shared import dimensionalityreductionmetrics as shared_dimensionalityreductionmetrics
from ..shared import multiclassclassificationmetrics as shared_multiclassclassificationmetrics
from ..shared import rankingmetrics as shared_rankingmetrics
from ..shared import regressionmetrics as shared_regressionmetrics
from dataclasses_json import Undefined, dataclass_json
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class EvaluationMetrics:
    r"""Evaluation metrics of a model. These are either computed on all training data or just the eval data based on whether eval data was used during training. These are not present for imported models."""
    
    arima_forecasting_metrics: Optional[shared_arimaforecastingmetrics.ArimaForecastingMetrics] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('arimaForecastingMetrics'), 'exclude': lambda f: f is None }})
    r"""Model evaluation metrics for ARIMA forecasting models."""  
    binary_classification_metrics: Optional[shared_binaryclassificationmetrics.BinaryClassificationMetrics] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('binaryClassificationMetrics'), 'exclude': lambda f: f is None }})
    r"""Evaluation metrics for binary classification/classifier models."""  
    clustering_metrics: Optional[shared_clusteringmetrics.ClusteringMetrics] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('clusteringMetrics'), 'exclude': lambda f: f is None }})
    r"""Evaluation metrics for clustering models."""  
    dimensionality_reduction_metrics: Optional[shared_dimensionalityreductionmetrics.DimensionalityReductionMetrics] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('dimensionalityReductionMetrics'), 'exclude': lambda f: f is None }})
    r"""Model evaluation metrics for dimensionality reduction models."""  
    multi_class_classification_metrics: Optional[shared_multiclassclassificationmetrics.MultiClassClassificationMetrics] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('multiClassClassificationMetrics'), 'exclude': lambda f: f is None }})
    r"""Evaluation metrics for multi-class classification/classifier models."""  
    ranking_metrics: Optional[shared_rankingmetrics.RankingMetrics] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('rankingMetrics'), 'exclude': lambda f: f is None }})
    r"""Evaluation metrics used by weighted-ALS models specified by feedback_type=implicit."""  
    regression_metrics: Optional[shared_regressionmetrics.RegressionMetrics] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('regressionMetrics'), 'exclude': lambda f: f is None }})
    r"""Evaluation metrics for regression and explicit feedback type matrix factorization models."""  
    