"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import aggregationresult as shared_aggregationresult
from dataclasses_json import Undefined, dataclass_json
from enum import Enum
from sdk import utils
from typing import Optional

class AggregationResultBatchMoreResultsEnum(str, Enum):
    r"""The state of the query after the current batch. Only COUNT(*) aggregations are supported in the initial launch. Therefore, expected result type is limited to `NO_MORE_RESULTS`."""
    MORE_RESULTS_TYPE_UNSPECIFIED = 'MORE_RESULTS_TYPE_UNSPECIFIED'
    NOT_FINISHED = 'NOT_FINISHED'
    MORE_RESULTS_AFTER_LIMIT = 'MORE_RESULTS_AFTER_LIMIT'
    MORE_RESULTS_AFTER_CURSOR = 'MORE_RESULTS_AFTER_CURSOR'
    NO_MORE_RESULTS = 'NO_MORE_RESULTS'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class AggregationResultBatch:
    r"""A batch of aggregation results produced by an aggregation query."""
    
    aggregation_results: Optional[list[shared_aggregationresult.AggregationResult]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('aggregationResults'), 'exclude': lambda f: f is None }})
    r"""The aggregation results for this batch."""  
    more_results: Optional[AggregationResultBatchMoreResultsEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('moreResults'), 'exclude': lambda f: f is None }})
    r"""The state of the query after the current batch. Only COUNT(*) aggregations are supported in the initial launch. Therefore, expected result type is limited to `NO_MORE_RESULTS`."""  
    read_time: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('readTime'), 'exclude': lambda f: f is None }})
    r"""Read timestamp this batch was returned from. In a single transaction, subsequent query result batches for the same query can have a greater timestamp. Each batch's read timestamp is valid for all preceding batches."""  
    