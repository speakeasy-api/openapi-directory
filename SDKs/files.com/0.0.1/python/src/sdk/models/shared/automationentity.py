"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
import dateutil.parser
from dataclasses_json import Undefined, dataclass_json
from datetime import datetime
from enum import Enum
from marshmallow import fields
from sdk import utils
from typing import Any, Optional

class AutomationEntityAutomationEnum(str, Enum):
    r"""Automation type"""
    CREATE_FOLDER = 'create_folder'
    REQUEST_FILE = 'request_file'
    REQUEST_MOVE = 'request_move'
    COPY_NEWEST_FILE = 'copy_newest_file'
    DELETE_FILE = 'delete_file'
    COPY_FILE = 'copy_file'
    MOVE_FILE = 'move_file'
    AS2_SEND = 'as2_send'
    RUN_SYNC = 'run_sync'

class AutomationEntityTriggerEnum(str, Enum):
    r"""How this automation is triggered to run. One of: `realtime`, `daily`, `custom_schedule`, `webhook`, `email`, or `action`."""
    REALTIME = 'realtime'
    DAILY = 'daily'
    CUSTOM_SCHEDULE = 'custom_schedule'
    WEBHOOK = 'webhook'
    EMAIL = 'email'
    ACTION = 'action'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class AutomationEntity:
    r"""List Automations"""
    
    automation: Optional[AutomationEntityAutomationEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('automation'), 'exclude': lambda f: f is None }})
    r"""Automation type"""  
    deleted: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('deleted'), 'exclude': lambda f: f is None }})
    r"""Indicates if the automation has been deleted."""  
    description: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('description'), 'exclude': lambda f: f is None }})
    r"""Description for the this Automation."""  
    destination_replace_from: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('destination_replace_from'), 'exclude': lambda f: f is None }})
    r"""If set, this string in the destination path will be replaced with the value in `destination_replace_to`."""  
    destination_replace_to: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('destination_replace_to'), 'exclude': lambda f: f is None }})
    r"""If set, this string will replace the value `destination_replace_from` in the destination filename. You can use special patterns here."""  
    destinations: Optional[list[str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('destinations'), 'exclude': lambda f: f is None }})
    r"""Destination Path"""  
    disabled: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('disabled'), 'exclude': lambda f: f is None }})
    r"""If true, this automation will not run."""  
    group_ids: Optional[list[int]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('group_ids'), 'exclude': lambda f: f is None }})
    r"""IDs of Groups for the Automation (i.e. who to Request File from)"""  
    id: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('id'), 'exclude': lambda f: f is None }})
    r"""Automation ID"""  
    interval: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('interval'), 'exclude': lambda f: f is None }})
    r"""If trigger is `daily`, this specifies how often to run this automation.  One of: `day`, `week`, `week_end`, `month`, `month_end`, `quarter`, `quarter_end`, `year`, `year_end`"""  
    last_modified_at: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('last_modified_at'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})
    r"""Time when automation was last modified. Does not change for name or description updates."""  
    name: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('name'), 'exclude': lambda f: f is None }})
    r"""Name for this automation."""  
    path: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('path'), 'exclude': lambda f: f is None }})
    r"""Path on which this Automation runs.  Supports globs."""  
    schedule: Optional[dict[str, Any]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('schedule'), 'exclude': lambda f: f is None }})
    r"""If trigger is `custom_schedule`, Custom schedule description for when the automation should be run."""  
    source: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('source'), 'exclude': lambda f: f is None }})
    r"""Source Path"""  
    sync_ids: Optional[list[int]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('sync_ids'), 'exclude': lambda f: f is None }})
    r"""IDs of remote sync folder behaviors to run by this Automation"""  
    trigger: Optional[AutomationEntityTriggerEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('trigger'), 'exclude': lambda f: f is None }})
    r"""How this automation is triggered to run. One of: `realtime`, `daily`, `custom_schedule`, `webhook`, `email`, or `action`."""  
    trigger_actions: Optional[list[str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('trigger_actions'), 'exclude': lambda f: f is None }})
    r"""If trigger is `action`, this is the list of action types on which to trigger the automation. Valid actions are create, read, update, destroy, move, copy"""  
    user_id: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('user_id'), 'exclude': lambda f: f is None }})
    r"""User ID of the Automation's creator."""  
    user_ids: Optional[list[int]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('user_ids'), 'exclude': lambda f: f is None }})
    r"""IDs of Users for the Automation (i.e. who to Request File from)"""  
    value: Optional[dict[str, Any]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('value'), 'exclude': lambda f: f is None }})
    r"""A Hash of attributes specific to the automation type."""  
    webhook_url: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('webhook_url'), 'exclude': lambda f: f is None }})
    r"""If trigger is `webhook`, this is the URL of the webhook to trigger the Automation."""  
    