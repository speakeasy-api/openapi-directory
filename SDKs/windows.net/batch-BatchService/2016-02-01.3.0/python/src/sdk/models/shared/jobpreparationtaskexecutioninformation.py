"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
import dateutil.parser
from ..shared import taskschedulingerror as shared_taskschedulingerror
from dataclasses_json import Undefined, dataclass_json
from datetime import datetime
from enum import Enum
from marshmallow import fields
from sdk import utils
from typing import Optional

class JobPreparationTaskExecutionInformationStateEnum(str, Enum):
    r"""The current state of the Job Preparation task."""
    RUNNING = 'running'
    COMPLETED = 'completed'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class JobPreparationTaskExecutionInformation:
    r"""Contains information about the execution of a Job Preparation task on a compute node."""
    
    retry_count: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('retryCount') }})
    r"""The number of times the task has been retried by the Batch service. Every time the task exits with a non-zero exit code, it is deemed a task failure. The Batch service will retry the task up to the limit specified by the constraints."""  
    start_time: datetime = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('startTime'), 'encoder': utils.datetimeisoformat(False), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso') }})
    r"""The time at which the task started running. Note that every time the task is restarted, this value is updated."""  
    state: JobPreparationTaskExecutionInformationStateEnum = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('state') }})
    r"""The current state of the Job Preparation task."""  
    end_time: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('endTime'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})
    r"""The time at which the Job Preparation task completed. This property is set only if the task is in the Completed state."""  
    exit_code: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('exitCode'), 'exclude': lambda f: f is None }})
    r"""The exit code of the Job Preparation task. This property is set only if the task is in the Completed state."""  
    last_retry_time: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('lastRetryTime'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})
    r"""The most recent time at which a retry of the Job Preparation task started running. This property is set only if the task was retried (i.e. retryCount is nonzero)."""  
    scheduling_error: Optional[shared_taskschedulingerror.TaskSchedulingError] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('schedulingError'), 'exclude': lambda f: f is None }})
    r"""Information about an error when scheduling a task."""  
    task_root_directory: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('taskRootDirectory'), 'exclude': lambda f: f is None }})
    r"""The root directory of the Job Preparation task on the compute node. You can use this path to retrieve files created by the task, such as log files."""  
    task_root_directory_url: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('taskRootDirectoryUrl'), 'exclude': lambda f: f is None }})
    r"""The URL to the root directory of the Job Preparation task on the compute node."""  
    