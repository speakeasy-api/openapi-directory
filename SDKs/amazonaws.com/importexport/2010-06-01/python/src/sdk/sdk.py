"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

import requests as requests_http
from . import utils
from sdk.models import operations, shared

SERVERS = [
    "http://importexport.amazonaws.com",
    r"""The general AWS Import/Export multi-region endpoint"""
    "https://importexport.amazonaws.com",
    r"""The general AWS Import/Export multi-region endpoint"""
    "http://importexport.{region}.amazonaws.com.cn",
    r"""The AWS Import/Export endpoint for China (Beijing) and China (Ningxia)"""
    "https://importexport.{region}.amazonaws.com.cn",
    r"""The AWS Import/Export endpoint for China (Beijing) and China (Ningxia)"""
]
"""Contains the list of servers available to the SDK"""

class SDK:
    r"""<fullname>AWS Import/Export Service</fullname> AWS Import/Export accelerates transferring large amounts of data between the AWS cloud and portable storage devices that you mail to us. AWS Import/Export transfers data directly onto and off of your storage devices using Amazon's high-speed internal network and bypassing the Internet. For large data sets, AWS Import/Export is often faster than Internet transfer and more cost effective than upgrading your connectivity.
    https://docs.aws.amazon.com/importexport/ - Amazon Web Services documentation
    """

    _client: requests_http.Session
    _security_client: requests_http.Session
    _server_url: str = SERVERS[0]
    _language: str = "python"
    _sdk_version: str = "0.0.1"
    _gen_version: str = "internal"

    def __init__(self,
                 security: shared.Security = None,
                 server_url: str = None,
                 url_params: dict[str, str] = None,
                 client: requests_http.Session = None
                 ) -> None:
        """Instantiates the SDK configuring it with the provided parameters.
        
        :param security: The security details required for authentication
        :type security: shared.Security
        :param server_url: The server URL to use for all operations
        :type server_url: str
        :param url_params: Parameters to optionally template the server URL with
        :type url_params: dict[str, str]
        :param client: The requests.Session HTTP client to use for all operations
        :type client: requests_http.Session        
        """
        self._client = requests_http.Session()
        
        
        if server_url is not None:
            if url_params is not None:
                self._server_url = utils.template_url(server_url, url_params)
            else:
                self._server_url = server_url

        if client is not None:
            self._client = client
        
        self._security_client = utils.configure_security_client(self._client, security)
        

        
    
    
    def get_cancel_job(self, request: operations.GETCancelJobRequest) -> operations.GETCancelJobResponse:
        r"""This operation cancels a specified job. Only the job owner can cancel it. The operation fails if the job has already started or is complete."""
        base_url = self._server_url
        
        url = base_url.removesuffix('/') + '/#Operation=CancelJob&Action=CancelJob'
        
        query_params = utils.get_query_params(operations.GETCancelJobRequest, request)
        
        client = self._security_client
        
        http_res = client.request('GET', url, params=query_params)
        content_type = http_res.headers.get('Content-Type')

        res = operations.GETCancelJobResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code in [200, 480, 481, 482, 483, 484, 485]:
            if utils.match_content_type(content_type, 'text/xml'):
                res.body = http_res.content

        return res

    def get_create_job(self, request: operations.GETCreateJobRequest) -> operations.GETCreateJobResponse:
        r"""This operation initiates the process of scheduling an upload or download of your data. You include in the request a manifest that describes the data transfer specifics. The response to the request includes a job ID, which you can use in other operations, a signature that you use to identify your storage device, and the address where you should ship your storage device."""
        base_url = self._server_url
        
        url = base_url.removesuffix('/') + '/#Operation=CreateJob&Action=CreateJob'
        
        query_params = utils.get_query_params(operations.GETCreateJobRequest, request)
        
        client = self._security_client
        
        http_res = client.request('GET', url, params=query_params)
        content_type = http_res.headers.get('Content-Type')

        res = operations.GETCreateJobResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code in [200, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495]:
            if utils.match_content_type(content_type, 'text/xml'):
                res.body = http_res.content

        return res

    def get_get_shipping_label(self, request: operations.GETGETShippingLabelRequest) -> operations.GETGETShippingLabelResponse:
        r"""This operation generates a pre-paid UPS shipping label that you will use to ship your device to AWS for processing."""
        base_url = self._server_url
        
        url = base_url.removesuffix('/') + '/#Operation=GetShippingLabel&Action=GetShippingLabel'
        
        query_params = utils.get_query_params(operations.GETGETShippingLabelRequest, request)
        
        client = self._security_client
        
        http_res = client.request('GET', url, params=query_params)
        content_type = http_res.headers.get('Content-Type')

        res = operations.GETGETShippingLabelResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code in [200, 480, 481, 482, 483, 484, 485, 486]:
            if utils.match_content_type(content_type, 'text/xml'):
                res.body = http_res.content

        return res

    def get_get_status(self, request: operations.GETGETStatusRequest) -> operations.GETGETStatusResponse:
        r"""This operation returns information about a job, including where the job is in the processing pipeline, the status of the results, and the signature value associated with the job. You can only return information about jobs you own."""
        base_url = self._server_url
        
        url = base_url.removesuffix('/') + '/#Operation=GetStatus&Action=GetStatus'
        
        query_params = utils.get_query_params(operations.GETGETStatusRequest, request)
        
        client = self._security_client
        
        http_res = client.request('GET', url, params=query_params)
        content_type = http_res.headers.get('Content-Type')

        res = operations.GETGETStatusResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code in [200, 480, 481, 482, 483, 484]:
            if utils.match_content_type(content_type, 'text/xml'):
                res.body = http_res.content

        return res

    def get_list_jobs(self, request: operations.GETListJobsRequest) -> operations.GETListJobsResponse:
        r"""This operation returns the jobs associated with the requester. AWS Import/Export lists the jobs in reverse chronological order based on the date of creation. For example if Job Test1 was created 2009Dec30 and Test2 was created 2010Feb05, the ListJobs operation would return Test2 followed by Test1."""
        base_url = self._server_url
        
        url = base_url.removesuffix('/') + '/#Operation=ListJobs&Action=ListJobs'
        
        query_params = utils.get_query_params(operations.GETListJobsRequest, request)
        
        client = self._security_client
        
        http_res = client.request('GET', url, params=query_params)
        content_type = http_res.headers.get('Content-Type')

        res = operations.GETListJobsResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code in [200, 480, 481, 482]:
            if utils.match_content_type(content_type, 'text/xml'):
                res.body = http_res.content

        return res

    def get_update_job(self, request: operations.GETUpdateJobRequest) -> operations.GETUpdateJobResponse:
        r"""You use this operation to change the parameters specified in the original manifest file by supplying a new manifest file. The manifest file attached to this request replaces the original manifest file. You can only use the operation after a CreateJob request but before the data transfer starts and you can only use it on jobs you own."""
        base_url = self._server_url
        
        url = base_url.removesuffix('/') + '/#Operation=UpdateJob&Action=UpdateJob'
        
        query_params = utils.get_query_params(operations.GETUpdateJobRequest, request)
        
        client = self._security_client
        
        http_res = client.request('GET', url, params=query_params)
        content_type = http_res.headers.get('Content-Type')

        res = operations.GETUpdateJobResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code in [200, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497]:
            if utils.match_content_type(content_type, 'text/xml'):
                res.body = http_res.content

        return res

    def post_cancel_job(self, request: operations.POSTCancelJobRequest) -> operations.POSTCancelJobResponse:
        r"""This operation cancels a specified job. Only the job owner can cancel it. The operation fails if the job has already started or is complete."""
        base_url = self._server_url
        
        url = base_url.removesuffix('/') + '/#Operation=CancelJob&Action=CancelJob'
        
        headers = {}
        req_content_type, data, form = utils.serialize_request_body(request, "request_body", 'raw')
        if req_content_type not in ('multipart/form-data', 'multipart/mixed'):
            headers['content-type'] = req_content_type
        query_params = utils.get_query_params(operations.POSTCancelJobRequest, request)
        
        client = self._security_client
        
        http_res = client.request('POST', url, params=query_params, data=data, files=form, headers=headers)
        content_type = http_res.headers.get('Content-Type')

        res = operations.POSTCancelJobResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code in [200, 480, 481, 482, 483, 484, 485]:
            if utils.match_content_type(content_type, 'text/xml'):
                res.body = http_res.content

        return res

    def post_create_job(self, request: operations.POSTCreateJobRequest) -> operations.POSTCreateJobResponse:
        r"""This operation initiates the process of scheduling an upload or download of your data. You include in the request a manifest that describes the data transfer specifics. The response to the request includes a job ID, which you can use in other operations, a signature that you use to identify your storage device, and the address where you should ship your storage device."""
        base_url = self._server_url
        
        url = base_url.removesuffix('/') + '/#Operation=CreateJob&Action=CreateJob'
        
        headers = {}
        req_content_type, data, form = utils.serialize_request_body(request, "request_body", 'raw')
        if req_content_type not in ('multipart/form-data', 'multipart/mixed'):
            headers['content-type'] = req_content_type
        query_params = utils.get_query_params(operations.POSTCreateJobRequest, request)
        
        client = self._security_client
        
        http_res = client.request('POST', url, params=query_params, data=data, files=form, headers=headers)
        content_type = http_res.headers.get('Content-Type')

        res = operations.POSTCreateJobResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code in [200, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495]:
            if utils.match_content_type(content_type, 'text/xml'):
                res.body = http_res.content

        return res

    def post_get_shipping_label(self, request: operations.POSTGetShippingLabelRequest) -> operations.POSTGetShippingLabelResponse:
        r"""This operation generates a pre-paid UPS shipping label that you will use to ship your device to AWS for processing."""
        base_url = self._server_url
        
        url = base_url.removesuffix('/') + '/#Operation=GetShippingLabel&Action=GetShippingLabel'
        
        headers = {}
        req_content_type, data, form = utils.serialize_request_body(request, "request_body", 'raw')
        if req_content_type not in ('multipart/form-data', 'multipart/mixed'):
            headers['content-type'] = req_content_type
        query_params = utils.get_query_params(operations.POSTGetShippingLabelRequest, request)
        
        client = self._security_client
        
        http_res = client.request('POST', url, params=query_params, data=data, files=form, headers=headers)
        content_type = http_res.headers.get('Content-Type')

        res = operations.POSTGetShippingLabelResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code in [200, 480, 481, 482, 483, 484, 485, 486]:
            if utils.match_content_type(content_type, 'text/xml'):
                res.body = http_res.content

        return res

    def post_get_status(self, request: operations.POSTGetStatusRequest) -> operations.POSTGetStatusResponse:
        r"""This operation returns information about a job, including where the job is in the processing pipeline, the status of the results, and the signature value associated with the job. You can only return information about jobs you own."""
        base_url = self._server_url
        
        url = base_url.removesuffix('/') + '/#Operation=GetStatus&Action=GetStatus'
        
        headers = {}
        req_content_type, data, form = utils.serialize_request_body(request, "request_body", 'raw')
        if req_content_type not in ('multipart/form-data', 'multipart/mixed'):
            headers['content-type'] = req_content_type
        query_params = utils.get_query_params(operations.POSTGetStatusRequest, request)
        
        client = self._security_client
        
        http_res = client.request('POST', url, params=query_params, data=data, files=form, headers=headers)
        content_type = http_res.headers.get('Content-Type')

        res = operations.POSTGetStatusResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code in [200, 480, 481, 482, 483, 484]:
            if utils.match_content_type(content_type, 'text/xml'):
                res.body = http_res.content

        return res

    def post_list_jobs(self, request: operations.POSTListJobsRequest) -> operations.POSTListJobsResponse:
        r"""This operation returns the jobs associated with the requester. AWS Import/Export lists the jobs in reverse chronological order based on the date of creation. For example if Job Test1 was created 2009Dec30 and Test2 was created 2010Feb05, the ListJobs operation would return Test2 followed by Test1."""
        base_url = self._server_url
        
        url = base_url.removesuffix('/') + '/#Operation=ListJobs&Action=ListJobs'
        
        headers = {}
        req_content_type, data, form = utils.serialize_request_body(request, "request_body", 'raw')
        if req_content_type not in ('multipart/form-data', 'multipart/mixed'):
            headers['content-type'] = req_content_type
        query_params = utils.get_query_params(operations.POSTListJobsRequest, request)
        
        client = self._security_client
        
        http_res = client.request('POST', url, params=query_params, data=data, files=form, headers=headers)
        content_type = http_res.headers.get('Content-Type')

        res = operations.POSTListJobsResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code in [200, 480, 481, 482]:
            if utils.match_content_type(content_type, 'text/xml'):
                res.body = http_res.content

        return res

    def post_update_job(self, request: operations.POSTUpdateJobRequest) -> operations.POSTUpdateJobResponse:
        r"""You use this operation to change the parameters specified in the original manifest file by supplying a new manifest file. The manifest file attached to this request replaces the original manifest file. You can only use the operation after a CreateJob request but before the data transfer starts and you can only use it on jobs you own."""
        base_url = self._server_url
        
        url = base_url.removesuffix('/') + '/#Operation=UpdateJob&Action=UpdateJob'
        
        headers = {}
        req_content_type, data, form = utils.serialize_request_body(request, "request_body", 'raw')
        if req_content_type not in ('multipart/form-data', 'multipart/mixed'):
            headers['content-type'] = req_content_type
        query_params = utils.get_query_params(operations.POSTUpdateJobRequest, request)
        
        client = self._security_client
        
        http_res = client.request('POST', url, params=query_params, data=data, files=form, headers=headers)
        content_type = http_res.headers.get('Content-Type')

        res = operations.POSTUpdateJobResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code in [200, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497]:
            if utils.match_content_type(content_type, 'text/xml'):
                res.body = http_res.content

        return res

    