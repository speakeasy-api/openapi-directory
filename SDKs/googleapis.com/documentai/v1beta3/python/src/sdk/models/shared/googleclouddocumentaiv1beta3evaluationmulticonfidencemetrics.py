"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import googleclouddocumentaiv1beta3evaluationconfidencelevelmetrics as shared_googleclouddocumentaiv1beta3evaluationconfidencelevelmetrics
from dataclasses_json import Undefined, dataclass_json
from enum import Enum
from sdk import utils
from typing import Optional

class GoogleCloudDocumentaiV1beta3EvaluationMultiConfidenceMetricsMetricsTypeEnum(str, Enum):
    r"""The metrics type for the label."""
    METRICS_TYPE_UNSPECIFIED = 'METRICS_TYPE_UNSPECIFIED'
    AGGREGATE = 'AGGREGATE'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class GoogleCloudDocumentaiV1beta3EvaluationMultiConfidenceMetrics:
    r"""Metrics across multiple confidence levels."""
    
    auprc: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('auprc'), 'exclude': lambda f: f is None }})
    r"""The calculated area under the precision recall curve (AUPRC), computed by integrating over all confidence thresholds."""  
    auprc_exact: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('auprcExact'), 'exclude': lambda f: f is None }})
    r"""The AUPRC for metrics with fuzzy matching disabled, i.e., exact matching only."""  
    confidence_level_metrics: Optional[list[shared_googleclouddocumentaiv1beta3evaluationconfidencelevelmetrics.GoogleCloudDocumentaiV1beta3EvaluationConfidenceLevelMetrics]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('confidenceLevelMetrics'), 'exclude': lambda f: f is None }})
    r"""Metrics across confidence levels with fuzzy matching enabled."""  
    confidence_level_metrics_exact: Optional[list[shared_googleclouddocumentaiv1beta3evaluationconfidencelevelmetrics.GoogleCloudDocumentaiV1beta3EvaluationConfidenceLevelMetrics]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('confidenceLevelMetricsExact'), 'exclude': lambda f: f is None }})
    r"""Metrics across confidence levels with only exact matching."""  
    estimated_calibration_error: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('estimatedCalibrationError'), 'exclude': lambda f: f is None }})
    r"""The Estimated Calibration Error (ECE) of the confidence of the predicted entities."""  
    estimated_calibration_error_exact: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('estimatedCalibrationErrorExact'), 'exclude': lambda f: f is None }})
    r"""The ECE for the predicted entities with fuzzy matching disabled, i.e., exact matching only."""  
    metrics_type: Optional[GoogleCloudDocumentaiV1beta3EvaluationMultiConfidenceMetricsMetricsTypeEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('metricsType'), 'exclude': lambda f: f is None }})
    r"""The metrics type for the label."""  
    