<?php

/**
 * Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.
 */

declare(strict_types=1);

namespace OpenAPI\OpenAPI\Models\Shared;


/**
 * JobInput - A Dataproc job resource.
 * 
 * @package OpenAPI\OpenAPI\Models\Shared
 * @access public
 */
class JobInput
{
    /**
     * Driver scheduling configuration.
     * 
     * @var ?\OpenAPI\OpenAPI\Models\Shared\DriverSchedulingConfig $driverSchedulingConfig
     */
	#[\JMS\Serializer\Annotation\SerializedName('driverSchedulingConfig')]
    #[\JMS\Serializer\Annotation\Type('OpenAPI\OpenAPI\Models\Shared\DriverSchedulingConfig')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public ?DriverSchedulingConfig $driverSchedulingConfig = null;
    
    /**
     * A Dataproc job for running Apache Hadoop MapReduce (https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html) jobs on Apache Hadoop YARN (https://hadoop.apache.org/docs/r2.7.1/hadoop-yarn/hadoop-yarn-site/YARN.html).
     * 
     * @var ?\OpenAPI\OpenAPI\Models\Shared\HadoopJob $hadoopJob
     */
	#[\JMS\Serializer\Annotation\SerializedName('hadoopJob')]
    #[\JMS\Serializer\Annotation\Type('OpenAPI\OpenAPI\Models\Shared\HadoopJob')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public ?HadoopJob $hadoopJob = null;
    
    /**
     * A Dataproc job for running Apache Hive (https://hive.apache.org/) queries on YARN.
     * 
     * @var ?\OpenAPI\OpenAPI\Models\Shared\HiveJob $hiveJob
     */
	#[\JMS\Serializer\Annotation\SerializedName('hiveJob')]
    #[\JMS\Serializer\Annotation\Type('OpenAPI\OpenAPI\Models\Shared\HiveJob')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public ?HiveJob $hiveJob = null;
    
    /**
     * Optional. The labels to associate with this job. Label keys must contain 1 to 63 characters, and must conform to RFC 1035 (https://www.ietf.org/rfc/rfc1035.txt). Label values may be empty, but, if present, must contain 1 to 63 characters, and must conform to RFC 1035 (https://www.ietf.org/rfc/rfc1035.txt). No more than 32 labels can be associated with a job.
     * 
     * @var ?array<string, string> $labels
     */
	#[\JMS\Serializer\Annotation\SerializedName('labels')]
    #[\JMS\Serializer\Annotation\Type('array<string, string>')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public ?array $labels = null;
    
    /**
     * A Dataproc job for running Apache Pig (https://pig.apache.org/) queries on YARN.
     * 
     * @var ?\OpenAPI\OpenAPI\Models\Shared\PigJob $pigJob
     */
	#[\JMS\Serializer\Annotation\SerializedName('pigJob')]
    #[\JMS\Serializer\Annotation\Type('OpenAPI\OpenAPI\Models\Shared\PigJob')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public ?PigJob $pigJob = null;
    
    /**
     * Dataproc job config.
     * 
     * @var ?\OpenAPI\OpenAPI\Models\Shared\JobPlacementInput $placement
     */
	#[\JMS\Serializer\Annotation\SerializedName('placement')]
    #[\JMS\Serializer\Annotation\Type('OpenAPI\OpenAPI\Models\Shared\JobPlacementInput')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public ?JobPlacementInput $placement = null;
    
    /**
     * A Dataproc job for running Presto (https://prestosql.io/) queries. IMPORTANT: The Dataproc Presto Optional Component (https://cloud.google.com/dataproc/docs/concepts/components/presto) must be enabled when the cluster is created to submit a Presto job to the cluster.
     * 
     * @var ?\OpenAPI\OpenAPI\Models\Shared\PrestoJob $prestoJob
     */
	#[\JMS\Serializer\Annotation\SerializedName('prestoJob')]
    #[\JMS\Serializer\Annotation\Type('OpenAPI\OpenAPI\Models\Shared\PrestoJob')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public ?PrestoJob $prestoJob = null;
    
    /**
     * A Dataproc job for running Apache PySpark (https://spark.apache.org/docs/0.9.0/python-programming-guide.html) applications on YARN.
     * 
     * @var ?\OpenAPI\OpenAPI\Models\Shared\PySparkJob $pysparkJob
     */
	#[\JMS\Serializer\Annotation\SerializedName('pysparkJob')]
    #[\JMS\Serializer\Annotation\Type('OpenAPI\OpenAPI\Models\Shared\PySparkJob')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public ?PySparkJob $pysparkJob = null;
    
    /**
     * Encapsulates the full scoping used to reference a job.
     * 
     * @var ?\OpenAPI\OpenAPI\Models\Shared\JobReference $reference
     */
	#[\JMS\Serializer\Annotation\SerializedName('reference')]
    #[\JMS\Serializer\Annotation\Type('OpenAPI\OpenAPI\Models\Shared\JobReference')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public ?JobReference $reference = null;
    
    /**
     * Job scheduling options.
     * 
     * @var ?\OpenAPI\OpenAPI\Models\Shared\JobScheduling $scheduling
     */
	#[\JMS\Serializer\Annotation\SerializedName('scheduling')]
    #[\JMS\Serializer\Annotation\Type('OpenAPI\OpenAPI\Models\Shared\JobScheduling')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public ?JobScheduling $scheduling = null;
    
    /**
     * A Dataproc job for running Apache Spark (https://spark.apache.org/) applications on YARN.
     * 
     * @var ?\OpenAPI\OpenAPI\Models\Shared\SparkJob $sparkJob
     */
	#[\JMS\Serializer\Annotation\SerializedName('sparkJob')]
    #[\JMS\Serializer\Annotation\Type('OpenAPI\OpenAPI\Models\Shared\SparkJob')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public ?SparkJob $sparkJob = null;
    
    /**
     * A Dataproc job for running Apache SparkR (https://spark.apache.org/docs/latest/sparkr.html) applications on YARN.
     * 
     * @var ?\OpenAPI\OpenAPI\Models\Shared\SparkRJob $sparkRJob
     */
	#[\JMS\Serializer\Annotation\SerializedName('sparkRJob')]
    #[\JMS\Serializer\Annotation\Type('OpenAPI\OpenAPI\Models\Shared\SparkRJob')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public ?SparkRJob $sparkRJob = null;
    
    /**
     * A Dataproc job for running Apache Spark SQL (https://spark.apache.org/sql/) queries.
     * 
     * @var ?\OpenAPI\OpenAPI\Models\Shared\SparkSqlJob $sparkSqlJob
     */
	#[\JMS\Serializer\Annotation\SerializedName('sparkSqlJob')]
    #[\JMS\Serializer\Annotation\Type('OpenAPI\OpenAPI\Models\Shared\SparkSqlJob')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public ?SparkSqlJob $sparkSqlJob = null;
    
    /**
     * A Dataproc job for running Trino (https://trino.io/) queries. IMPORTANT: The Dataproc Trino Optional Component (https://cloud.google.com/dataproc/docs/concepts/components/trino) must be enabled when the cluster is created to submit a Trino job to the cluster.
     * 
     * @var ?\OpenAPI\OpenAPI\Models\Shared\TrinoJob $trinoJob
     */
	#[\JMS\Serializer\Annotation\SerializedName('trinoJob')]
    #[\JMS\Serializer\Annotation\Type('OpenAPI\OpenAPI\Models\Shared\TrinoJob')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public ?TrinoJob $trinoJob = null;
    
	public function __construct()
	{
		$this->driverSchedulingConfig = null;
		$this->hadoopJob = null;
		$this->hiveJob = null;
		$this->labels = null;
		$this->pigJob = null;
		$this->placement = null;
		$this->prestoJob = null;
		$this->pysparkJob = null;
		$this->reference = null;
		$this->scheduling = null;
		$this->sparkJob = null;
		$this->sparkRJob = null;
		$this->sparkSqlJob = null;
		$this->trinoJob = null;
	}
}
