"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
import dateutil.parser
from ..shared import completionreport as shared_completionreport
from ..shared import datarepositorytaskfailuredetails as shared_datarepositorytaskfailuredetails
from ..shared import datarepositorytasklifecycle_enum as shared_datarepositorytasklifecycle_enum
from ..shared import datarepositorytaskstatus as shared_datarepositorytaskstatus
from ..shared import datarepositorytasktype_enum as shared_datarepositorytasktype_enum
from ..shared import tag as shared_tag
from dataclasses_json import Undefined, dataclass_json
from datetime import datetime
from marshmallow import fields
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class DataRepositoryTask:
    r"""A description of the data repository task. You use data repository tasks to perform bulk transfer operations between an Amazon FSx for Lustre file system and a linked data repository. An Amazon File Cache resource uses a task to automatically release files from the cache."""
    
    creation_time: datetime = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('CreationTime'), 'encoder': utils.datetimeisoformat(False), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso') }})
    r"""The time that the resource was created, in seconds (since 1970-01-01T00:00:00Z), also known as Unix time."""  
    lifecycle: shared_datarepositorytasklifecycle_enum.DataRepositoryTaskLifecycleEnum = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('Lifecycle') }})  
    task_id: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('TaskId') }})  
    type: shared_datarepositorytasktype_enum.DataRepositoryTaskTypeEnum = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('Type') }})  
    capacity_to_release: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('CapacityToRelease'), 'exclude': lambda f: f is None }})  
    end_time: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('EndTime'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})  
    failure_details: Optional[shared_datarepositorytaskfailuredetails.DataRepositoryTaskFailureDetails] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('FailureDetails'), 'exclude': lambda f: f is None }})  
    file_cache_id: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('FileCacheId'), 'exclude': lambda f: f is None }})  
    file_system_id: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('FileSystemId'), 'exclude': lambda f: f is None }})  
    paths: Optional[list[str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('Paths'), 'exclude': lambda f: f is None }})  
    report: Optional[shared_completionreport.CompletionReport] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('Report'), 'exclude': lambda f: f is None }})
    r"""Provides a report detailing the data repository task results of the files processed that match the criteria specified in the report <code>Scope</code> parameter. FSx delivers the report to the file system's linked data repository in Amazon S3, using the path specified in the report <code>Path</code> parameter. You can specify whether or not a report gets generated for a task using the <code>Enabled</code> parameter."""  
    resource_arn: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ResourceARN'), 'exclude': lambda f: f is None }})
    r"""The Amazon Resource Name (ARN) for a given resource. ARNs uniquely identify Amazon Web Services resources. We require an ARN when you need to specify a resource unambiguously across all of Amazon Web Services. For more information, see <a href=\\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\\">Amazon Resource Names (ARNs)</a> in the <i>Amazon Web Services General Reference</i>."""  
    start_time: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('StartTime'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})  
    status: Optional[shared_datarepositorytaskstatus.DataRepositoryTaskStatus] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('Status'), 'exclude': lambda f: f is None }})  
    tags: Optional[list[shared_tag.Tag]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('Tags'), 'exclude': lambda f: f is None }})
    r"""A list of <code>Tag</code> values, with a maximum of 50 elements."""  
    