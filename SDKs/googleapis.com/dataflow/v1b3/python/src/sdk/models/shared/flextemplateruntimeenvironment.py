"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from dataclasses_json import Undefined, dataclass_json
from enum import Enum
from sdk import utils
from typing import Optional

class FlexTemplateRuntimeEnvironmentAutoscalingAlgorithmEnum(str, Enum):
    r"""The algorithm to use for autoscaling"""
    AUTOSCALING_ALGORITHM_UNKNOWN = 'AUTOSCALING_ALGORITHM_UNKNOWN'
    AUTOSCALING_ALGORITHM_NONE = 'AUTOSCALING_ALGORITHM_NONE'
    AUTOSCALING_ALGORITHM_BASIC = 'AUTOSCALING_ALGORITHM_BASIC'

class FlexTemplateRuntimeEnvironmentFlexrsGoalEnum(str, Enum):
    r"""Set FlexRS goal for the job. https://cloud.google.com/dataflow/docs/guides/flexrs"""
    FLEXRS_UNSPECIFIED = 'FLEXRS_UNSPECIFIED'
    FLEXRS_SPEED_OPTIMIZED = 'FLEXRS_SPEED_OPTIMIZED'
    FLEXRS_COST_OPTIMIZED = 'FLEXRS_COST_OPTIMIZED'

class FlexTemplateRuntimeEnvironmentIPConfigurationEnum(str, Enum):
    r"""Configuration for VM IPs."""
    WORKER_IP_UNSPECIFIED = 'WORKER_IP_UNSPECIFIED'
    WORKER_IP_PUBLIC = 'WORKER_IP_PUBLIC'
    WORKER_IP_PRIVATE = 'WORKER_IP_PRIVATE'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class FlexTemplateRuntimeEnvironment:
    r"""The environment values to be set at runtime for flex template."""
    
    additional_experiments: Optional[list[str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('additionalExperiments'), 'exclude': lambda f: f is None }})
    r"""Additional experiment flags for the job."""  
    additional_user_labels: Optional[dict[str, str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('additionalUserLabels'), 'exclude': lambda f: f is None }})
    r"""Additional user labels to be specified for the job. Keys and values must follow the restrictions specified in the [labeling restrictions](https://cloud.google.com/compute/docs/labeling-resources#restrictions) page. An object containing a list of \\"key\\": value pairs. Example: { \\"name\\": \\"wrench\\", \\"mass\\": \\"1kg\\", \\"count\\": \\"3\\" }."""  
    autoscaling_algorithm: Optional[FlexTemplateRuntimeEnvironmentAutoscalingAlgorithmEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('autoscalingAlgorithm'), 'exclude': lambda f: f is None }})
    r"""The algorithm to use for autoscaling"""  
    disk_size_gb: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('diskSizeGb'), 'exclude': lambda f: f is None }})
    r"""Worker disk size, in gigabytes."""  
    dump_heap_on_oom: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('dumpHeapOnOom'), 'exclude': lambda f: f is None }})
    r"""If true, when processing time is spent almost entirely on garbage collection (GC), saves a heap dump before ending the thread or process. If false, ends the thread or process without saving a heap dump. Does not save a heap dump when the Java Virtual Machine (JVM) has an out of memory error during processing. The location of the heap file is either echoed back to the user, or the user is given the opportunity to download the heap file."""  
    enable_launcher_vm_serial_port_logging: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('enableLauncherVmSerialPortLogging'), 'exclude': lambda f: f is None }})
    r"""If true serial port logging will be enabled for the launcher VM."""  
    enable_streaming_engine: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('enableStreamingEngine'), 'exclude': lambda f: f is None }})
    r"""Whether to enable Streaming Engine for the job."""  
    flexrs_goal: Optional[FlexTemplateRuntimeEnvironmentFlexrsGoalEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('flexrsGoal'), 'exclude': lambda f: f is None }})
    r"""Set FlexRS goal for the job. https://cloud.google.com/dataflow/docs/guides/flexrs"""  
    ip_configuration: Optional[FlexTemplateRuntimeEnvironmentIPConfigurationEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ipConfiguration'), 'exclude': lambda f: f is None }})
    r"""Configuration for VM IPs."""  
    kms_key_name: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('kmsKeyName'), 'exclude': lambda f: f is None }})
    r"""Name for the Cloud KMS key for the job. Key format is: projects//locations//keyRings//cryptoKeys/"""  
    launcher_machine_type: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('launcherMachineType'), 'exclude': lambda f: f is None }})
    r"""The machine type to use for launching the job. The default is n1-standard-1."""  
    machine_type: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('machineType'), 'exclude': lambda f: f is None }})
    r"""The machine type to use for the job. Defaults to the value from the template if not specified."""  
    max_workers: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('maxWorkers'), 'exclude': lambda f: f is None }})
    r"""The maximum number of Google Compute Engine instances to be made available to your pipeline during execution, from 1 to 1000."""  
    network: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('network'), 'exclude': lambda f: f is None }})
    r"""Network to which VMs will be assigned. If empty or unspecified, the service will use the network \\"default\\"."""  
    num_workers: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('numWorkers'), 'exclude': lambda f: f is None }})
    r"""The initial number of Google Compute Engine instances for the job."""  
    save_heap_dumps_to_gcs_path: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('saveHeapDumpsToGcsPath'), 'exclude': lambda f: f is None }})
    r"""Cloud Storage bucket (directory) to upload heap dumps to. Enabling this field implies that `dump_heap_on_oom` is set to true."""  
    sdk_container_image: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('sdkContainerImage'), 'exclude': lambda f: f is None }})
    r"""Docker registry location of container image to use for the 'worker harness. Default is the container for the version of the SDK. Note this field is only valid for portable pipelines."""  
    service_account_email: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('serviceAccountEmail'), 'exclude': lambda f: f is None }})
    r"""The email address of the service account to run the job as."""  
    staging_location: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('stagingLocation'), 'exclude': lambda f: f is None }})
    r"""The Cloud Storage path for staging local files. Must be a valid Cloud Storage URL, beginning with `gs://`."""  
    subnetwork: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('subnetwork'), 'exclude': lambda f: f is None }})
    r"""Subnetwork to which VMs will be assigned, if desired. You can specify a subnetwork using either a complete URL or an abbreviated path. Expected to be of the form \\"https://www.googleapis.com/compute/v1/projects/HOST_PROJECT_ID/regions/REGION/subnetworks/SUBNETWORK\\" or \\"regions/REGION/subnetworks/SUBNETWORK\\". If the subnetwork is located in a Shared VPC network, you must use the complete URL."""  
    temp_location: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('tempLocation'), 'exclude': lambda f: f is None }})
    r"""The Cloud Storage path to use for temporary files. Must be a valid Cloud Storage URL, beginning with `gs://`."""  
    worker_region: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('workerRegion'), 'exclude': lambda f: f is None }})
    r"""The Compute Engine region (https://cloud.google.com/compute/docs/regions-zones/regions-zones) in which worker processing should occur, e.g. \\"us-west1\\". Mutually exclusive with worker_zone. If neither worker_region nor worker_zone is specified, default to the control plane's region."""  
    worker_zone: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('workerZone'), 'exclude': lambda f: f is None }})
    r"""The Compute Engine zone (https://cloud.google.com/compute/docs/regions-zones/regions-zones) in which worker processing should occur, e.g. \\"us-west1-a\\". Mutually exclusive with worker_region. If neither worker_region nor worker_zone is specified, a zone in the control plane's region is chosen based on available capacity. If both `worker_zone` and `zone` are set, `worker_zone` takes precedence."""  
    zone: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('zone'), 'exclude': lambda f: f is None }})
    r"""The Compute Engine [availability zone](https://cloud.google.com/compute/docs/regions-zones/regions-zones) for launching worker instances to run your pipeline. In the future, worker_zone will take precedence."""  
    