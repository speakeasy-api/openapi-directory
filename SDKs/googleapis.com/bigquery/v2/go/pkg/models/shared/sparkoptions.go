// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

// SparkOptions - Options for a user-defined Spark routine.
type SparkOptions struct {
	// Archive files to be extracted into the working directory of each executor. For more information about Apache Spark, see [Apache Spark](https://spark.apache.org/docs/latest/index.html).
	ArchiveUris []string `json:"archiveUris,omitempty"`
	// Fully qualified name of the user-provided Spark connection object. Format: ```"projects/{project_id}/locations/{location_id}/connections/{connection_id}"```
	Connection *string `json:"connection,omitempty"`
	// Custom container image for the runtime environment.
	ContainerImage *string `json:"containerImage,omitempty"`
	// Files to be placed in the working directory of each executor. For more information about Apache Spark, see [Apache Spark](https://spark.apache.org/docs/latest/index.html).
	FileUris []string `json:"fileUris,omitempty"`
	// JARs to include on the driver and executor CLASSPATH. For more information about Apache Spark, see [Apache Spark](https://spark.apache.org/docs/latest/index.html).
	JarUris []string `json:"jarUris,omitempty"`
	// The fully qualified name of a class in jar_uris, for example, com.example.wordcount. Exactly one of main_class and main_jar_uri field should be set for Java/Scala language type.
	MainClass *string `json:"mainClass,omitempty"`
	// The main file/jar URI of the Spark application. Exactly one of the definition_body field and the main_file_uri field must be set for Python.
	MainFileURI *string `json:"mainFileUri,omitempty"`
	// Configuration properties as a set of key/value pairs, which will be passed on to the Spark application. For more information, see [Apache Spark](https://spark.apache.org/docs/latest/index.html) and the [procedure option list](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#procedure_option_list).
	Properties map[string]string `json:"properties,omitempty"`
	// Python files to be placed on the PYTHONPATH for PySpark application. Supported file types: `.py`, `.egg`, and `.zip`. For more information about Apache Spark, see [Apache Spark](https://spark.apache.org/docs/latest/index.html).
	PyFileUris []string `json:"pyFileUris,omitempty"`
	// Runtime version. If not specified, the default runtime version is used.
	RuntimeVersion *string `json:"runtimeVersion,omitempty"`
}
