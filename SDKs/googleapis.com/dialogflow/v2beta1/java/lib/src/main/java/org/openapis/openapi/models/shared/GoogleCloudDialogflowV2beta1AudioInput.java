/* 
 * Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.
 */

package org.openapis.openapi.models.shared;

import com.fasterxml.jackson.annotation.JsonInclude.Include;
import com.fasterxml.jackson.annotation.JsonInclude;
import com.fasterxml.jackson.annotation.JsonProperty;

/**
 * GoogleCloudDialogflowV2beta1AudioInput - Represents the natural language speech audio to be processed.
 */
public class GoogleCloudDialogflowV2beta1AudioInput {
    /**
     * Required. The natural language speech audio to be processed. A single request can contain up to 1 minute of speech audio data. The transcribed text cannot contain more than 256 bytes for virtual agent interactions.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("audio")
    public String audio;
    public GoogleCloudDialogflowV2beta1AudioInput withAudio(String audio) {
        this.audio = audio;
        return this;
    }
    
    /**
     * Instructs the speech recognizer on how to process the audio content.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("config")
    public GoogleCloudDialogflowV2beta1InputAudioConfig config;
    public GoogleCloudDialogflowV2beta1AudioInput withConfig(GoogleCloudDialogflowV2beta1InputAudioConfig config) {
        this.config = config;
        return this;
    }
    
}
