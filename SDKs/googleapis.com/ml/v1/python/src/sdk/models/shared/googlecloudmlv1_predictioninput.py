"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from dataclasses_json import Undefined, dataclass_json
from enum import Enum
from sdk import utils
from typing import Optional

class GoogleCloudMlV1PredictionInputDataFormatEnum(str, Enum):
    r"""Required. The format of the input data files."""
    DATA_FORMAT_UNSPECIFIED = 'DATA_FORMAT_UNSPECIFIED'
    JSON = 'JSON'
    TEXT = 'TEXT'
    TF_RECORD = 'TF_RECORD'
    TF_RECORD_GZIP = 'TF_RECORD_GZIP'
    CSV = 'CSV'

class GoogleCloudMlV1PredictionInputOutputDataFormatEnum(str, Enum):
    r"""Optional. Format of the output data files, defaults to JSON."""
    DATA_FORMAT_UNSPECIFIED = 'DATA_FORMAT_UNSPECIFIED'
    JSON = 'JSON'
    TEXT = 'TEXT'
    TF_RECORD = 'TF_RECORD'
    TF_RECORD_GZIP = 'TF_RECORD_GZIP'
    CSV = 'CSV'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class GoogleCloudMlV1PredictionInput:
    r"""Represents input parameters for a prediction job."""
    
    batch_size: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('batchSize'), 'exclude': lambda f: f is None }})
    r"""Optional. Number of records per batch, defaults to 64. The service will buffer batch_size number of records in memory before invoking one Tensorflow prediction call internally. So take the record size and memory available into consideration when setting this parameter."""  
    data_format: Optional[GoogleCloudMlV1PredictionInputDataFormatEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('dataFormat'), 'exclude': lambda f: f is None }})
    r"""Required. The format of the input data files."""  
    input_paths: Optional[list[str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('inputPaths'), 'exclude': lambda f: f is None }})
    r"""Required. The Cloud Storage location of the input data files. May contain wildcards."""  
    max_worker_count: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('maxWorkerCount'), 'exclude': lambda f: f is None }})
    r"""Optional. The maximum number of workers to be used for parallel processing. Defaults to 10 if not specified."""  
    model_name: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('modelName'), 'exclude': lambda f: f is None }})
    r"""Use this field if you want to use the default version for the specified model. The string must use the following format: `\\"projects/YOUR_PROJECT/models/YOUR_MODEL\\"`"""  
    output_data_format: Optional[GoogleCloudMlV1PredictionInputOutputDataFormatEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('outputDataFormat'), 'exclude': lambda f: f is None }})
    r"""Optional. Format of the output data files, defaults to JSON."""  
    output_path: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('outputPath'), 'exclude': lambda f: f is None }})
    r"""Required. The output Google Cloud Storage location."""  
    region: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('region'), 'exclude': lambda f: f is None }})
    r"""Required. The Google Compute Engine region to run the prediction job in. See the available regions for AI Platform services."""  
    runtime_version: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('runtimeVersion'), 'exclude': lambda f: f is None }})
    r"""Optional. The AI Platform runtime version to use for this batch prediction. If not set, AI Platform will pick the runtime version used during the CreateVersion request for this model version, or choose the latest stable version when model version information is not available such as when the model is specified by uri."""  
    signature_name: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('signatureName'), 'exclude': lambda f: f is None }})
    r"""Optional. The name of the signature defined in the SavedModel to use for this job. Please refer to [SavedModel](https://tensorflow.github.io/serving/serving_basic.html) for information about how to use signatures. Defaults to [DEFAULT_SERVING_SIGNATURE_DEF_KEY](https://www.tensorflow.org/api_docs/python/tf/saved_model/signature_constants) , which is \\"serving_default\\"."""  
    uri: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('uri'), 'exclude': lambda f: f is None }})
    r"""Use this field if you want to specify a Google Cloud Storage path for the model to use."""  
    version_name: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('versionName'), 'exclude': lambda f: f is None }})
    r"""Use this field if you want to specify a version of the model to use. The string is formatted the same way as `model_version`, with the addition of the version information: `\\"projects/YOUR_PROJECT/models/YOUR_MODEL/versions/YOUR_VERSION\\"`"""  
    