"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
import requests as requests_http
from dataclasses_json import Undefined, dataclass_json
from sdk import utils
from typing import Any, Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class UploadArchiveRequestBody:
    
    body: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('body'), 'exclude': lambda f: f is None }})
    r"""The data to upload."""  
    

@dataclasses.dataclass
class UploadArchiveRequest:
    
    account_id: str = dataclasses.field(metadata={'path_param': { 'field_name': 'accountId', 'style': 'simple', 'explode': False }})
    r"""The <code>AccountId</code> value is the AWS account ID of the account that owns the vault. You can either specify an AWS account ID or optionally a single '<code>-</code>' (hyphen), in which case Amazon S3 Glacier uses the AWS account ID associated with the credentials used to sign the request. If you use an account ID, do not include any hyphens ('-') in the ID."""  
    request_body: UploadArchiveRequestBody = dataclasses.field(metadata={'request': { 'media_type': 'application/json' }})  
    vault_name: str = dataclasses.field(metadata={'path_param': { 'field_name': 'vaultName', 'style': 'simple', 'explode': False }})
    r"""The name of the vault."""  
    x_amz_algorithm: Optional[str] = dataclasses.field(default=None, metadata={'header': { 'field_name': 'X-Amz-Algorithm', 'style': 'simple', 'explode': False }})  
    x_amz_archive_description: Optional[str] = dataclasses.field(default=None, metadata={'header': { 'field_name': 'x-amz-archive-description', 'style': 'simple', 'explode': False }})
    r"""The optional description of the archive you are uploading."""  
    x_amz_content_sha256: Optional[str] = dataclasses.field(default=None, metadata={'header': { 'field_name': 'X-Amz-Content-Sha256', 'style': 'simple', 'explode': False }})  
    x_amz_credential: Optional[str] = dataclasses.field(default=None, metadata={'header': { 'field_name': 'X-Amz-Credential', 'style': 'simple', 'explode': False }})  
    x_amz_date: Optional[str] = dataclasses.field(default=None, metadata={'header': { 'field_name': 'X-Amz-Date', 'style': 'simple', 'explode': False }})  
    x_amz_security_token: Optional[str] = dataclasses.field(default=None, metadata={'header': { 'field_name': 'X-Amz-Security-Token', 'style': 'simple', 'explode': False }})  
    x_amz_sha256_tree_hash: Optional[str] = dataclasses.field(default=None, metadata={'header': { 'field_name': 'x-amz-sha256-tree-hash', 'style': 'simple', 'explode': False }})
    r"""The SHA256 tree hash of the data being uploaded."""  
    x_amz_signature: Optional[str] = dataclasses.field(default=None, metadata={'header': { 'field_name': 'X-Amz-Signature', 'style': 'simple', 'explode': False }})  
    x_amz_signed_headers: Optional[str] = dataclasses.field(default=None, metadata={'header': { 'field_name': 'X-Amz-SignedHeaders', 'style': 'simple', 'explode': False }})  
    

@dataclasses.dataclass
class UploadArchiveResponse:
    
    content_type: str = dataclasses.field()  
    status_code: int = dataclasses.field()  
    archive_creation_output: Optional[dict[str, Any]] = dataclasses.field(default=None)
    r"""Success"""  
    invalid_parameter_value_exception: Optional[Any] = dataclasses.field(default=None)
    r"""InvalidParameterValueException"""  
    missing_parameter_value_exception: Optional[Any] = dataclasses.field(default=None)
    r"""MissingParameterValueException"""  
    raw_response: Optional[requests_http.Response] = dataclasses.field(default=None)  
    request_timeout_exception: Optional[Any] = dataclasses.field(default=None)
    r"""RequestTimeoutException"""  
    resource_not_found_exception: Optional[Any] = dataclasses.field(default=None)
    r"""ResourceNotFoundException"""  
    service_unavailable_exception: Optional[Any] = dataclasses.field(default=None)
    r"""ServiceUnavailableException"""  
    