"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import flatteninstruction as shared_flatteninstruction
from ..shared import instructionoutput as shared_instructionoutput
from ..shared import pardoinstruction as shared_pardoinstruction
from ..shared import partialgroupbykeyinstruction as shared_partialgroupbykeyinstruction
from ..shared import readinstruction as shared_readinstruction
from ..shared import writeinstruction as shared_writeinstruction
from dataclasses_json import Undefined, dataclass_json
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class ParallelInstruction:
    r"""Describes a particular operation comprising a MapTask."""
    
    flatten: Optional[shared_flatteninstruction.FlattenInstruction] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('flatten'), 'exclude': lambda f: f is None }})
    r"""An instruction that copies its inputs (zero or more) to its (single) output."""  
    name: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('name'), 'exclude': lambda f: f is None }})
    r"""User-provided name of this operation."""  
    original_name: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('originalName'), 'exclude': lambda f: f is None }})
    r"""System-defined name for the operation in the original workflow graph."""  
    outputs: Optional[list[shared_instructionoutput.InstructionOutput]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('outputs'), 'exclude': lambda f: f is None }})
    r"""Describes the outputs of the instruction."""  
    par_do: Optional[shared_pardoinstruction.ParDoInstruction] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('parDo'), 'exclude': lambda f: f is None }})
    r"""An instruction that does a ParDo operation. Takes one main input and zero or more side inputs, and produces zero or more outputs. Runs user code."""  
    partial_group_by_key: Optional[shared_partialgroupbykeyinstruction.PartialGroupByKeyInstruction] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('partialGroupByKey'), 'exclude': lambda f: f is None }})
    r"""An instruction that does a partial group-by-key. One input and one output."""  
    read: Optional[shared_readinstruction.ReadInstruction] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('read'), 'exclude': lambda f: f is None }})
    r"""An instruction that reads records. Takes no inputs, produces one output."""  
    system_name: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('systemName'), 'exclude': lambda f: f is None }})
    r"""System-defined name of this operation. Unique across the workflow."""  
    write: Optional[shared_writeinstruction.WriteInstruction] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('write'), 'exclude': lambda f: f is None }})
    r"""An instruction that writes records. Takes one input, produces no outputs."""  
    