"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import classificationevaluationmetricsconfidencemetricsentry as shared_classificationevaluationmetricsconfidencemetricsentry
from ..shared import confusionmatrix as shared_confusionmatrix
from dataclasses_json import Undefined, dataclass_json
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class ClassificationEvaluationMetrics:
    r"""Model evaluation metrics for classification problems. Note: For Video Classification this metrics only describe quality of the Video Classification predictions of \\"segment_classification\\" type."""
    
    annotation_spec_id: Optional[list[str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('annotationSpecId'), 'exclude': lambda f: f is None }})
    r"""Output only. The annotation spec ids used for this evaluation."""  
    au_prc: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('auPrc'), 'exclude': lambda f: f is None }})
    r"""Output only. The Area Under Precision-Recall Curve metric. Micro-averaged for the overall evaluation."""  
    au_roc: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('auRoc'), 'exclude': lambda f: f is None }})
    r"""Output only. The Area Under Receiver Operating Characteristic curve metric. Micro-averaged for the overall evaluation."""  
    base_au_prc: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('baseAuPrc'), 'exclude': lambda f: f is None }})
    r"""Output only. The Area Under Precision-Recall Curve metric based on priors. Micro-averaged for the overall evaluation. Deprecated."""  
    confidence_metrics_entry: Optional[list[shared_classificationevaluationmetricsconfidencemetricsentry.ClassificationEvaluationMetricsConfidenceMetricsEntry]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('confidenceMetricsEntry'), 'exclude': lambda f: f is None }})
    r"""Output only. Metrics for each confidence_threshold in 0.00,0.05,0.10,...,0.95,0.96,0.97,0.98,0.99 and position_threshold = INT32_MAX_VALUE. ROC and precision-recall curves, and other aggregated metrics are derived from them. The confidence metrics entries may also be supplied for additional values of position_threshold, but from these no aggregated metrics are computed."""  
    confusion_matrix: Optional[shared_confusionmatrix.ConfusionMatrix] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('confusionMatrix'), 'exclude': lambda f: f is None }})
    r"""Confusion matrix of the model running the classification."""  
    log_loss: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('logLoss'), 'exclude': lambda f: f is None }})
    r"""Output only. The Log Loss metric."""  
    