// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package operations

import (
	"net/http"
	"openapi/pkg/models/shared"
)

type RecognizePrintedTextRequest struct {
	// A JSON document with a URL pointing to the image that is to be analyzed.
	ImageURL shared.ImageURL `request:"mediaType=application/json"`
	// Whether detect the text orientation in the image. With detectOrientation=true the OCR service tries to detect the image orientation and correct it before further processing (e.g. if it's upside-down).
	DetectOrientation bool `queryParam:"style=form,explode=true,name=detectOrientation"`
	// The BCP-47 language code of the text to be detected in the image. The default value is 'unk'.
	Language *shared.OcrLanguageEnum `queryParam:"style=form,explode=true,name=language"`
}

type RecognizePrintedTextResponse struct {
	// Error response.
	ComputerVisionError *shared.ComputerVisionError
	ContentType         string
	// The OCR results in the hierarchy of region/line/word. The results include text, bounding box for regions, lines and words. The angle, in degrees, of the detected text with respect to the closest horizontal or vertical direction. After rotating the input image clockwise by this angle, the recognized text lines become horizontal or vertical. In combination with the orientation property it can be used to overlay recognition results correctly on the original image, by rotating either the original image or recognition results by a suitable angle around the center of the original image. If the angle cannot be confidently detected, this property is not present. If the image contains text at different angles, only part of the text will be recognized correctly.
	OcrResult   *shared.OcrResult
	StatusCode  int
	RawResponse *http.Response
}
