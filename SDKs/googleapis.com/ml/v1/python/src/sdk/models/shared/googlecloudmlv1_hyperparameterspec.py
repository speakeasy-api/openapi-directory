"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import googlecloudmlv1_parameterspec as shared_googlecloudmlv1_parameterspec
from dataclasses_json import Undefined, dataclass_json
from enum import Enum
from sdk import utils
from typing import Optional

class GoogleCloudMlV1HyperparameterSpecAlgorithmEnum(str, Enum):
    r"""Optional. The search algorithm specified for the hyperparameter tuning job. Uses the default AI Platform hyperparameter tuning algorithm if unspecified."""
    ALGORITHM_UNSPECIFIED = 'ALGORITHM_UNSPECIFIED'
    GRID_SEARCH = 'GRID_SEARCH'
    RANDOM_SEARCH = 'RANDOM_SEARCH'

class GoogleCloudMlV1HyperparameterSpecGoalEnum(str, Enum):
    r"""Required. The type of goal to use for tuning. Available types are `MAXIMIZE` and `MINIMIZE`. Defaults to `MAXIMIZE`."""
    GOAL_TYPE_UNSPECIFIED = 'GOAL_TYPE_UNSPECIFIED'
    MAXIMIZE = 'MAXIMIZE'
    MINIMIZE = 'MINIMIZE'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class GoogleCloudMlV1HyperparameterSpec:
    r"""Represents a set of hyperparameters to optimize."""
    
    algorithm: Optional[GoogleCloudMlV1HyperparameterSpecAlgorithmEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('algorithm'), 'exclude': lambda f: f is None }})
    r"""Optional. The search algorithm specified for the hyperparameter tuning job. Uses the default AI Platform hyperparameter tuning algorithm if unspecified."""  
    enable_trial_early_stopping: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('enableTrialEarlyStopping'), 'exclude': lambda f: f is None }})
    r"""Optional. Indicates if the hyperparameter tuning job enables auto trial early stopping."""  
    goal: Optional[GoogleCloudMlV1HyperparameterSpecGoalEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('goal'), 'exclude': lambda f: f is None }})
    r"""Required. The type of goal to use for tuning. Available types are `MAXIMIZE` and `MINIMIZE`. Defaults to `MAXIMIZE`."""  
    hyperparameter_metric_tag: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('hyperparameterMetricTag'), 'exclude': lambda f: f is None }})
    r"""Optional. The TensorFlow summary tag name to use for optimizing trials. For current versions of TensorFlow, this tag name should exactly match what is shown in TensorBoard, including all scopes. For versions of TensorFlow prior to 0.12, this should be only the tag passed to tf.Summary. By default, \\"training/hptuning/metric\\" will be used."""  
    max_failed_trials: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('maxFailedTrials'), 'exclude': lambda f: f is None }})
    r"""Optional. The number of failed trials that need to be seen before failing the hyperparameter tuning job. You can specify this field to override the default failing criteria for AI Platform hyperparameter tuning jobs. Defaults to zero, which means the service decides when a hyperparameter job should fail."""  
    max_parallel_trials: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('maxParallelTrials'), 'exclude': lambda f: f is None }})
    r"""Optional. The number of training trials to run concurrently. You can reduce the time it takes to perform hyperparameter tuning by adding trials in parallel. However, each trail only benefits from the information gained in completed trials. That means that a trial does not get access to the results of trials running at the same time, which could reduce the quality of the overall optimization. Each trial will use the same scale tier and machine types. Defaults to one."""  
    max_trials: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('maxTrials'), 'exclude': lambda f: f is None }})
    r"""Optional. How many training trials should be attempted to optimize the specified hyperparameters. Defaults to one."""  
    params: Optional[list[shared_googlecloudmlv1_parameterspec.GoogleCloudMlV1ParameterSpec]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('params'), 'exclude': lambda f: f is None }})
    r"""Required. The set of parameters to tune."""  
    resume_previous_job_id: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('resumePreviousJobId'), 'exclude': lambda f: f is None }})
    r"""Optional. The prior hyperparameter tuning job id that users hope to continue with. The job id will be used to find the corresponding vizier study guid and resume the study."""  
    