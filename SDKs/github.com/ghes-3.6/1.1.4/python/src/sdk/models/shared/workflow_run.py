"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
import dateutil.parser
from ..shared import minimal_repository as shared_minimal_repository
from ..shared import nullable_simple_commit as shared_nullable_simple_commit
from ..shared import pull_request_minimal as shared_pull_request_minimal
from ..shared import referenced_workflow as shared_referenced_workflow
from ..shared import simple_user as shared_simple_user
from dataclasses_json import Undefined, dataclass_json
from datetime import datetime
from marshmallow import fields
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class WorkflowRun:
    r"""An invocation of a workflow"""
    
    artifacts_url: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('artifacts_url') }})
    r"""The URL to the artifacts for the workflow run."""  
    cancel_url: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('cancel_url') }})
    r"""The URL to cancel the workflow run."""  
    check_suite_url: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('check_suite_url') }})
    r"""The URL to the associated check suite."""  
    conclusion: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('conclusion') }})  
    created_at: datetime = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('created_at'), 'encoder': utils.datetimeisoformat(False), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso') }})  
    event: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('event') }})  
    head_branch: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('head_branch') }})  
    head_commit: shared_nullable_simple_commit.NullableSimpleCommit = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('head_commit') }})
    r"""A commit."""  
    head_repository: shared_minimal_repository.MinimalRepository = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('head_repository') }})
    r"""Minimal Repository"""  
    head_sha: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('head_sha') }})
    r"""The SHA of the head commit that points to the version of the workflow being run."""  
    html_url: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('html_url') }})  
    id: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('id') }})
    r"""The ID of the workflow run."""  
    jobs_url: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('jobs_url') }})
    r"""The URL to the jobs for the workflow run."""  
    logs_url: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('logs_url') }})
    r"""The URL to download the logs for the workflow run."""  
    node_id: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('node_id') }})  
    path: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('path') }})
    r"""The full path of the workflow"""  
    pull_requests: list[shared_pull_request_minimal.PullRequestMinimal] = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('pull_requests') }})  
    repository: shared_minimal_repository.MinimalRepository = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('repository') }})
    r"""Minimal Repository"""  
    rerun_url: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('rerun_url') }})
    r"""The URL to rerun the workflow run."""  
    run_number: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('run_number') }})
    r"""The auto incrementing run number for the workflow run."""  
    status: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('status') }})  
    updated_at: datetime = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('updated_at'), 'encoder': utils.datetimeisoformat(False), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso') }})  
    url: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('url') }})
    r"""The URL to the workflow run."""  
    workflow_id: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('workflow_id') }})
    r"""The ID of the parent workflow."""  
    workflow_url: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('workflow_url') }})
    r"""The URL to the workflow."""  
    actor: Optional[shared_simple_user.SimpleUser] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('actor'), 'exclude': lambda f: f is None }})
    r"""A GitHub user."""  
    check_suite_id: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('check_suite_id'), 'exclude': lambda f: f is None }})
    r"""The ID of the associated check suite."""  
    check_suite_node_id: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('check_suite_node_id'), 'exclude': lambda f: f is None }})
    r"""The node ID of the associated check suite."""  
    head_repository_id: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('head_repository_id'), 'exclude': lambda f: f is None }})  
    name: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('name'), 'exclude': lambda f: f is None }})
    r"""The name of the workflow run."""  
    previous_attempt_url: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('previous_attempt_url'), 'exclude': lambda f: f is None }})
    r"""The URL to the previous attempted run of this workflow, if one exists."""  
    referenced_workflows: Optional[list[shared_referenced_workflow.ReferencedWorkflow]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('referenced_workflows'), 'exclude': lambda f: f is None }})  
    run_attempt: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('run_attempt'), 'exclude': lambda f: f is None }})
    r"""Attempt number of the run, 1 for first attempt and higher if the workflow was re-run."""  
    run_started_at: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('run_started_at'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})
    r"""The start time of the latest run. Resets on re-run."""  
    triggering_actor: Optional[shared_simple_user.SimpleUser] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('triggering_actor'), 'exclude': lambda f: f is None }})
    r"""A GitHub user."""  
    