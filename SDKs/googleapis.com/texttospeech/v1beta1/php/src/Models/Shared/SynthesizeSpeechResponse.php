<?php

/**
 * Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.
 */

declare(strict_types=1);

namespace OpenAPI\OpenAPI\Models\Shared;


/**
 * SynthesizeSpeechResponse - The message returned to the client by the `SynthesizeSpeech` method.
 * 
 * @package OpenAPI\OpenAPI\Models\Shared
 * @access public
 */
class SynthesizeSpeechResponse
{
    /**
     * Description of audio data to be synthesized.
     * 
     * @var ?\OpenAPI\OpenAPI\Models\Shared\AudioConfig $audioConfig
     */
	#[\JMS\Serializer\Annotation\SerializedName('audioConfig')]
    #[\JMS\Serializer\Annotation\Type('OpenAPI\OpenAPI\Models\Shared\AudioConfig')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public ?AudioConfig $audioConfig = null;
    
    /**
     * The audio data bytes encoded as specified in the request, including the header for encodings that are wrapped in containers (e.g. MP3, OGG_OPUS). For LINEAR16 audio, we include the WAV header. Note: as with all bytes fields, protobuffers use a pure binary representation, whereas JSON representations use base64.
     * 
     * @var ?string $audioContent
     */
	#[\JMS\Serializer\Annotation\SerializedName('audioContent')]
    #[\JMS\Serializer\Annotation\Type('string')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public ?string $audioContent = null;
    
    /**
     * A link between a position in the original request input and a corresponding time in the output audio. It's only supported via `` of SSML input.
     * 
     * @var ?array<\OpenAPI\OpenAPI\Models\Shared\Timepoint> $timepoints
     */
	#[\JMS\Serializer\Annotation\SerializedName('timepoints')]
    #[\JMS\Serializer\Annotation\Type('array<OpenAPI\OpenAPI\Models\Shared\Timepoint>')]
    #[\JMS\Serializer\Annotation\SkipWhenEmpty]
    public ?array $timepoints = null;
    
	public function __construct()
	{
		$this->audioConfig = null;
		$this->audioContent = null;
		$this->timepoints = null;
	}
}
