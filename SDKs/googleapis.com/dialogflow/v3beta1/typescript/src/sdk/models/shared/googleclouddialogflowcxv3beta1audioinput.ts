/*
 * Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.
 */

import { SpeakeasyBase, SpeakeasyMetadata } from "../../../internal/utils";
import { GoogleCloudDialogflowCxV3beta1InputAudioConfig } from "./googleclouddialogflowcxv3beta1inputaudioconfig";
import { Expose, Type } from "class-transformer";

/**
 * Represents the natural speech audio to be processed.
 */
export class GoogleCloudDialogflowCxV3beta1AudioInput extends SpeakeasyBase {
  /**
   * The natural language speech audio to be processed. A single request can contain up to 2 minutes of speech audio data. The transcribed text cannot contain more than 256 bytes. For non-streaming audio detect intent, both `config` and `audio` must be provided. For streaming audio detect intent, `config` must be provided in the first request and `audio` must be provided in all following requests.
   */
  @SpeakeasyMetadata()
  @Expose({ name: "audio" })
  audio?: string;

  /**
   * Instructs the speech recognizer on how to process the audio content.
   */
  @SpeakeasyMetadata()
  @Expose({ name: "config" })
  @Type(() => GoogleCloudDialogflowCxV3beta1InputAudioConfig)
  config?: GoogleCloudDialogflowCxV3beta1InputAudioConfig;
}
