"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

import requests as requests_http
from . import utils
from sdk.models import operations, shared
from typing import Any, Optional

class Analysis:
    _client: requests_http.Session
    _security_client: requests_http.Session
    _server_url: str
    _language: str
    _sdk_version: str
    _gen_version: str

    def __init__(self, client: requests_http.Session, security_client: requests_http.Session, server_url: str, language: str, sdk_version: str, gen_version: str) -> None:
        self._client = client
        self._security_client = security_client
        self._server_url = server_url
        self._language = language
        self._sdk_version = sdk_version
        self._gen_version = gen_version
        
    def create_urls_export(self, request: operations.CreateUrlsExportRequest) -> operations.CreateUrlsExportResponse:
        r"""Creates a new UrlExport object and starts a task that will export the results into a csv
        Creates a new UrlExport object and starts a task that will export the results into a csv. Returns the model id that manages the task
        """
        base_url = self._server_url
        
        url = utils.generate_url(operations.CreateUrlsExportRequest, base_url, '/analyses/{username}/{project_slug}/{analysis_slug}/urls/export', request)
        
        headers = {}
        req_content_type, data, form = utils.serialize_request_body(request, "urls_query", 'json')
        if req_content_type not in ('multipart/form-data', 'multipart/mixed'):
            headers['content-type'] = req_content_type
        query_params = utils.get_query_params(operations.CreateUrlsExportRequest, request)
        
        client = self._security_client
        
        http_res = client.request('POST', url, params=query_params, data=data, files=form, headers=headers)
        content_type = http_res.headers.get('Content-Type')

        res = operations.CreateUrlsExportResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 201:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.CsvExportStatus])
                res.csv_export_status = out
        else:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.DefaultPayload])
                res.default_payload = out

        return res

    def get_analysis_summary(self, request: operations.GetAnalysisSummaryRequest) -> operations.GetAnalysisSummaryResponse:
        r"""Get an Analysis detail
        Get an Analysis detail
        """
        base_url = self._server_url
        
        url = utils.generate_url(operations.GetAnalysisSummaryRequest, base_url, '/analyses/{username}/{project_slug}/{analysis_slug}', request)
        
        
        client = self._security_client
        
        http_res = client.request('GET', url)
        content_type = http_res.headers.get('Content-Type')

        res = operations.GetAnalysisSummaryResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.AnalysisDetail])
                res.analysis_detail = out
        else:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.DefaultPayload])
                res.default_payload = out

        return res

    def get_crawl_statistics(self, request: operations.GetCrawlStatisticsRequest) -> operations.GetCrawlStatisticsResponse:
        r"""Return global statistics for an analysis
        Return global statistics for an analysis
        """
        base_url = self._server_url
        
        url = utils.generate_url(operations.GetCrawlStatisticsRequest, base_url, '/analyses/{username}/{project_slug}/{analysis_slug}/crawl_statistics', request)
        
        
        client = self._security_client
        
        http_res = client.request('GET', url)
        content_type = http_res.headers.get('Content-Type')

        res = operations.GetCrawlStatisticsResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.CrawlStatistics])
                res.crawl_statistics = out
        else:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.DefaultPayload])
                res.default_payload = out

        return res

    def get_crawl_statistics_by_frequency(self, request: operations.GetCrawlStatisticsByFrequencyRequest) -> operations.GetCrawlStatisticsByFrequencyResponse:
        r"""Return crawl statistics grouped by time frequency (1 min, 5 mins or 60 min)
        Return crawl statistics grouped by time frequency (1 min, 5 mins or 60 min) for an analysis
        """
        base_url = self._server_url
        
        url = utils.generate_url(operations.GetCrawlStatisticsByFrequencyRequest, base_url, '/analyses/{username}/{project_slug}/{analysis_slug}/crawl_statistics/time', request)
        
        query_params = utils.get_query_params(operations.GetCrawlStatisticsByFrequencyRequest, request)
        
        client = self._security_client
        
        http_res = client.request('GET', url, params=query_params)
        content_type = http_res.headers.get('Content-Type')

        res = operations.GetCrawlStatisticsByFrequencyResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.CrawlStatisticsTime])
                res.crawl_statistics_time = out
        else:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.DefaultPayload])
                res.default_payload = out

        return res

    def get_crawl_statistics_urls(self, request: operations.GetCrawlStatisticsUrlsRequest) -> operations.GetCrawlStatisticsUrlsResponse:
        r"""Return a list of 1000 latest URLs crawled (all crawled URLs or only URLS with HTTP errors)
        Return a list of 1000 latest URLs crawled (all crawled URLs or only URLS with HTTP errors)
        """
        base_url = self._server_url
        
        url = utils.generate_url(operations.GetCrawlStatisticsUrlsRequest, base_url, '/analyses/{username}/{project_slug}/{analysis_slug}/crawl_statistics/urls/{list_type}', request)
        
        
        client = self._security_client
        
        http_res = client.request('GET', url)
        content_type = http_res.headers.get('Content-Type')

        res = operations.GetCrawlStatisticsUrlsResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[list[Any]])
                res.get_crawl_statistics_urls_200_application_json_anies = out
        else:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.DefaultPayload])
                res.default_payload = out

        return res

    def get_ganalytics_orphan_ur_ls(self, request: operations.GetGanalyticsOrphanURLsRequest) -> operations.GetGanalyticsOrphanURLsResponse:
        r"""List of Orphan URLs
        List of Orphan URLs. URLs which generated visits from the selected source according to Google Analytics data, but were not crawled with by the Botify crawler (either because no links to them were found on the website, or because the crawler was not allowed to follow these links according to the project settings).   For a search engine (medium: origanic; sources: all, aol, ask, baidu, bing, google, naver, yahoo, yandex) or a social network (medium: social; sources: all, facebook, google+, linkedin, pinterest, reddit, tumblr, twitter)
        """
        base_url = self._server_url
        
        url = utils.generate_url(operations.GetGanalyticsOrphanURLsRequest, base_url, '/analyses/{username}/{project_slug}/{analysis_slug}/features/ganalytics/orphan_urls/{medium}/{source}', request)
        
        query_params = utils.get_query_params(operations.GetGanalyticsOrphanURLsRequest, request)
        
        client = self._security_client
        
        http_res = client.request('GET', url, params=query_params)
        content_type = http_res.headers.get('Content-Type')

        res = operations.GetGanalyticsOrphanURLsResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[operations.GetGanalyticsOrphanURLs200ApplicationJSON])
                res.get_ganalytics_orphan_ur_ls_200_application_json_object = out
        else:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.DefaultPayload])
                res.default_payload = out

        return res

    def get_links_percentiles(self, request: operations.GetLinksPercentilesRequest) -> operations.GetLinksPercentilesResponse:
        r"""Get inlinks percentiles
        Get inlinks percentiles
        """
        base_url = self._server_url
        
        url = utils.generate_url(operations.GetLinksPercentilesRequest, base_url, '/analyses/{username}/{project_slug}/{analysis_slug}/features/links/percentiles', request)
        
        
        client = self._security_client
        
        http_res = client.request('GET', url)
        content_type = http_res.headers.get('Content-Type')

        res = operations.GetLinksPercentilesResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.LinksPercentiles])
                res.links_percentiles = out
        else:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.DefaultPayload])
                res.default_payload = out

        return res

    def get_links_top_domains(self, request: operations.GetLinksTopDomainsRequest) -> operations.GetLinksTopDomainsResponse:
        r"""Top domains
        Top domains
        """
        base_url = self._server_url
        
        url = utils.generate_url(operations.GetLinksTopDomainsRequest, base_url, '/analyses/{username}/{project_slug}/{analysis_slug}/features/top_domains/domains', request)
        
        query_params = utils.get_query_params(operations.GetLinksTopDomainsRequest, request)
        
        client = self._security_client
        
        http_res = client.request('GET', url, params=query_params)
        content_type = http_res.headers.get('Content-Type')

        res = operations.GetLinksTopDomainsResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[operations.GetLinksTopDomains200ApplicationJSON])
                res.get_links_top_domains_200_application_json_object = out
        else:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.DefaultPayload])
                res.default_payload = out

        return res

    def get_links_top_subdomains(self, request: operations.GetLinksTopSubdomainsRequest) -> operations.GetLinksTopSubdomainsResponse:
        r"""Top subddomains
        Top subddomains
        """
        base_url = self._server_url
        
        url = utils.generate_url(operations.GetLinksTopSubdomainsRequest, base_url, '/analyses/{username}/{project_slug}/{analysis_slug}/features/top_domains/subdomains', request)
        
        query_params = utils.get_query_params(operations.GetLinksTopSubdomainsRequest, request)
        
        client = self._security_client
        
        http_res = client.request('GET', url, params=query_params)
        content_type = http_res.headers.get('Content-Type')

        res = operations.GetLinksTopSubdomainsResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[operations.GetLinksTopSubdomains200ApplicationJSON])
                res.get_links_top_subdomains_200_application_json_object = out
        else:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.DefaultPayload])
                res.default_payload = out

        return res

    def get_page_rank_lost(self, request: operations.GetPageRankLostRequest) -> operations.GetPageRankLostResponse:
        r"""Lost pagerank
        Lost pagerank
        """
        base_url = self._server_url
        
        url = utils.generate_url(operations.GetPageRankLostRequest, base_url, '/analyses/{username}/{project_slug}/{analysis_slug}/features/pagerank/lost', request)
        
        
        client = self._security_client
        
        http_res = client.request('GET', url)
        content_type = http_res.headers.get('Content-Type')

        res = operations.GetPageRankLostResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.PageRankLost])
                res.page_rank_lost = out
        else:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.DefaultPayload])
                res.default_payload = out

        return res

    def get_sitemaps_report(self, request: operations.GetSitemapsReportRequest) -> operations.GetSitemapsReportResponse:
        r"""Get global information of the sitemaps found (sitemaps indexes, invalid sitemaps urls, etc
        Get global information of the sitemaps found (sitemaps indexes, invalid sitemaps urls, etc.)
        """
        base_url = self._server_url
        
        url = utils.generate_url(operations.GetSitemapsReportRequest, base_url, '/analyses/{username}/{project_slug}/{analysis_slug}/features/sitemaps/report', request)
        
        
        client = self._security_client
        
        http_res = client.request('GET', url)
        content_type = http_res.headers.get('Content-Type')

        res = operations.GetSitemapsReportResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.SitemapsReport])
                res.sitemaps_report = out
        else:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.DefaultPayload])
                res.default_payload = out

        return res

    def get_sitemaps_samples_out_of_config(self, request: operations.GetSitemapsSamplesOutOfConfigRequest) -> operations.GetSitemapsSamplesOutOfConfigResponse:
        r"""Sample list of URLs which were found in your sitemaps but outside of the
        Sample list of URLs which were found in your sitemaps but outside of the crawl perimeter defined for the project, for instance domain/subdomain or protocol (HTTP/HTTPS) not allowed in the crawl settings.
        """
        base_url = self._server_url
        
        url = utils.generate_url(operations.GetSitemapsSamplesOutOfConfigRequest, base_url, '/analyses/{username}/{project_slug}/{analysis_slug}/features/sitemaps/samples/out_of_config', request)
        
        query_params = utils.get_query_params(operations.GetSitemapsSamplesOutOfConfigRequest, request)
        
        client = self._security_client
        
        http_res = client.request('GET', url, params=query_params)
        content_type = http_res.headers.get('Content-Type')

        res = operations.GetSitemapsSamplesOutOfConfigResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[operations.GetSitemapsSamplesOutOfConfig200ApplicationJSON])
                res.get_sitemaps_samples_out_of_config_200_application_json_object = out
        else:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.DefaultPayload])
                res.default_payload = out

        return res

    def get_sitemaps_samples_sitemaps_only(self, request: operations.GetSitemapsSamplesSitemapsOnlyRequest) -> operations.GetSitemapsSamplesSitemapsOnlyResponse:
        r"""Sample list of URLs which were found in your sitemaps, within the project
        Sample list of URLs which were found in your sitemaps, within the project allowed scope (allowed domains/subdomains/protocols), but not found by the Botify crawler.
        """
        base_url = self._server_url
        
        url = utils.generate_url(operations.GetSitemapsSamplesSitemapsOnlyRequest, base_url, '/analyses/{username}/{project_slug}/{analysis_slug}/features/sitemaps/samples/sitemap_only', request)
        
        query_params = utils.get_query_params(operations.GetSitemapsSamplesSitemapsOnlyRequest, request)
        
        client = self._security_client
        
        http_res = client.request('GET', url, params=query_params)
        content_type = http_res.headers.get('Content-Type')

        res = operations.GetSitemapsSamplesSitemapsOnlyResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[operations.GetSitemapsSamplesSitemapsOnly200ApplicationJSON])
                res.get_sitemaps_samples_sitemaps_only_200_application_json_object = out
        else:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.DefaultPayload])
                res.default_payload = out

        return res

    def get_url_detail(self, request: operations.GetURLDetailRequest) -> operations.GetURLDetailResponse:
        r"""Gets the detail of an URL for an analysis
        Gets the detail of an URL for an analysis
        """
        base_url = self._server_url
        
        url = utils.generate_url(operations.GetURLDetailRequest, base_url, '/analyses/{username}/{project_slug}/{analysis_slug}/urls/{url}', request)
        
        query_params = utils.get_query_params(operations.GetURLDetailRequest, request)
        
        client = self._security_client
        
        http_res = client.request('GET', url, params=query_params)
        content_type = http_res.headers.get('Content-Type')

        res = operations.GetURLDetailResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[dict[str, Any]])
                res.url_detail = out
        else:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.DefaultPayload])
                res.default_payload = out

        return res

    def get_urls(self, request: operations.GetUrlsRequest) -> operations.GetUrlsResponse:
        r"""Executes a query and returns a paginated response
        Executes a query and returns a paginated response
        """
        base_url = self._server_url
        
        url = utils.generate_url(operations.GetUrlsRequest, base_url, '/analyses/{username}/{project_slug}/{analysis_slug}/urls', request)
        
        headers = {}
        req_content_type, data, form = utils.serialize_request_body(request, "urls_query", 'json')
        if req_content_type not in ('multipart/form-data', 'multipart/mixed'):
            headers['content-type'] = req_content_type
        query_params = utils.get_query_params(operations.GetUrlsRequest, request)
        
        client = self._security_client
        
        http_res = client.request('POST', url, params=query_params, data=data, files=form, headers=headers)
        content_type = http_res.headers.get('Content-Type')

        res = operations.GetUrlsResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[operations.GetUrls200ApplicationJSON])
                res.get_urls_200_application_json_object = out
        else:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.DefaultPayload])
                res.default_payload = out

        return res

    def get_urls_aggs(self, request: operations.GetUrlsAggsRequest) -> operations.GetUrlsAggsResponse:
        r"""Query aggregator
        Query aggregator. It accepts multiple queries
        """
        base_url = self._server_url
        
        url = utils.generate_url(operations.GetUrlsAggsRequest, base_url, '/analyses/{username}/{project_slug}/{analysis_slug}/urls/aggs', request)
        
        headers = {}
        req_content_type, data, form = utils.serialize_request_body(request, "request_body", 'json')
        if req_content_type not in ('multipart/form-data', 'multipart/mixed'):
            headers['content-type'] = req_content_type
        query_params = utils.get_query_params(operations.GetUrlsAggsRequest, request)
        
        client = self._security_client
        
        http_res = client.request('POST', url, params=query_params, data=data, files=form, headers=headers)
        content_type = http_res.headers.get('Content-Type')

        res = operations.GetUrlsAggsResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[list[Any]])
                res.get_urls_aggs_200_application_json_anies = out
        else:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.DefaultPayload])
                res.default_payload = out

        return res

    def get_urls_datamodel(self, request: operations.GetUrlsDatamodelRequest) -> operations.GetUrlsDatamodelResponse:
        r"""Gets an Analysis datamodel
        Gets an Analysis datamodel
        """
        base_url = self._server_url
        
        url = utils.generate_url(operations.GetUrlsDatamodelRequest, base_url, '/analyses/{username}/{project_slug}/{analysis_slug}/urls/datamodel', request)
        
        query_params = utils.get_query_params(operations.GetUrlsDatamodelRequest, request)
        
        client = self._security_client
        
        http_res = client.request('GET', url, params=query_params)
        content_type = http_res.headers.get('Content-Type')

        res = operations.GetUrlsDatamodelResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.CrawlDatamodel])
                res.crawl_datamodel = out
        else:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.DefaultPayload])
                res.default_payload = out

        return res

    def get_urls_export_status(self, request: operations.GetUrlsExportStatusRequest) -> operations.GetUrlsExportStatusResponse:
        r"""Checks the status of an CSVUrlExportJob object
        Checks the status of an CSVUrlExportJob object. Returns json object with the status.
        """
        base_url = self._server_url
        
        url = utils.generate_url(operations.GetUrlsExportStatusRequest, base_url, '/analyses/{username}/{project_slug}/{analysis_slug}/urls/export/{url_export_id}', request)
        
        
        client = self._security_client
        
        http_res = client.request('GET', url)
        content_type = http_res.headers.get('Content-Type')

        res = operations.GetUrlsExportStatusResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.CsvExportStatus])
                res.csv_export_status = out
        else:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.DefaultPayload])
                res.default_payload = out

        return res

    def get_urls_exports(self, request: operations.GetUrlsExportsRequest) -> operations.GetUrlsExportsResponse:
        r"""A list of the CSV Exports requests and their current status
        A list of the CSV Exports requests and their current status
        """
        base_url = self._server_url
        
        url = utils.generate_url(operations.GetUrlsExportsRequest, base_url, '/analyses/{username}/{project_slug}/{analysis_slug}/urls/export', request)
        
        query_params = utils.get_query_params(operations.GetUrlsExportsRequest, request)
        
        client = self._security_client
        
        http_res = client.request('GET', url, params=query_params)
        content_type = http_res.headers.get('Content-Type')

        res = operations.GetUrlsExportsResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[operations.GetUrlsExports200ApplicationJSON])
                res.get_urls_exports_200_application_json_object = out
        else:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.DefaultPayload])
                res.default_payload = out

        return res

    def get_urls_suggested_filters(self, request: operations.GetUrlsSuggestedFiltersRequest) -> operations.GetUrlsSuggestedFiltersResponse:
        r"""Return most frequent segments (= suggested patterns in the previous version)
        Return most frequent segments (= suggested patterns in the previous version) for a Botify Query.
        """
        base_url = self._server_url
        
        url = utils.generate_url(operations.GetUrlsSuggestedFiltersRequest, base_url, '/analyses/{username}/{project_slug}/{analysis_slug}/urls/suggested_filters', request)
        
        headers = {}
        req_content_type, data, form = utils.serialize_request_body(request, "urls_aggs_query", 'json')
        if req_content_type not in ('multipart/form-data', 'multipart/mixed'):
            headers['content-type'] = req_content_type
        query_params = utils.get_query_params(operations.GetUrlsSuggestedFiltersRequest, request)
        
        client = self._security_client
        
        http_res = client.request('POST', url, params=query_params, data=data, files=form, headers=headers)
        content_type = http_res.headers.get('Content-Type')

        res = operations.GetUrlsSuggestedFiltersResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 201:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.UrlsAggsQuery])
                res.urls_aggs_query = out
        else:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.DefaultPayload])
                res.default_payload = out

        return res

    