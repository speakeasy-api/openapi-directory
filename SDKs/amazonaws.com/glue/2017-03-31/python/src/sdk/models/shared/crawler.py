"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
import dateutil.parser
from ..shared import crawlerstate_enum as shared_crawlerstate_enum
from ..shared import crawlertargets as shared_crawlertargets
from ..shared import lakeformationconfiguration as shared_lakeformationconfiguration
from ..shared import lastcrawlinfo as shared_lastcrawlinfo
from ..shared import lineageconfiguration as shared_lineageconfiguration
from ..shared import recrawlpolicy as shared_recrawlpolicy
from ..shared import schedule as shared_schedule
from ..shared import schemachangepolicy as shared_schemachangepolicy
from dataclasses_json import Undefined, dataclass_json
from datetime import datetime
from marshmallow import fields
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class Crawler:
    r"""Specifies a crawler program that examines a data source and uses classifiers to try to determine its schema. If successful, the crawler records metadata concerning the data source in the Glue Data Catalog."""
    
    classifiers: Optional[list[str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('Classifiers'), 'exclude': lambda f: f is None }})  
    configuration: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('Configuration'), 'exclude': lambda f: f is None }})  
    crawl_elapsed_time: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('CrawlElapsedTime'), 'exclude': lambda f: f is None }})  
    crawler_security_configuration: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('CrawlerSecurityConfiguration'), 'exclude': lambda f: f is None }})  
    creation_time: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('CreationTime'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})  
    database_name: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('DatabaseName'), 'exclude': lambda f: f is None }})  
    description: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('Description'), 'exclude': lambda f: f is None }})  
    lake_formation_configuration: Optional[shared_lakeformationconfiguration.LakeFormationConfiguration] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('LakeFormationConfiguration'), 'exclude': lambda f: f is None }})  
    last_crawl: Optional[shared_lastcrawlinfo.LastCrawlInfo] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('LastCrawl'), 'exclude': lambda f: f is None }})  
    last_updated: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('LastUpdated'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})  
    lineage_configuration: Optional[shared_lineageconfiguration.LineageConfiguration] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('LineageConfiguration'), 'exclude': lambda f: f is None }})  
    name: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('Name'), 'exclude': lambda f: f is None }})  
    recrawl_policy: Optional[shared_recrawlpolicy.RecrawlPolicy] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('RecrawlPolicy'), 'exclude': lambda f: f is None }})  
    role: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('Role'), 'exclude': lambda f: f is None }})  
    schedule: Optional[shared_schedule.Schedule] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('Schedule'), 'exclude': lambda f: f is None }})  
    schema_change_policy: Optional[shared_schemachangepolicy.SchemaChangePolicy] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('SchemaChangePolicy'), 'exclude': lambda f: f is None }})  
    state: Optional[shared_crawlerstate_enum.CrawlerStateEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('State'), 'exclude': lambda f: f is None }})  
    table_prefix: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('TablePrefix'), 'exclude': lambda f: f is None }})  
    targets: Optional[shared_crawlertargets.CrawlerTargets] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('Targets'), 'exclude': lambda f: f is None }})  
    version: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('Version'), 'exclude': lambda f: f is None }})  
    