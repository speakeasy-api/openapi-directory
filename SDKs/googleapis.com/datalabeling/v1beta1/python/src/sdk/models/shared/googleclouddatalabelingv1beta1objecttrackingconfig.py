"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from dataclasses_json import Undefined, dataclass_json
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class GoogleCloudDatalabelingV1beta1ObjectTrackingConfig:
    r"""Config for video object tracking human labeling task."""
    
    annotation_spec_set: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('annotationSpecSet'), 'exclude': lambda f: f is None }})
    r"""Required. Annotation spec set resource name."""  
    clip_length: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('clipLength'), 'exclude': lambda f: f is None }})
    r"""Videos will be cut to smaller clips to make it easier for labelers to work on. Users can configure is field in seconds, if not set, default value is 20s."""  
    overlap_length: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('overlapLength'), 'exclude': lambda f: f is None }})
    r"""The overlap length between different video clips. Users can configure is field in seconds, if not set, default value is 0.3s."""  
    