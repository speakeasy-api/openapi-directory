// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
)

// GPUSharingConfigGPUSharingStrategyEnum - The type of GPU sharing strategy to enable on the GPU node.
type GPUSharingConfigGPUSharingStrategyEnum string

const (
	GPUSharingConfigGPUSharingStrategyEnumGpuSharingStrategyUnspecified GPUSharingConfigGPUSharingStrategyEnum = "GPU_SHARING_STRATEGY_UNSPECIFIED"
	GPUSharingConfigGPUSharingStrategyEnumTimeSharing                   GPUSharingConfigGPUSharingStrategyEnum = "TIME_SHARING"
)

func (e *GPUSharingConfigGPUSharingStrategyEnum) UnmarshalJSON(data []byte) error {
	var s string
	if err := json.Unmarshal(data, &s); err != nil {
		return err
	}
	switch s {
	case "GPU_SHARING_STRATEGY_UNSPECIFIED":
		fallthrough
	case "TIME_SHARING":
		*e = GPUSharingConfigGPUSharingStrategyEnum(s)
		return nil
	default:
		return fmt.Errorf("invalid value for GPUSharingConfigGPUSharingStrategyEnum: %s", s)
	}
}

// GPUSharingConfig - GPUSharingConfig represents the GPU sharing configuration for Hardware Accelerators.
type GPUSharingConfig struct {
	// The type of GPU sharing strategy to enable on the GPU node.
	GpuSharingStrategy *GPUSharingConfigGPUSharingStrategyEnum `json:"gpuSharingStrategy,omitempty"`
	// The max number of containers that can share a physical GPU.
	MaxSharedClientsPerGpu *string `json:"maxSharedClientsPerGpu,omitempty"`
}
