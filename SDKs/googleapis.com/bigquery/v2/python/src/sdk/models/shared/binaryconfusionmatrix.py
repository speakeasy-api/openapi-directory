"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from dataclasses_json import Undefined, dataclass_json
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class BinaryConfusionMatrix:
    r"""Confusion matrix for binary classification models."""
    
    accuracy: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('accuracy'), 'exclude': lambda f: f is None }})
    r"""The fraction of predictions given the correct label."""  
    f1_score: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('f1Score'), 'exclude': lambda f: f is None }})
    r"""The equally weighted average of recall and precision."""  
    false_negatives: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('falseNegatives'), 'exclude': lambda f: f is None }})
    r"""Number of false samples predicted as false."""  
    false_positives: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('falsePositives'), 'exclude': lambda f: f is None }})
    r"""Number of false samples predicted as true."""  
    positive_class_threshold: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('positiveClassThreshold'), 'exclude': lambda f: f is None }})
    r"""Threshold value used when computing each of the following metric."""  
    precision: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('precision'), 'exclude': lambda f: f is None }})
    r"""The fraction of actual positive predictions that had positive actual labels."""  
    recall: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('recall'), 'exclude': lambda f: f is None }})
    r"""The fraction of actual positive labels that were given a positive prediction."""  
    true_negatives: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('trueNegatives'), 'exclude': lambda f: f is None }})
    r"""Number of true samples predicted as false."""  
    true_positives: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('truePositives'), 'exclude': lambda f: f is None }})
    r"""Number of true samples predicted as true."""  
    