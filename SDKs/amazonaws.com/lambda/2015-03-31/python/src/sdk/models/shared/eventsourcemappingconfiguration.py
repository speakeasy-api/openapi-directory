"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
import dateutil.parser
from ..shared import amazonmanagedkafkaeventsourceconfig as shared_amazonmanagedkafkaeventsourceconfig
from ..shared import destinationconfig as shared_destinationconfig
from ..shared import documentdbeventsourceconfig as shared_documentdbeventsourceconfig
from ..shared import eventsourceposition_enum as shared_eventsourceposition_enum
from ..shared import filtercriteria as shared_filtercriteria
from ..shared import functionresponsetype_enum as shared_functionresponsetype_enum
from ..shared import scalingconfig as shared_scalingconfig
from ..shared import selfmanagedeventsource as shared_selfmanagedeventsource
from ..shared import selfmanagedkafkaeventsourceconfig as shared_selfmanagedkafkaeventsourceconfig
from ..shared import sourceaccessconfiguration as shared_sourceaccessconfiguration
from dataclasses_json import Undefined, dataclass_json
from datetime import datetime
from marshmallow import fields
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class EventSourceMappingConfiguration:
    r"""A mapping between an Amazon Web Services resource and a Lambda function. For details, see <a>CreateEventSourceMapping</a>."""
    
    amazon_managed_kafka_event_source_config: Optional[shared_amazonmanagedkafkaeventsourceconfig.AmazonManagedKafkaEventSourceConfig] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('AmazonManagedKafkaEventSourceConfig'), 'exclude': lambda f: f is None }})  
    batch_size: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('BatchSize'), 'exclude': lambda f: f is None }})  
    bisect_batch_on_function_error: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('BisectBatchOnFunctionError'), 'exclude': lambda f: f is None }})  
    destination_config: Optional[shared_destinationconfig.DestinationConfig] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('DestinationConfig'), 'exclude': lambda f: f is None }})  
    document_db_event_source_config: Optional[shared_documentdbeventsourceconfig.DocumentDBEventSourceConfig] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('DocumentDBEventSourceConfig'), 'exclude': lambda f: f is None }})  
    event_source_arn: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('EventSourceArn'), 'exclude': lambda f: f is None }})  
    filter_criteria: Optional[shared_filtercriteria.FilterCriteria] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('FilterCriteria'), 'exclude': lambda f: f is None }})  
    function_arn: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('FunctionArn'), 'exclude': lambda f: f is None }})  
    function_response_types: Optional[list[shared_functionresponsetype_enum.FunctionResponseTypeEnum]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('FunctionResponseTypes'), 'exclude': lambda f: f is None }})  
    last_modified: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('LastModified'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})  
    last_processing_result: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('LastProcessingResult'), 'exclude': lambda f: f is None }})  
    maximum_batching_window_in_seconds: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('MaximumBatchingWindowInSeconds'), 'exclude': lambda f: f is None }})  
    maximum_record_age_in_seconds: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('MaximumRecordAgeInSeconds'), 'exclude': lambda f: f is None }})  
    maximum_retry_attempts: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('MaximumRetryAttempts'), 'exclude': lambda f: f is None }})  
    parallelization_factor: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ParallelizationFactor'), 'exclude': lambda f: f is None }})  
    queues: Optional[list[str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('Queues'), 'exclude': lambda f: f is None }})  
    scaling_config: Optional[shared_scalingconfig.ScalingConfig] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ScalingConfig'), 'exclude': lambda f: f is None }})  
    self_managed_event_source: Optional[shared_selfmanagedeventsource.SelfManagedEventSource] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('SelfManagedEventSource'), 'exclude': lambda f: f is None }})  
    self_managed_kafka_event_source_config: Optional[shared_selfmanagedkafkaeventsourceconfig.SelfManagedKafkaEventSourceConfig] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('SelfManagedKafkaEventSourceConfig'), 'exclude': lambda f: f is None }})  
    source_access_configurations: Optional[list[shared_sourceaccessconfiguration.SourceAccessConfiguration]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('SourceAccessConfigurations'), 'exclude': lambda f: f is None }})  
    starting_position: Optional[shared_eventsourceposition_enum.EventSourcePositionEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('StartingPosition'), 'exclude': lambda f: f is None }})  
    starting_position_timestamp: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('StartingPositionTimestamp'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})  
    state: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('State'), 'exclude': lambda f: f is None }})  
    state_transition_reason: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('StateTransitionReason'), 'exclude': lambda f: f is None }})  
    topics: Optional[list[str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('Topics'), 'exclude': lambda f: f is None }})  
    tumbling_window_in_seconds: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('TumblingWindowInSeconds'), 'exclude': lambda f: f is None }})  
    uuid: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('UUID'), 'exclude': lambda f: f is None }})  
    