"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import audioconfig as shared_audioconfig
from ..shared import timepoint as shared_timepoint
from dataclasses_json import Undefined, dataclass_json
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class SynthesizeSpeechResponse:
    r"""The message returned to the client by the `SynthesizeSpeech` method."""
    
    audio_config: Optional[shared_audioconfig.AudioConfig] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('audioConfig'), 'exclude': lambda f: f is None }})
    r"""Description of audio data to be synthesized."""  
    audio_content: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('audioContent'), 'exclude': lambda f: f is None }})
    r"""The audio data bytes encoded as specified in the request, including the header for encodings that are wrapped in containers (e.g. MP3, OGG_OPUS). For LINEAR16 audio, we include the WAV header. Note: as with all bytes fields, protobuffers use a pure binary representation, whereas JSON representations use base64."""  
    timepoints: Optional[list[shared_timepoint.Timepoint]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('timepoints'), 'exclude': lambda f: f is None }})
    r"""A link between a position in the original request input and a corresponding time in the output audio. It's only supported via `` of SSML input."""  
    