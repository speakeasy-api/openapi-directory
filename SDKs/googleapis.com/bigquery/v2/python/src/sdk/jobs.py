"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

import requests as requests_http
from . import utils
from sdk.models import operations, shared
from typing import Optional

class Jobs:
    _client: requests_http.Session
    _security_client: requests_http.Session
    _server_url: str
    _language: str
    _sdk_version: str
    _gen_version: str

    def __init__(self, client: requests_http.Session, security_client: requests_http.Session, server_url: str, language: str, sdk_version: str, gen_version: str) -> None:
        self._client = client
        self._security_client = security_client
        self._server_url = server_url
        self._language = language
        self._sdk_version = sdk_version
        self._gen_version = gen_version
        
    def bigquery_jobs_cancel(self, request: operations.BigqueryJobsCancelRequest, security: operations.BigqueryJobsCancelSecurity) -> operations.BigqueryJobsCancelResponse:
        r"""Requests that a job be cancelled. This call will return immediately, and the client will need to poll for the job status to see if the cancel completed successfully. Cancelled jobs may still incur costs."""
        base_url = self._server_url
        
        url = utils.generate_url(operations.BigqueryJobsCancelRequest, base_url, '/projects/{projectId}/jobs/{jobId}/cancel', request)
        
        query_params = utils.get_query_params(operations.BigqueryJobsCancelRequest, request)
        
        client = utils.configure_security_client(self._client, security)
        
        http_res = client.request('POST', url, params=query_params)
        content_type = http_res.headers.get('Content-Type')

        res = operations.BigqueryJobsCancelResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.JobCancelResponse])
                res.job_cancel_response = out

        return res

    def bigquery_jobs_delete(self, request: operations.BigqueryJobsDeleteRequest, security: operations.BigqueryJobsDeleteSecurity) -> operations.BigqueryJobsDeleteResponse:
        r"""Requests the deletion of the metadata of a job. This call returns when the job's metadata is deleted."""
        base_url = self._server_url
        
        url = utils.generate_url(operations.BigqueryJobsDeleteRequest, base_url, '/projects/{projectId}/jobs/{jobId}/delete', request)
        
        query_params = utils.get_query_params(operations.BigqueryJobsDeleteRequest, request)
        
        client = utils.configure_security_client(self._client, security)
        
        http_res = client.request('DELETE', url, params=query_params)
        content_type = http_res.headers.get('Content-Type')

        res = operations.BigqueryJobsDeleteResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        

        return res

    def bigquery_jobs_get(self, request: operations.BigqueryJobsGetRequest, security: operations.BigqueryJobsGetSecurity) -> operations.BigqueryJobsGetResponse:
        r"""Returns information about a specific job. Job information is available for a six month period after creation. Requires that you're the person who ran the job, or have the Is Owner project role."""
        base_url = self._server_url
        
        url = utils.generate_url(operations.BigqueryJobsGetRequest, base_url, '/projects/{projectId}/jobs/{jobId}', request)
        
        query_params = utils.get_query_params(operations.BigqueryJobsGetRequest, request)
        
        client = utils.configure_security_client(self._client, security)
        
        http_res = client.request('GET', url, params=query_params)
        content_type = http_res.headers.get('Content-Type')

        res = operations.BigqueryJobsGetResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.Job])
                res.job = out

        return res

    def bigquery_jobs_get_query_results(self, request: operations.BigqueryJobsGetQueryResultsRequest, security: operations.BigqueryJobsGetQueryResultsSecurity) -> operations.BigqueryJobsGetQueryResultsResponse:
        r"""Retrieves the results of a query job."""
        base_url = self._server_url
        
        url = utils.generate_url(operations.BigqueryJobsGetQueryResultsRequest, base_url, '/projects/{projectId}/queries/{jobId}', request)
        
        query_params = utils.get_query_params(operations.BigqueryJobsGetQueryResultsRequest, request)
        
        client = utils.configure_security_client(self._client, security)
        
        http_res = client.request('GET', url, params=query_params)
        content_type = http_res.headers.get('Content-Type')

        res = operations.BigqueryJobsGetQueryResultsResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.GetQueryResultsResponse])
                res.get_query_results_response = out

        return res

    def bigquery_jobs_insert(self, request: operations.BigqueryJobsInsertRequest, security: operations.BigqueryJobsInsertSecurity) -> operations.BigqueryJobsInsertResponse:
        r"""Starts a new asynchronous job. Requires the Can View project role."""
        base_url = self._server_url
        
        url = utils.generate_url(operations.BigqueryJobsInsertRequest, base_url, '/projects/{projectId}/jobs', request)
        
        headers = {}
        req_content_type, data, form = utils.serialize_request_body(request, "request_body", 'raw')
        if req_content_type not in ('multipart/form-data', 'multipart/mixed'):
            headers['content-type'] = req_content_type
        query_params = utils.get_query_params(operations.BigqueryJobsInsertRequest, request)
        
        client = utils.configure_security_client(self._client, security)
        
        http_res = client.request('POST', url, params=query_params, data=data, files=form, headers=headers)
        content_type = http_res.headers.get('Content-Type')

        res = operations.BigqueryJobsInsertResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.Job])
                res.job = out

        return res

    def bigquery_jobs_list(self, request: operations.BigqueryJobsListRequest, security: operations.BigqueryJobsListSecurity) -> operations.BigqueryJobsListResponse:
        r"""Lists all jobs that you started in the specified project. Job information is available for a six month period after creation. The job list is sorted in reverse chronological order, by job creation time. Requires the Can View project role, or the Is Owner project role if you set the allUsers property."""
        base_url = self._server_url
        
        url = utils.generate_url(operations.BigqueryJobsListRequest, base_url, '/projects/{projectId}/jobs', request)
        
        query_params = utils.get_query_params(operations.BigqueryJobsListRequest, request)
        
        client = utils.configure_security_client(self._client, security)
        
        http_res = client.request('GET', url, params=query_params)
        content_type = http_res.headers.get('Content-Type')

        res = operations.BigqueryJobsListResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.JobList])
                res.job_list = out

        return res

    def bigquery_jobs_query(self, request: operations.BigqueryJobsQueryRequest, security: operations.BigqueryJobsQuerySecurity) -> operations.BigqueryJobsQueryResponse:
        r"""Runs a BigQuery SQL query synchronously and returns query results if the query completes within a specified timeout."""
        base_url = self._server_url
        
        url = utils.generate_url(operations.BigqueryJobsQueryRequest, base_url, '/projects/{projectId}/queries', request)
        
        headers = {}
        req_content_type, data, form = utils.serialize_request_body(request, "query_request", 'json')
        if req_content_type not in ('multipart/form-data', 'multipart/mixed'):
            headers['content-type'] = req_content_type
        query_params = utils.get_query_params(operations.BigqueryJobsQueryRequest, request)
        
        client = utils.configure_security_client(self._client, security)
        
        http_res = client.request('POST', url, params=query_params, data=data, files=form, headers=headers)
        content_type = http_res.headers.get('Content-Type')

        res = operations.BigqueryJobsQueryResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.QueryResponse])
                res.query_response = out

        return res

    