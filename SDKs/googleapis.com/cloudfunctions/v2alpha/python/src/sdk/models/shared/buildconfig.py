"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import source as shared_source
from ..shared import sourceprovenance as shared_sourceprovenance
from dataclasses_json import Undefined, dataclass_json
from enum import Enum
from sdk import utils
from typing import Optional

class BuildConfigDockerRegistryEnum(str, Enum):
    r"""Optional. Docker Registry to use for this deployment. This configuration is only applicable to 1st Gen functions, 2nd Gen functions can only use Artifact Registry. If `docker_repository` field is specified, this field will be automatically set as `ARTIFACT_REGISTRY`. If unspecified, it currently defaults to `CONTAINER_REGISTRY`. This field may be overridden by the backend for eligible deployments."""
    DOCKER_REGISTRY_UNSPECIFIED = 'DOCKER_REGISTRY_UNSPECIFIED'
    CONTAINER_REGISTRY = 'CONTAINER_REGISTRY'
    ARTIFACT_REGISTRY = 'ARTIFACT_REGISTRY'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class BuildConfigInput:
    r"""Describes the Build step of the function that builds a container from the given source."""
    
    buildpack_stack: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('buildpackStack'), 'exclude': lambda f: f is None }})
    r"""Specifies one of the Google provided buildpack stacks."""  
    docker_registry: Optional[BuildConfigDockerRegistryEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('dockerRegistry'), 'exclude': lambda f: f is None }})
    r"""Optional. Docker Registry to use for this deployment. This configuration is only applicable to 1st Gen functions, 2nd Gen functions can only use Artifact Registry. If `docker_repository` field is specified, this field will be automatically set as `ARTIFACT_REGISTRY`. If unspecified, it currently defaults to `CONTAINER_REGISTRY`. This field may be overridden by the backend for eligible deployments."""  
    docker_repository: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('dockerRepository'), 'exclude': lambda f: f is None }})
    r"""User managed repository created in Artifact Registry optionally with a customer managed encryption key. This is the repository to which the function docker image will be pushed after it is built by Cloud Build. If unspecified, GCF will create and use a repository named 'gcf-artifacts' for every deployed region. It must match the pattern `projects/{project}/locations/{location}/repositories/{repository}`. Cross-project repositories are not supported. Cross-location repositories are not supported. Repository format must be 'DOCKER'."""  
    entry_point: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('entryPoint'), 'exclude': lambda f: f is None }})
    r"""The name of the function (as defined in source code) that will be executed. Defaults to the resource name suffix, if not specified. For backward compatibility, if function with given name is not found, then the system will try to use function named \\"function\\". For Node.js this is name of a function exported by the module specified in `source_location`."""  
    environment_variables: Optional[dict[str, str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('environmentVariables'), 'exclude': lambda f: f is None }})
    r"""User-provided build-time environment variables for the function"""  
    runtime: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('runtime'), 'exclude': lambda f: f is None }})
    r"""The runtime in which to run the function. Required when deploying a new function, optional when updating an existing function. For a complete list of possible choices, see the [`gcloud` command reference](https://cloud.google.com/sdk/gcloud/reference/functions/deploy#--runtime)."""  
    source: Optional[shared_source.Source] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('source'), 'exclude': lambda f: f is None }})
    r"""The location of the function source code."""  
    source_provenance: Optional[shared_sourceprovenance.SourceProvenance] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('sourceProvenance'), 'exclude': lambda f: f is None }})
    r"""Provenance of the source. Ways to find the original source, or verify that some source was used for this build."""  
    worker_pool: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('workerPool'), 'exclude': lambda f: f is None }})
    r"""Name of the Cloud Build Custom Worker Pool that should be used to build the function. The format of this field is `projects/{project}/locations/{region}/workerPools/{workerPool}` where {project} and {region} are the project id and region respectively where the worker pool is defined and {workerPool} is the short name of the worker pool. If the project id is not the same as the function, then the Cloud Functions Service Agent (service-@gcf-admin-robot.iam.gserviceaccount.com) must be granted the role Cloud Build Custom Workers Builder (roles/cloudbuild.customworkers.builder) in the project."""  
    

@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class BuildConfig:
    r"""Describes the Build step of the function that builds a container from the given source."""
    
    build: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('build'), 'exclude': lambda f: f is None }})
    r"""Output only. The Cloud Build name of the latest successful deployment of the function."""  
    buildpack_stack: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('buildpackStack'), 'exclude': lambda f: f is None }})
    r"""Specifies one of the Google provided buildpack stacks."""  
    docker_registry: Optional[BuildConfigDockerRegistryEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('dockerRegistry'), 'exclude': lambda f: f is None }})
    r"""Optional. Docker Registry to use for this deployment. This configuration is only applicable to 1st Gen functions, 2nd Gen functions can only use Artifact Registry. If `docker_repository` field is specified, this field will be automatically set as `ARTIFACT_REGISTRY`. If unspecified, it currently defaults to `CONTAINER_REGISTRY`. This field may be overridden by the backend for eligible deployments."""  
    docker_repository: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('dockerRepository'), 'exclude': lambda f: f is None }})
    r"""User managed repository created in Artifact Registry optionally with a customer managed encryption key. This is the repository to which the function docker image will be pushed after it is built by Cloud Build. If unspecified, GCF will create and use a repository named 'gcf-artifacts' for every deployed region. It must match the pattern `projects/{project}/locations/{location}/repositories/{repository}`. Cross-project repositories are not supported. Cross-location repositories are not supported. Repository format must be 'DOCKER'."""  
    entry_point: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('entryPoint'), 'exclude': lambda f: f is None }})
    r"""The name of the function (as defined in source code) that will be executed. Defaults to the resource name suffix, if not specified. For backward compatibility, if function with given name is not found, then the system will try to use function named \\"function\\". For Node.js this is name of a function exported by the module specified in `source_location`."""  
    environment_variables: Optional[dict[str, str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('environmentVariables'), 'exclude': lambda f: f is None }})
    r"""User-provided build-time environment variables for the function"""  
    runtime: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('runtime'), 'exclude': lambda f: f is None }})
    r"""The runtime in which to run the function. Required when deploying a new function, optional when updating an existing function. For a complete list of possible choices, see the [`gcloud` command reference](https://cloud.google.com/sdk/gcloud/reference/functions/deploy#--runtime)."""  
    source: Optional[shared_source.Source] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('source'), 'exclude': lambda f: f is None }})
    r"""The location of the function source code."""  
    source_provenance: Optional[shared_sourceprovenance.SourceProvenance] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('sourceProvenance'), 'exclude': lambda f: f is None }})
    r"""Provenance of the source. Ways to find the original source, or verify that some source was used for this build."""  
    worker_pool: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('workerPool'), 'exclude': lambda f: f is None }})
    r"""Name of the Cloud Build Custom Worker Pool that should be used to build the function. The format of this field is `projects/{project}/locations/{region}/workerPools/{workerPool}` where {project} and {region} are the project id and region respectively where the worker pool is defined and {workerPool} is the short name of the worker pool. If the project id is not the same as the function, then the Cloud Functions Service Agent (service-@gcf-admin-robot.iam.gserviceaccount.com) must be granted the role Cloud Build Custom Workers Builder (roles/cloudbuild.customworkers.builder) in the project."""  
    