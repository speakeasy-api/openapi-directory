"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import monitoringdatasetformat as shared_monitoringdatasetformat
from ..shared import processings3datadistributiontype_enum as shared_processings3datadistributiontype_enum
from ..shared import processings3inputmode_enum as shared_processings3inputmode_enum
from dataclasses_json import Undefined, dataclass_json
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class BatchTransformInput:
    r"""Input object for the batch transform job."""
    
    data_captured_destination_s3_uri: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('DataCapturedDestinationS3Uri') }})  
    dataset_format: shared_monitoringdatasetformat.MonitoringDatasetFormat = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('DatasetFormat') }})  
    local_path: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('LocalPath') }})  
    end_time_offset: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('EndTimeOffset'), 'exclude': lambda f: f is None }})  
    features_attribute: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('FeaturesAttribute'), 'exclude': lambda f: f is None }})  
    inference_attribute: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('InferenceAttribute'), 'exclude': lambda f: f is None }})  
    probability_attribute: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ProbabilityAttribute'), 'exclude': lambda f: f is None }})  
    probability_threshold_attribute: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ProbabilityThresholdAttribute'), 'exclude': lambda f: f is None }})  
    s3_data_distribution_type: Optional[shared_processings3datadistributiontype_enum.ProcessingS3DataDistributionTypeEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('S3DataDistributionType'), 'exclude': lambda f: f is None }})  
    s3_input_mode: Optional[shared_processings3inputmode_enum.ProcessingS3InputModeEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('S3InputMode'), 'exclude': lambda f: f is None }})  
    start_time_offset: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('StartTimeOffset'), 'exclude': lambda f: f is None }})  
    