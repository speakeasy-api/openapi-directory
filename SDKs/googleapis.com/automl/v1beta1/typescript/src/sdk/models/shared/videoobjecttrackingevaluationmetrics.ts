/*
 * Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.
 */

import { SpeakeasyBase, SpeakeasyMetadata } from "../../../internal/utils";
import { BoundingBoxMetricsEntry } from "./boundingboxmetricsentry";
import { Expose, Type } from "class-transformer";

/**
 * Model evaluation metrics for video object tracking problems. Evaluates prediction quality of both labeled bounding boxes and labeled tracks (i.e. series of bounding boxes sharing same label and instance ID).
 */
export class VideoObjectTrackingEvaluationMetrics extends SpeakeasyBase {
  /**
   * Output only. The single metric for bounding boxes evaluation: the mean_average_precision averaged over all bounding_box_metrics_entries.
   */
  @SpeakeasyMetadata()
  @Expose({ name: "boundingBoxMeanAveragePrecision" })
  boundingBoxMeanAveragePrecision?: number;

  /**
   * Output only. The bounding boxes match metrics for each Intersection-over-union threshold 0.05,0.10,...,0.95,0.96,0.97,0.98,0.99 and each label confidence threshold 0.05,0.10,...,0.95,0.96,0.97,0.98,0.99 pair.
   */
  @SpeakeasyMetadata({ elemType: BoundingBoxMetricsEntry })
  @Expose({ name: "boundingBoxMetricsEntries" })
  @Type(() => BoundingBoxMetricsEntry)
  boundingBoxMetricsEntries?: BoundingBoxMetricsEntry[];

  /**
   * Output only. The total number of bounding boxes (i.e. summed over all frames) the ground truth used to create this evaluation had.
   */
  @SpeakeasyMetadata()
  @Expose({ name: "evaluatedBoundingBoxCount" })
  evaluatedBoundingBoxCount?: number;

  /**
   * Output only. The number of video frames used to create this evaluation.
   */
  @SpeakeasyMetadata()
  @Expose({ name: "evaluatedFrameCount" })
  evaluatedFrameCount?: number;
}
