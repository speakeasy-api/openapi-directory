"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import googleclouddatalabelingv1beta1boundingpolyconfig as shared_googleclouddatalabelingv1beta1boundingpolyconfig
from ..shared import googleclouddatalabelingv1beta1evaluationconfig as shared_googleclouddatalabelingv1beta1evaluationconfig
from ..shared import googleclouddatalabelingv1beta1evaluationjobalertconfig as shared_googleclouddatalabelingv1beta1evaluationjobalertconfig
from ..shared import googleclouddatalabelingv1beta1humanannotationconfig as shared_googleclouddatalabelingv1beta1humanannotationconfig
from ..shared import googleclouddatalabelingv1beta1imageclassificationconfig as shared_googleclouddatalabelingv1beta1imageclassificationconfig
from ..shared import googleclouddatalabelingv1beta1inputconfig as shared_googleclouddatalabelingv1beta1inputconfig
from ..shared import googleclouddatalabelingv1beta1textclassificationconfig as shared_googleclouddatalabelingv1beta1textclassificationconfig
from dataclasses_json import Undefined, dataclass_json
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class GoogleCloudDatalabelingV1beta1EvaluationJobConfig:
    r"""Configures specific details of how a continuous evaluation job works. Provide this configuration when you create an EvaluationJob."""
    
    bigquery_import_keys: Optional[dict[str, str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('bigqueryImportKeys'), 'exclude': lambda f: f is None }})
    r"""Required. Prediction keys that tell Data Labeling Service where to find the data for evaluation in your BigQuery table. When the service samples prediction input and output from your model version and saves it to BigQuery, the data gets stored as JSON strings in the BigQuery table. These keys tell Data Labeling Service how to parse the JSON. You can provide the following entries in this field: * `data_json_key`: the data key for prediction input. You must provide either this key or `reference_json_key`. * `reference_json_key`: the data reference key for prediction input. You must provide either this key or `data_json_key`. * `label_json_key`: the label key for prediction output. Required. * `label_score_json_key`: the score key for prediction output. Required. * `bounding_box_json_key`: the bounding box key for prediction output. Required if your model version perform image object detection. Learn [how to configure prediction keys](/ml-engine/docs/continuous-evaluation/create-job#prediction-keys)."""  
    bounding_poly_config: Optional[shared_googleclouddatalabelingv1beta1boundingpolyconfig.GoogleCloudDatalabelingV1beta1BoundingPolyConfig] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('boundingPolyConfig'), 'exclude': lambda f: f is None }})
    r"""Config for image bounding poly (and bounding box) human labeling task."""  
    evaluation_config: Optional[shared_googleclouddatalabelingv1beta1evaluationconfig.GoogleCloudDatalabelingV1beta1EvaluationConfig] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('evaluationConfig'), 'exclude': lambda f: f is None }})
    r"""Configuration details used for calculating evaluation metrics and creating an Evaluation."""  
    evaluation_job_alert_config: Optional[shared_googleclouddatalabelingv1beta1evaluationjobalertconfig.GoogleCloudDatalabelingV1beta1EvaluationJobAlertConfig] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('evaluationJobAlertConfig'), 'exclude': lambda f: f is None }})
    r"""Provides details for how an evaluation job sends email alerts based on the results of a run."""  
    example_count: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('exampleCount'), 'exclude': lambda f: f is None }})
    r"""Required. The maximum number of predictions to sample and save to BigQuery during each evaluation interval. This limit overrides `example_sample_percentage`: even if the service has not sampled enough predictions to fulfill `example_sample_perecentage` during an interval, it stops sampling predictions when it meets this limit."""  
    example_sample_percentage: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('exampleSamplePercentage'), 'exclude': lambda f: f is None }})
    r"""Required. Fraction of predictions to sample and save to BigQuery during each evaluation interval. For example, 0.1 means 10% of predictions served by your model version get saved to BigQuery."""  
    human_annotation_config: Optional[shared_googleclouddatalabelingv1beta1humanannotationconfig.GoogleCloudDatalabelingV1beta1HumanAnnotationConfig] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('humanAnnotationConfig'), 'exclude': lambda f: f is None }})
    r"""Configuration for how human labeling task should be done."""  
    image_classification_config: Optional[shared_googleclouddatalabelingv1beta1imageclassificationconfig.GoogleCloudDatalabelingV1beta1ImageClassificationConfig] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('imageClassificationConfig'), 'exclude': lambda f: f is None }})
    r"""Config for image classification human labeling task."""  
    input_config: Optional[shared_googleclouddatalabelingv1beta1inputconfig.GoogleCloudDatalabelingV1beta1InputConfig] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('inputConfig'), 'exclude': lambda f: f is None }})
    r"""The configuration of input data, including data type, location, etc."""  
    text_classification_config: Optional[shared_googleclouddatalabelingv1beta1textclassificationconfig.GoogleCloudDatalabelingV1beta1TextClassificationConfig] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('textClassificationConfig'), 'exclude': lambda f: f is None }})
    r"""Config for text classification human labeling task."""  
    