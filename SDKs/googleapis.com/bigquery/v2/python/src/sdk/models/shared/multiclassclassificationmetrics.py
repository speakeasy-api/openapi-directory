"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import aggregateclassificationmetrics as shared_aggregateclassificationmetrics
from ..shared import confusionmatrix as shared_confusionmatrix
from dataclasses_json import Undefined, dataclass_json
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class MultiClassClassificationMetrics:
    r"""Evaluation metrics for multi-class classification/classifier models."""
    
    aggregate_classification_metrics: Optional[shared_aggregateclassificationmetrics.AggregateClassificationMetrics] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('aggregateClassificationMetrics'), 'exclude': lambda f: f is None }})
    r"""Aggregate metrics for classification/classifier models. For multi-class models, the metrics are either macro-averaged or micro-averaged. When macro-averaged, the metrics are calculated for each label and then an unweighted average is taken of those values. When micro-averaged, the metric is calculated globally by counting the total number of correctly predicted rows."""  
    confusion_matrix_list: Optional[list[shared_confusionmatrix.ConfusionMatrix]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('confusionMatrixList'), 'exclude': lambda f: f is None }})
    r"""Confusion matrix at different thresholds."""  
    