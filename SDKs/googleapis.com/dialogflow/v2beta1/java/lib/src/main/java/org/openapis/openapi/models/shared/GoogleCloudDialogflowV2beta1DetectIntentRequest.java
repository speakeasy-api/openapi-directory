/* 
 * Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.
 */

package org.openapis.openapi.models.shared;

import com.fasterxml.jackson.annotation.JsonInclude.Include;
import com.fasterxml.jackson.annotation.JsonInclude;
import com.fasterxml.jackson.annotation.JsonProperty;

/**
 * GoogleCloudDialogflowV2beta1DetectIntentRequest - The request to detect user's intent.
 */
public class GoogleCloudDialogflowV2beta1DetectIntentRequest {
    /**
     * The natural language speech audio to be processed. This field should be populated iff `query_input` is set to an input audio config. A single request can contain up to 1 minute of speech audio data.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("inputAudio")
    public String inputAudio;

    public GoogleCloudDialogflowV2beta1DetectIntentRequest withInputAudio(String inputAudio) {
        this.inputAudio = inputAudio;
        return this;
    }
    
    /**
     * Instructs the speech synthesizer how to generate the output audio content. If this audio config is supplied in a request, it overrides all existing text-to-speech settings applied to the agent.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("outputAudioConfig")
    public GoogleCloudDialogflowV2beta1OutputAudioConfig outputAudioConfig;

    public GoogleCloudDialogflowV2beta1DetectIntentRequest withOutputAudioConfig(GoogleCloudDialogflowV2beta1OutputAudioConfig outputAudioConfig) {
        this.outputAudioConfig = outputAudioConfig;
        return this;
    }
    
    /**
     * Mask for output_audio_config indicating which settings in this request-level config should override speech synthesizer settings defined at agent-level. If unspecified or empty, output_audio_config replaces the agent-level config in its entirety.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("outputAudioConfigMask")
    public String outputAudioConfigMask;

    public GoogleCloudDialogflowV2beta1DetectIntentRequest withOutputAudioConfigMask(String outputAudioConfigMask) {
        this.outputAudioConfigMask = outputAudioConfigMask;
        return this;
    }
    
    /**
     * Represents the query input. It can contain either: 1. An audio config which instructs the speech recognizer how to process the speech audio. 2. A conversational query in the form of text. 3. An event that specifies which intent to trigger.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("queryInput")
    public GoogleCloudDialogflowV2beta1QueryInput queryInput;

    public GoogleCloudDialogflowV2beta1DetectIntentRequest withQueryInput(GoogleCloudDialogflowV2beta1QueryInput queryInput) {
        this.queryInput = queryInput;
        return this;
    }
    
    /**
     * Represents the parameters of the conversational query.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("queryParams")
    public GoogleCloudDialogflowV2beta1QueryParameters queryParams;

    public GoogleCloudDialogflowV2beta1DetectIntentRequest withQueryParams(GoogleCloudDialogflowV2beta1QueryParameters queryParams) {
        this.queryParams = queryParams;
        return this;
    }
    
    public GoogleCloudDialogflowV2beta1DetectIntentRequest(){}
}
