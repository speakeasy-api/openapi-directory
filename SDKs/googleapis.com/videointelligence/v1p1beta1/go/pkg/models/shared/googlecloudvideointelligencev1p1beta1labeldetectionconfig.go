// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
)

// GoogleCloudVideointelligenceV1p1beta1LabelDetectionConfigLabelDetectionModeEnum - What labels should be detected with LABEL_DETECTION, in addition to video-level labels or segment-level labels. If unspecified, defaults to `SHOT_MODE`.
type GoogleCloudVideointelligenceV1p1beta1LabelDetectionConfigLabelDetectionModeEnum string

const (
	GoogleCloudVideointelligenceV1p1beta1LabelDetectionConfigLabelDetectionModeEnumLabelDetectionModeUnspecified GoogleCloudVideointelligenceV1p1beta1LabelDetectionConfigLabelDetectionModeEnum = "LABEL_DETECTION_MODE_UNSPECIFIED"
	GoogleCloudVideointelligenceV1p1beta1LabelDetectionConfigLabelDetectionModeEnumShotMode                      GoogleCloudVideointelligenceV1p1beta1LabelDetectionConfigLabelDetectionModeEnum = "SHOT_MODE"
	GoogleCloudVideointelligenceV1p1beta1LabelDetectionConfigLabelDetectionModeEnumFrameMode                     GoogleCloudVideointelligenceV1p1beta1LabelDetectionConfigLabelDetectionModeEnum = "FRAME_MODE"
	GoogleCloudVideointelligenceV1p1beta1LabelDetectionConfigLabelDetectionModeEnumShotAndFrameMode              GoogleCloudVideointelligenceV1p1beta1LabelDetectionConfigLabelDetectionModeEnum = "SHOT_AND_FRAME_MODE"
)

func (e GoogleCloudVideointelligenceV1p1beta1LabelDetectionConfigLabelDetectionModeEnum) ToPointer() *GoogleCloudVideointelligenceV1p1beta1LabelDetectionConfigLabelDetectionModeEnum {
	return &e
}

func (e *GoogleCloudVideointelligenceV1p1beta1LabelDetectionConfigLabelDetectionModeEnum) UnmarshalJSON(data []byte) error {
	var v string
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}
	switch v {
	case "LABEL_DETECTION_MODE_UNSPECIFIED":
		fallthrough
	case "SHOT_MODE":
		fallthrough
	case "FRAME_MODE":
		fallthrough
	case "SHOT_AND_FRAME_MODE":
		*e = GoogleCloudVideointelligenceV1p1beta1LabelDetectionConfigLabelDetectionModeEnum(v)
		return nil
	default:
		return fmt.Errorf("invalid value for GoogleCloudVideointelligenceV1p1beta1LabelDetectionConfigLabelDetectionModeEnum: %v", v)
	}
}

// GoogleCloudVideointelligenceV1p1beta1LabelDetectionConfig - Config for LABEL_DETECTION.
type GoogleCloudVideointelligenceV1p1beta1LabelDetectionConfig struct {
	// The confidence threshold we perform filtering on the labels from frame-level detection. If not set, it is set to 0.4 by default. The valid range for this threshold is [0.1, 0.9]. Any value set outside of this range will be clipped. Note: For best results, follow the default threshold. We will update the default threshold everytime when we release a new model.
	FrameConfidenceThreshold *float32 `json:"frameConfidenceThreshold,omitempty"`
	// What labels should be detected with LABEL_DETECTION, in addition to video-level labels or segment-level labels. If unspecified, defaults to `SHOT_MODE`.
	LabelDetectionMode *GoogleCloudVideointelligenceV1p1beta1LabelDetectionConfigLabelDetectionModeEnum `json:"labelDetectionMode,omitempty"`
	// Model to use for label detection. Supported values: "builtin/stable" (the default if unset) and "builtin/latest".
	Model *string `json:"model,omitempty"`
	// Whether the video has been shot from a stationary (i.e., non-moving) camera. When set to true, might improve detection accuracy for moving objects. Should be used with `SHOT_AND_FRAME_MODE` enabled.
	StationaryCamera *bool `json:"stationaryCamera,omitempty"`
	// The confidence threshold we perform filtering on the labels from video-level and shot-level detections. If not set, it's set to 0.3 by default. The valid range for this threshold is [0.1, 0.9]. Any value set outside of this range will be clipped. Note: For best results, follow the default threshold. We will update the default threshold everytime when we release a new model.
	VideoConfidenceThreshold *float32 `json:"videoConfidenceThreshold,omitempty"`
}
