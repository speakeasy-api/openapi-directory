"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
import dateutil.parser
from dataclasses_json import Undefined, dataclass_json
from datetime import datetime
from marshmallow import fields
from sdk import utils


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class JobScheduleStatistics:
    r"""The lifetime resource usage statistics for a job schedule."""
    
    kernel_cpu_time: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('kernelCPUTime') }})
    r"""Gets or sets the total kernel mode CPU time (summed across all cores and all compute nodes) consumed by all the tasks in all the jobs created under the schedule."""  
    last_update_time: datetime = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('lastUpdateTime'), 'encoder': utils.datetimeisoformat(False), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso') }})
    r"""Gets or sets the time at which the statistics were last updated. All statistics are limited to the range between startTime and lastUpdateTime."""  
    num_failed_tasks: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('numFailedTasks') }})
    r"""Gets or sets the total number of tasks that failed during the given time range in jobs created under the schedule. A task fails if it exhausts its maximum retry count without returning exit code 0."""  
    num_succeeded_tasks: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('numSucceededTasks') }})
    r"""Gets or sets the total number of tasks successfully completed during the given time range in jobs created under the schedule.  A task completes successfully if it returns exit code 0."""  
    num_task_retries: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('numTaskRetries') }})
    r"""Gets or sets the total number of retries during the given time range on all the tasks in jobs created under the schedule."""  
    read_io_gi_b: float = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('readIOGiB') }})
    r"""Gets or sets the total amount of data in GiB of I/O read by all the tasks in all the jobs created under the schedule."""  
    read_i_ops: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('readIOps') }})
    r"""Gets or sets the total number of I/O read operations performed by all the tasks in all the jobs created under the schedule."""  
    start_time: datetime = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('startTime'), 'encoder': utils.datetimeisoformat(False), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso') }})
    r"""Gets or sets the start time of the time range covered by the statistics."""  
    url: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('url') }})
    r"""Gets or sets the URL for the statistics."""  
    user_cpu_time: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('userCPUTime') }})
    r"""Gets or sets the total user mode CPU time (summed across all cores and all compute nodes) consumed by all the tasks in all the jobs created under the schedule."""  
    wait_time: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('waitTime') }})
    r"""Gets or sets the total wait time of all the tasks in jobs created under the schedule."""  
    wall_clock_time: str = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('wallClockTime') }})
    r"""Gets or sets the total wall clock time of all the tasks in all the jobs created under the schedule."""  
    write_io_gi_b: float = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('writeIOGiB') }})
    r"""Gets or sets the total amount of data in GiB of I/O written by all the tasks in all the jobs created under the schedule."""  
    write_i_ops: int = dataclasses.field(metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('writeIOps') }})
    r"""Gets or sets the total number of I/O write operations performed by all the tasks in all the jobs created under the schedule."""  
    