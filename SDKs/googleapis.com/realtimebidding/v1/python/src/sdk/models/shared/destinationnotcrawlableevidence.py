"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from dataclasses_json import Undefined, dataclass_json
from enum import Enum
from sdk import utils
from typing import Optional

class DestinationNotCrawlableEvidenceReasonEnum(str, Enum):
    r"""Reason of destination not crawlable."""
    REASON_UNSPECIFIED = 'REASON_UNSPECIFIED'
    UNREACHABLE_ROBOTS = 'UNREACHABLE_ROBOTS'
    TIMEOUT_ROBOTS = 'TIMEOUT_ROBOTS'
    ROBOTED_DENIED = 'ROBOTED_DENIED'
    UNKNOWN = 'UNKNOWN'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class DestinationNotCrawlableEvidence:
    r"""Evidence that the creative's destination URL was not crawlable by Google."""
    
    crawled_url: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('crawledUrl'), 'exclude': lambda f: f is None }})
    r"""Destination URL that was attempted to be crawled."""  
    crawl_time: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('crawlTime'), 'exclude': lambda f: f is None }})
    r"""Approximate time of the crawl."""  
    reason: Optional[DestinationNotCrawlableEvidenceReasonEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('reason'), 'exclude': lambda f: f is None }})
    r"""Reason of destination not crawlable."""  
    