/*
 * Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.
 */

import {
  objectToClass,
  SpeakeasyBase,
  SpeakeasyMetadata,
} from "../../../internal/utils";
import { GoogleCloudDialogflowV2SynthesizeSpeechConfig } from "./googleclouddialogflowv2synthesizespeechconfig";
import { Expose, Transform } from "class-transformer";

/**
 * Required. Audio encoding of the synthesized audio content.
 */
export enum GoogleCloudDialogflowV2TextToSpeechSettingsOutputAudioEncodingEnum {
  OutputAudioEncodingUnspecified = "OUTPUT_AUDIO_ENCODING_UNSPECIFIED",
  OutputAudioEncodingLinear16 = "OUTPUT_AUDIO_ENCODING_LINEAR_16",
  OutputAudioEncodingMp3 = "OUTPUT_AUDIO_ENCODING_MP3",
  OutputAudioEncodingMp364Kbps = "OUTPUT_AUDIO_ENCODING_MP3_64_KBPS",
  OutputAudioEncodingOggOpus = "OUTPUT_AUDIO_ENCODING_OGG_OPUS",
  OutputAudioEncodingMulaw = "OUTPUT_AUDIO_ENCODING_MULAW",
}

/**
 * Instructs the speech synthesizer on how to generate the output audio content.
 */
export class GoogleCloudDialogflowV2TextToSpeechSettings extends SpeakeasyBase {
  /**
   * Optional. Indicates whether text to speech is enabled. Even when this field is false, other settings in this proto are still retained.
   */
  @SpeakeasyMetadata()
  @Expose({ name: "enableTextToSpeech" })
  enableTextToSpeech?: boolean;

  /**
   * Required. Audio encoding of the synthesized audio content.
   */
  @SpeakeasyMetadata()
  @Expose({ name: "outputAudioEncoding" })
  outputAudioEncoding?: GoogleCloudDialogflowV2TextToSpeechSettingsOutputAudioEncodingEnum;

  /**
   * Optional. The synthesis sample rate (in hertz) for this audio. If not provided, then the synthesizer will use the default sample rate based on the audio encoding. If this is different from the voice's natural sample rate, then the synthesizer will honor this request by converting to the desired sample rate (which might result in worse audio quality).
   */
  @SpeakeasyMetadata()
  @Expose({ name: "sampleRateHertz" })
  sampleRateHertz?: number;

  /**
   * Optional. Configuration of how speech should be synthesized, mapping from language (https://cloud.google.com/dialogflow/docs/reference/language) to SynthesizeSpeechConfig.
   */
  @SpeakeasyMetadata({
    elemType: GoogleCloudDialogflowV2SynthesizeSpeechConfig,
  })
  @Expose({ name: "synthesizeSpeechConfigs" })
  @Transform(
    ({ value }) => {
      const obj: Record<string, GoogleCloudDialogflowV2SynthesizeSpeechConfig> =
        {};
      for (const key in value) {
        obj[key] = objectToClass(
          value[key],
          GoogleCloudDialogflowV2SynthesizeSpeechConfig
        );
      }
      return obj;
    },
    { toClassOnly: true }
  )
  synthesizeSpeechConfigs?: Record<
    string,
    GoogleCloudDialogflowV2SynthesizeSpeechConfig
  >;
}
