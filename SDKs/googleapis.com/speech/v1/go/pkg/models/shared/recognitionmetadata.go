// Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.

package shared

import (
	"encoding/json"
	"fmt"
)

// RecognitionMetadataInteractionTypeEnum - The use case most closely describing the audio content to be recognized.
type RecognitionMetadataInteractionTypeEnum string

const (
	RecognitionMetadataInteractionTypeEnumInteractionTypeUnspecified RecognitionMetadataInteractionTypeEnum = "INTERACTION_TYPE_UNSPECIFIED"
	RecognitionMetadataInteractionTypeEnumDiscussion                 RecognitionMetadataInteractionTypeEnum = "DISCUSSION"
	RecognitionMetadataInteractionTypeEnumPresentation               RecognitionMetadataInteractionTypeEnum = "PRESENTATION"
	RecognitionMetadataInteractionTypeEnumPhoneCall                  RecognitionMetadataInteractionTypeEnum = "PHONE_CALL"
	RecognitionMetadataInteractionTypeEnumVoicemail                  RecognitionMetadataInteractionTypeEnum = "VOICEMAIL"
	RecognitionMetadataInteractionTypeEnumProfessionallyProduced     RecognitionMetadataInteractionTypeEnum = "PROFESSIONALLY_PRODUCED"
	RecognitionMetadataInteractionTypeEnumVoiceSearch                RecognitionMetadataInteractionTypeEnum = "VOICE_SEARCH"
	RecognitionMetadataInteractionTypeEnumVoiceCommand               RecognitionMetadataInteractionTypeEnum = "VOICE_COMMAND"
	RecognitionMetadataInteractionTypeEnumDictation                  RecognitionMetadataInteractionTypeEnum = "DICTATION"
)

func (e *RecognitionMetadataInteractionTypeEnum) UnmarshalJSON(data []byte) error {
	var s string
	if err := json.Unmarshal(data, &s); err != nil {
		return err
	}
	switch s {
	case "INTERACTION_TYPE_UNSPECIFIED":
		fallthrough
	case "DISCUSSION":
		fallthrough
	case "PRESENTATION":
		fallthrough
	case "PHONE_CALL":
		fallthrough
	case "VOICEMAIL":
		fallthrough
	case "PROFESSIONALLY_PRODUCED":
		fallthrough
	case "VOICE_SEARCH":
		fallthrough
	case "VOICE_COMMAND":
		fallthrough
	case "DICTATION":
		*e = RecognitionMetadataInteractionTypeEnum(s)
		return nil
	default:
		return fmt.Errorf("invalid value for RecognitionMetadataInteractionTypeEnum: %s", s)
	}
}

// RecognitionMetadataMicrophoneDistanceEnum - The audio type that most closely describes the audio being recognized.
type RecognitionMetadataMicrophoneDistanceEnum string

const (
	RecognitionMetadataMicrophoneDistanceEnumMicrophoneDistanceUnspecified RecognitionMetadataMicrophoneDistanceEnum = "MICROPHONE_DISTANCE_UNSPECIFIED"
	RecognitionMetadataMicrophoneDistanceEnumNearfield                     RecognitionMetadataMicrophoneDistanceEnum = "NEARFIELD"
	RecognitionMetadataMicrophoneDistanceEnumMidfield                      RecognitionMetadataMicrophoneDistanceEnum = "MIDFIELD"
	RecognitionMetadataMicrophoneDistanceEnumFarfield                      RecognitionMetadataMicrophoneDistanceEnum = "FARFIELD"
)

func (e *RecognitionMetadataMicrophoneDistanceEnum) UnmarshalJSON(data []byte) error {
	var s string
	if err := json.Unmarshal(data, &s); err != nil {
		return err
	}
	switch s {
	case "MICROPHONE_DISTANCE_UNSPECIFIED":
		fallthrough
	case "NEARFIELD":
		fallthrough
	case "MIDFIELD":
		fallthrough
	case "FARFIELD":
		*e = RecognitionMetadataMicrophoneDistanceEnum(s)
		return nil
	default:
		return fmt.Errorf("invalid value for RecognitionMetadataMicrophoneDistanceEnum: %s", s)
	}
}

// RecognitionMetadataOriginalMediaTypeEnum - The original media the speech was recorded on.
type RecognitionMetadataOriginalMediaTypeEnum string

const (
	RecognitionMetadataOriginalMediaTypeEnumOriginalMediaTypeUnspecified RecognitionMetadataOriginalMediaTypeEnum = "ORIGINAL_MEDIA_TYPE_UNSPECIFIED"
	RecognitionMetadataOriginalMediaTypeEnumAudio                        RecognitionMetadataOriginalMediaTypeEnum = "AUDIO"
	RecognitionMetadataOriginalMediaTypeEnumVideo                        RecognitionMetadataOriginalMediaTypeEnum = "VIDEO"
)

func (e *RecognitionMetadataOriginalMediaTypeEnum) UnmarshalJSON(data []byte) error {
	var s string
	if err := json.Unmarshal(data, &s); err != nil {
		return err
	}
	switch s {
	case "ORIGINAL_MEDIA_TYPE_UNSPECIFIED":
		fallthrough
	case "AUDIO":
		fallthrough
	case "VIDEO":
		*e = RecognitionMetadataOriginalMediaTypeEnum(s)
		return nil
	default:
		return fmt.Errorf("invalid value for RecognitionMetadataOriginalMediaTypeEnum: %s", s)
	}
}

// RecognitionMetadataRecordingDeviceTypeEnum - The type of device the speech was recorded with.
type RecognitionMetadataRecordingDeviceTypeEnum string

const (
	RecognitionMetadataRecordingDeviceTypeEnumRecordingDeviceTypeUnspecified RecognitionMetadataRecordingDeviceTypeEnum = "RECORDING_DEVICE_TYPE_UNSPECIFIED"
	RecognitionMetadataRecordingDeviceTypeEnumSmartphone                     RecognitionMetadataRecordingDeviceTypeEnum = "SMARTPHONE"
	RecognitionMetadataRecordingDeviceTypeEnumPc                             RecognitionMetadataRecordingDeviceTypeEnum = "PC"
	RecognitionMetadataRecordingDeviceTypeEnumPhoneLine                      RecognitionMetadataRecordingDeviceTypeEnum = "PHONE_LINE"
	RecognitionMetadataRecordingDeviceTypeEnumVehicle                        RecognitionMetadataRecordingDeviceTypeEnum = "VEHICLE"
	RecognitionMetadataRecordingDeviceTypeEnumOtherOutdoorDevice             RecognitionMetadataRecordingDeviceTypeEnum = "OTHER_OUTDOOR_DEVICE"
	RecognitionMetadataRecordingDeviceTypeEnumOtherIndoorDevice              RecognitionMetadataRecordingDeviceTypeEnum = "OTHER_INDOOR_DEVICE"
)

func (e *RecognitionMetadataRecordingDeviceTypeEnum) UnmarshalJSON(data []byte) error {
	var s string
	if err := json.Unmarshal(data, &s); err != nil {
		return err
	}
	switch s {
	case "RECORDING_DEVICE_TYPE_UNSPECIFIED":
		fallthrough
	case "SMARTPHONE":
		fallthrough
	case "PC":
		fallthrough
	case "PHONE_LINE":
		fallthrough
	case "VEHICLE":
		fallthrough
	case "OTHER_OUTDOOR_DEVICE":
		fallthrough
	case "OTHER_INDOOR_DEVICE":
		*e = RecognitionMetadataRecordingDeviceTypeEnum(s)
		return nil
	default:
		return fmt.Errorf("invalid value for RecognitionMetadataRecordingDeviceTypeEnum: %s", s)
	}
}

// RecognitionMetadata - Description of audio data to be recognized.
type RecognitionMetadata struct {
	// Description of the content. Eg. "Recordings of federal supreme court hearings from 2012".
	AudioTopic *string `json:"audioTopic,omitempty"`
	// The industry vertical to which this speech recognition request most closely applies. This is most indicative of the topics contained in the audio. Use the 6-digit NAICS code to identify the industry vertical - see https://www.naics.com/search/.
	IndustryNaicsCodeOfAudio *int64 `json:"industryNaicsCodeOfAudio,omitempty"`
	// The use case most closely describing the audio content to be recognized.
	InteractionType *RecognitionMetadataInteractionTypeEnum `json:"interactionType,omitempty"`
	// The audio type that most closely describes the audio being recognized.
	MicrophoneDistance *RecognitionMetadataMicrophoneDistanceEnum `json:"microphoneDistance,omitempty"`
	// The original media the speech was recorded on.
	OriginalMediaType *RecognitionMetadataOriginalMediaTypeEnum `json:"originalMediaType,omitempty"`
	// Mime type of the original audio file. For example `audio/m4a`, `audio/x-alaw-basic`, `audio/mp3`, `audio/3gpp`. A list of possible audio mime types is maintained at http://www.iana.org/assignments/media-types/media-types.xhtml#audio
	OriginalMimeType *string `json:"originalMimeType,omitempty"`
	// The device used to make the recording. Examples 'Nexus 5X' or 'Polycom SoundStation IP 6000' or 'POTS' or 'VoIP' or 'Cardioid Microphone'.
	RecordingDeviceName *string `json:"recordingDeviceName,omitempty"`
	// The type of device the speech was recorded with.
	RecordingDeviceType *RecognitionMetadataRecordingDeviceTypeEnum `json:"recordingDeviceType,omitempty"`
}
