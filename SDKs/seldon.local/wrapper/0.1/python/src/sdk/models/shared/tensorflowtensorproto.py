"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import tensorflowdatatype_enum as shared_tensorflowdatatype_enum
from ..shared import tensorflowresourcehandleproto as shared_tensorflowresourcehandleproto
from ..shared import tensorflowtensorshapeproto as shared_tensorflowtensorshapeproto
from ..shared import tensorflowvarianttensordataproto as shared_tensorflowvarianttensordataproto
from dataclasses_json import Undefined, dataclass_json
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class TensorflowTensorProto:
    r"""Protocol buffer representing a tensor."""
    
    bool_val: Optional[list[bool]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('bool_val'), 'exclude': lambda f: f is None }})  
    dcomplex_val: Optional[list[float]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('dcomplex_val'), 'exclude': lambda f: f is None }})
    r"""DT_COMPLEX128. dcomplex_val(2*i) and dcomplex_val(2*i+1) are real
    and imaginary parts of i-th double precision complex.
    """  
    double_val: Optional[list[float]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('double_val'), 'exclude': lambda f: f is None }})
    r"""DT_DOUBLE."""  
    dtype: Optional[shared_tensorflowdatatype_enum.TensorflowDataTypeEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('dtype'), 'exclude': lambda f: f is None }})
    r"""- DT_INVALID: Not a legal value for DataType.  Used to indicate a DataType field
    has not been set.
     - DT_FLOAT: Data types that all computation devices are expected to be
    capable to support.
     - DT_FLOAT_REF: Do not use!  These are only for parameters.  Every enum above
    should have a corresponding value below (verified by types_test).
    """  
    float_val: Optional[list[float]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('float_val'), 'exclude': lambda f: f is None }})
    r"""DT_FLOAT."""  
    half_val: Optional[list[int]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('half_val'), 'exclude': lambda f: f is None }})
    r"""DT_HALF, DT_BFLOAT16. Note that since protobuf has no int16 type, we'll
    have some pointless zero padding for each value here.
    """  
    int_val: Optional[list[int]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('int_val'), 'exclude': lambda f: f is None }})
    r"""DT_INT32, DT_INT16, DT_INT8, DT_UINT8."""  
    int64_val: Optional[list[str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('int64_val'), 'exclude': lambda f: f is None }})  
    resource_handle_val: Optional[list[shared_tensorflowresourcehandleproto.TensorflowResourceHandleProto]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('resource_handle_val'), 'exclude': lambda f: f is None }})  
    scomplex_val: Optional[list[float]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('scomplex_val'), 'exclude': lambda f: f is None }})
    r"""DT_COMPLEX64. scomplex_val(2*i) and scomplex_val(2*i+1) are real
    and imaginary parts of i-th single precision complex.
    """  
    string_val: Optional[list[str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('string_val'), 'exclude': lambda f: f is None }})  
    tensor_content: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('tensor_content'), 'exclude': lambda f: f is None }})
    r"""Serialized raw tensor content from either Tensor::AsProtoTensorContent or
    memcpy in tensorflow::grpc::EncodeTensorToByteBuffer. This representation
    can be used for all tensor types. The purpose of this representation is to
    reduce serialization overhead during RPC call by avoiding serialization of
    many repeated small items.
    """  
    tensor_shape: Optional[shared_tensorflowtensorshapeproto.TensorflowTensorShapeProto] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('tensor_shape'), 'exclude': lambda f: f is None }})
    r"""Dimensions of a tensor."""  
    uint32_val: Optional[list[int]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('uint32_val'), 'exclude': lambda f: f is None }})  
    uint64_val: Optional[list[str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('uint64_val'), 'exclude': lambda f: f is None }})  
    variant_val: Optional[list[shared_tensorflowvarianttensordataproto.TensorflowVariantTensorDataProto]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('variant_val'), 'exclude': lambda f: f is None }})  
    version_number: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('version_number'), 'exclude': lambda f: f is None }})
    r"""Version number.
    
    In version 0, if the \"repeated xxx\" representations contain only one
    element, that element is repeated to fill the shape.  This makes it easy
    to represent a constant Tensor with a single value.
    """  
    