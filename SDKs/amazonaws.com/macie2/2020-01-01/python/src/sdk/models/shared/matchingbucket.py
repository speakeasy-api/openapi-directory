"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
import dateutil.parser
from ..shared import bucketmetadataerrorcode_enum as shared_bucketmetadataerrorcode_enum
from ..shared import jobdetails as shared_jobdetails
from ..shared import objectcountbyencryptiontype as shared_objectcountbyencryptiontype
from ..shared import objectlevelstatistics as shared_objectlevelstatistics
from dataclasses_json import Undefined, dataclass_json
from datetime import datetime
from marshmallow import fields
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class MatchingBucket:
    r"""<p>Provides statistical data and other information about an S3 bucket that Amazon Macie monitors and analyzes for your account. By default, object count and storage size values include data for object parts that are the result of incomplete multipart uploads. For more information, see <a href=\\"https://docs.aws.amazon.com/macie/latest/user/monitoring-s3-how-it-works.html\\">How Macie monitors Amazon S3 data security</a> in the <i>Amazon Macie User Guide</i>.</p> <p>If an error occurs when Macie attempts to retrieve and process information about the bucket or the bucket's objects, the value for most of these properties is null. Key exceptions are accountId and bucketName. To identify the cause of the error, refer to the errorCode and errorMessage values.</p>"""
    
    account_id: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('accountId'), 'exclude': lambda f: f is None }})  
    bucket_name: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('bucketName'), 'exclude': lambda f: f is None }})  
    classifiable_object_count: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('classifiableObjectCount'), 'exclude': lambda f: f is None }})  
    classifiable_size_in_bytes: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('classifiableSizeInBytes'), 'exclude': lambda f: f is None }})  
    error_code: Optional[shared_bucketmetadataerrorcode_enum.BucketMetadataErrorCodeEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('errorCode'), 'exclude': lambda f: f is None }})  
    error_message: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('errorMessage'), 'exclude': lambda f: f is None }})  
    job_details: Optional[shared_jobdetails.JobDetails] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('jobDetails'), 'exclude': lambda f: f is None }})  
    last_automated_discovery_time: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('lastAutomatedDiscoveryTime'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})  
    object_count: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('objectCount'), 'exclude': lambda f: f is None }})  
    object_count_by_encryption_type: Optional[shared_objectcountbyencryptiontype.ObjectCountByEncryptionType] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('objectCountByEncryptionType'), 'exclude': lambda f: f is None }})  
    sensitivity_score: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('sensitivityScore'), 'exclude': lambda f: f is None }})  
    size_in_bytes: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('sizeInBytes'), 'exclude': lambda f: f is None }})  
    size_in_bytes_compressed: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('sizeInBytesCompressed'), 'exclude': lambda f: f is None }})  
    unclassifiable_object_count: Optional[shared_objectlevelstatistics.ObjectLevelStatistics] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('unclassifiableObjectCount'), 'exclude': lambda f: f is None }})  
    unclassifiable_object_size_in_bytes: Optional[shared_objectlevelstatistics.ObjectLevelStatistics] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('unclassifiableObjectSizeInBytes'), 'exclude': lambda f: f is None }})  
    