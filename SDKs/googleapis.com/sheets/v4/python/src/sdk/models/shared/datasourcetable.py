"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import dataexecutionstatus as shared_dataexecutionstatus
from ..shared import datasourcecolumnreference as shared_datasourcecolumnreference
from ..shared import filterspec as shared_filterspec
from ..shared import sortspec as shared_sortspec
from dataclasses_json import Undefined, dataclass_json
from enum import Enum
from sdk import utils
from typing import Optional

class DataSourceTableColumnSelectionTypeEnum(str, Enum):
    r"""The type to select columns for the data source table. Defaults to SELECTED."""
    DATA_SOURCE_TABLE_COLUMN_SELECTION_TYPE_UNSPECIFIED = 'DATA_SOURCE_TABLE_COLUMN_SELECTION_TYPE_UNSPECIFIED'
    SELECTED = 'SELECTED'
    SYNC_ALL = 'SYNC_ALL'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class DataSourceTable:
    r"""A data source table, which allows the user to import a static table of data from the DataSource into Sheets. This is also known as \\"Extract\\" in the Sheets editor."""
    
    columns: Optional[list[shared_datasourcecolumnreference.DataSourceColumnReference]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('columns'), 'exclude': lambda f: f is None }})
    r"""Columns selected for the data source table. The column_selection_type must be SELECTED."""  
    column_selection_type: Optional[DataSourceTableColumnSelectionTypeEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('columnSelectionType'), 'exclude': lambda f: f is None }})
    r"""The type to select columns for the data source table. Defaults to SELECTED."""  
    data_execution_status: Optional[shared_dataexecutionstatus.DataExecutionStatus] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('dataExecutionStatus'), 'exclude': lambda f: f is None }})
    r"""The data execution status. A data execution is created to sync a data source object with the latest data from a DataSource. It is usually scheduled to run at background, you can check its state to tell if an execution completes There are several scenarios where a data execution is triggered to run: * Adding a data source creates an associated data source sheet as well as a data execution to sync the data from the data source to the sheet. * Updating a data source creates a data execution to refresh the associated data source sheet similarly. * You can send refresh request to explicitly refresh one or multiple data source objects."""  
    data_source_id: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('dataSourceId'), 'exclude': lambda f: f is None }})
    r"""The ID of the data source the data source table is associated with."""  
    filter_specs: Optional[list[shared_filterspec.FilterSpec]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('filterSpecs'), 'exclude': lambda f: f is None }})
    r"""Filter specifications in the data source table."""  
    row_limit: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('rowLimit'), 'exclude': lambda f: f is None }})
    r"""The limit of rows to return. If not set, a default limit is applied. Please refer to the Sheets editor for the default and max limit."""  
    sort_specs: Optional[list[shared_sortspec.SortSpec]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('sortSpecs'), 'exclude': lambda f: f is None }})
    r"""Sort specifications in the data source table. The result of the data source table is sorted based on the sort specifications in order."""  
    