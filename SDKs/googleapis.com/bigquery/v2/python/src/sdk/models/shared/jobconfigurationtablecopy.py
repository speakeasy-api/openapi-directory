"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import encryptionconfiguration as shared_encryptionconfiguration
from ..shared import tablereference as shared_tablereference
from dataclasses_json import Undefined, dataclass_json
from sdk import utils
from typing import Any, Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class JobConfigurationTableCopy:
    
    create_disposition: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('createDisposition'), 'exclude': lambda f: f is None }})
    r"""[Optional] Specifies whether the job is allowed to create new tables. The following values are supported: CREATE_IF_NEEDED: If the table does not exist, BigQuery creates the table. CREATE_NEVER: The table must already exist. If it does not, a 'notFound' error is returned in the job result. The default value is CREATE_IF_NEEDED. Creation, truncation and append actions occur as one atomic update upon job completion."""  
    destination_encryption_configuration: Optional[shared_encryptionconfiguration.EncryptionConfiguration] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('destinationEncryptionConfiguration'), 'exclude': lambda f: f is None }})  
    destination_expiration_time: Optional[Any] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('destinationExpirationTime'), 'exclude': lambda f: f is None }})
    r"""[Optional] The time when the destination table expires. Expired tables will be deleted and their storage reclaimed."""  
    destination_table: Optional[shared_tablereference.TableReference] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('destinationTable'), 'exclude': lambda f: f is None }})  
    operation_type: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('operationType'), 'exclude': lambda f: f is None }})
    r"""[Optional] Supported operation types in table copy job."""  
    source_table: Optional[shared_tablereference.TableReference] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('sourceTable'), 'exclude': lambda f: f is None }})  
    source_tables: Optional[list[shared_tablereference.TableReference]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('sourceTables'), 'exclude': lambda f: f is None }})
    r"""[Pick one] Source tables to copy."""  
    write_disposition: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('writeDisposition'), 'exclude': lambda f: f is None }})
    r"""[Optional] Specifies the action that occurs if the destination table already exists. The following values are supported: WRITE_TRUNCATE: If the table already exists, BigQuery overwrites the table data. WRITE_APPEND: If the table already exists, BigQuery appends the data to the table. WRITE_EMPTY: If the table already exists and contains data, a 'duplicate' error is returned in the job result. The default value is WRITE_EMPTY. Each action is atomic and only occurs if BigQuery is able to complete the job successfully. Creation, truncation and append actions occur as one atomic update upon job completion."""  
    