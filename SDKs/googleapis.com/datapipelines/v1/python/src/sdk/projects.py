"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

import requests as requests_http
from . import utils
from sdk.models import operations, shared
from typing import Any, Optional

class Projects:
    _client: requests_http.Session
    _security_client: requests_http.Session
    _server_url: str
    _language: str
    _sdk_version: str
    _gen_version: str

    def __init__(self, client: requests_http.Session, security_client: requests_http.Session, server_url: str, language: str, sdk_version: str, gen_version: str) -> None:
        self._client = client
        self._security_client = security_client
        self._server_url = server_url
        self._language = language
        self._sdk_version = sdk_version
        self._gen_version = gen_version
        
    def datapipelines_projects_locations_pipelines_create(self, request: operations.DatapipelinesProjectsLocationsPipelinesCreateRequest, security: operations.DatapipelinesProjectsLocationsPipelinesCreateSecurity) -> operations.DatapipelinesProjectsLocationsPipelinesCreateResponse:
        r"""Creates a pipeline. For a batch pipeline, you can pass scheduler information. Data Pipelines uses the scheduler information to create an internal scheduler that runs jobs periodically. If the internal scheduler is not configured, you can use RunPipeline to run jobs."""
        base_url = self._server_url
        
        url = utils.generate_url(operations.DatapipelinesProjectsLocationsPipelinesCreateRequest, base_url, '/v1/{parent}/pipelines', request)
        
        headers = {}
        req_content_type, data, form = utils.serialize_request_body(request, "google_cloud_datapipelines_v1_pipeline_input", 'json')
        if req_content_type not in ('multipart/form-data', 'multipart/mixed'):
            headers['content-type'] = req_content_type
        query_params = utils.get_query_params(operations.DatapipelinesProjectsLocationsPipelinesCreateRequest, request)
        
        client = utils.configure_security_client(self._client, security)
        
        http_res = client.request('POST', url, params=query_params, data=data, files=form, headers=headers)
        content_type = http_res.headers.get('Content-Type')

        res = operations.DatapipelinesProjectsLocationsPipelinesCreateResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.GoogleCloudDatapipelinesV1Pipeline])
                res.google_cloud_datapipelines_v1_pipeline = out

        return res

    def datapipelines_projects_locations_pipelines_delete(self, request: operations.DatapipelinesProjectsLocationsPipelinesDeleteRequest, security: operations.DatapipelinesProjectsLocationsPipelinesDeleteSecurity) -> operations.DatapipelinesProjectsLocationsPipelinesDeleteResponse:
        r"""Deletes a pipeline. If a scheduler job is attached to the pipeline, it will be deleted."""
        base_url = self._server_url
        
        url = utils.generate_url(operations.DatapipelinesProjectsLocationsPipelinesDeleteRequest, base_url, '/v1/{name}', request)
        
        query_params = utils.get_query_params(operations.DatapipelinesProjectsLocationsPipelinesDeleteRequest, request)
        
        client = utils.configure_security_client(self._client, security)
        
        http_res = client.request('DELETE', url, params=query_params)
        content_type = http_res.headers.get('Content-Type')

        res = operations.DatapipelinesProjectsLocationsPipelinesDeleteResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[dict[str, Any]])
                res.google_protobuf_empty = out

        return res

    def datapipelines_projects_locations_pipelines_get(self, request: operations.DatapipelinesProjectsLocationsPipelinesGetRequest, security: operations.DatapipelinesProjectsLocationsPipelinesGetSecurity) -> operations.DatapipelinesProjectsLocationsPipelinesGetResponse:
        r"""Looks up a single pipeline. Returns a \\"NOT_FOUND\\" error if no such pipeline exists. Returns a \\"FORBIDDEN\\" error if the caller doesn't have permission to access it."""
        base_url = self._server_url
        
        url = utils.generate_url(operations.DatapipelinesProjectsLocationsPipelinesGetRequest, base_url, '/v1/{name}', request)
        
        query_params = utils.get_query_params(operations.DatapipelinesProjectsLocationsPipelinesGetRequest, request)
        
        client = utils.configure_security_client(self._client, security)
        
        http_res = client.request('GET', url, params=query_params)
        content_type = http_res.headers.get('Content-Type')

        res = operations.DatapipelinesProjectsLocationsPipelinesGetResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.GoogleCloudDatapipelinesV1Pipeline])
                res.google_cloud_datapipelines_v1_pipeline = out

        return res

    def datapipelines_projects_locations_pipelines_jobs_list(self, request: operations.DatapipelinesProjectsLocationsPipelinesJobsListRequest, security: operations.DatapipelinesProjectsLocationsPipelinesJobsListSecurity) -> operations.DatapipelinesProjectsLocationsPipelinesJobsListResponse:
        r"""Lists jobs for a given pipeline. Throws a \\"FORBIDDEN\\" error if the caller doesn't have permission to access it."""
        base_url = self._server_url
        
        url = utils.generate_url(operations.DatapipelinesProjectsLocationsPipelinesJobsListRequest, base_url, '/v1/{parent}/jobs', request)
        
        query_params = utils.get_query_params(operations.DatapipelinesProjectsLocationsPipelinesJobsListRequest, request)
        
        client = utils.configure_security_client(self._client, security)
        
        http_res = client.request('GET', url, params=query_params)
        content_type = http_res.headers.get('Content-Type')

        res = operations.DatapipelinesProjectsLocationsPipelinesJobsListResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.GoogleCloudDatapipelinesV1ListJobsResponse])
                res.google_cloud_datapipelines_v1_list_jobs_response = out

        return res

    def datapipelines_projects_locations_pipelines_list(self, request: operations.DatapipelinesProjectsLocationsPipelinesListRequest, security: operations.DatapipelinesProjectsLocationsPipelinesListSecurity) -> operations.DatapipelinesProjectsLocationsPipelinesListResponse:
        r"""Lists pipelines. Returns a \\"FORBIDDEN\\" error if the caller doesn't have permission to access it."""
        base_url = self._server_url
        
        url = utils.generate_url(operations.DatapipelinesProjectsLocationsPipelinesListRequest, base_url, '/v1/{parent}/pipelines', request)
        
        query_params = utils.get_query_params(operations.DatapipelinesProjectsLocationsPipelinesListRequest, request)
        
        client = utils.configure_security_client(self._client, security)
        
        http_res = client.request('GET', url, params=query_params)
        content_type = http_res.headers.get('Content-Type')

        res = operations.DatapipelinesProjectsLocationsPipelinesListResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.GoogleCloudDatapipelinesV1ListPipelinesResponse])
                res.google_cloud_datapipelines_v1_list_pipelines_response = out

        return res

    def datapipelines_projects_locations_pipelines_patch(self, request: operations.DatapipelinesProjectsLocationsPipelinesPatchRequest, security: operations.DatapipelinesProjectsLocationsPipelinesPatchSecurity) -> operations.DatapipelinesProjectsLocationsPipelinesPatchResponse:
        r"""Updates a pipeline. If successful, the updated Pipeline is returned. Returns `NOT_FOUND` if the pipeline doesn't exist. If UpdatePipeline does not return successfully, you can retry the UpdatePipeline request until you receive a successful response."""
        base_url = self._server_url
        
        url = utils.generate_url(operations.DatapipelinesProjectsLocationsPipelinesPatchRequest, base_url, '/v1/{name}', request)
        
        headers = {}
        req_content_type, data, form = utils.serialize_request_body(request, "google_cloud_datapipelines_v1_pipeline_input", 'json')
        if req_content_type not in ('multipart/form-data', 'multipart/mixed'):
            headers['content-type'] = req_content_type
        query_params = utils.get_query_params(operations.DatapipelinesProjectsLocationsPipelinesPatchRequest, request)
        
        client = utils.configure_security_client(self._client, security)
        
        http_res = client.request('PATCH', url, params=query_params, data=data, files=form, headers=headers)
        content_type = http_res.headers.get('Content-Type')

        res = operations.DatapipelinesProjectsLocationsPipelinesPatchResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.GoogleCloudDatapipelinesV1Pipeline])
                res.google_cloud_datapipelines_v1_pipeline = out

        return res

    def datapipelines_projects_locations_pipelines_run(self, request: operations.DatapipelinesProjectsLocationsPipelinesRunRequest, security: operations.DatapipelinesProjectsLocationsPipelinesRunSecurity) -> operations.DatapipelinesProjectsLocationsPipelinesRunResponse:
        r"""Creates a job for the specified pipeline directly. You can use this method when the internal scheduler is not configured and you want to trigger the job directly or through an external system. Returns a \\"NOT_FOUND\\" error if the pipeline doesn't exist. Returns a \\"FORBIDDEN\\" error if the user doesn't have permission to access the pipeline or run jobs for the pipeline."""
        base_url = self._server_url
        
        url = utils.generate_url(operations.DatapipelinesProjectsLocationsPipelinesRunRequest, base_url, '/v1/{name}:run', request)
        
        headers = {}
        req_content_type, data, form = utils.serialize_request_body(request, "request_body", 'json')
        if req_content_type not in ('multipart/form-data', 'multipart/mixed'):
            headers['content-type'] = req_content_type
        query_params = utils.get_query_params(operations.DatapipelinesProjectsLocationsPipelinesRunRequest, request)
        
        client = utils.configure_security_client(self._client, security)
        
        http_res = client.request('POST', url, params=query_params, data=data, files=form, headers=headers)
        content_type = http_res.headers.get('Content-Type')

        res = operations.DatapipelinesProjectsLocationsPipelinesRunResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.GoogleCloudDatapipelinesV1RunPipelineResponse])
                res.google_cloud_datapipelines_v1_run_pipeline_response = out

        return res

    def datapipelines_projects_locations_pipelines_stop(self, request: operations.DatapipelinesProjectsLocationsPipelinesStopRequest, security: operations.DatapipelinesProjectsLocationsPipelinesStopSecurity) -> operations.DatapipelinesProjectsLocationsPipelinesStopResponse:
        r"""Freezes pipeline execution permanently. If there's a corresponding scheduler entry, it's deleted, and the pipeline state is changed to \\"ARCHIVED\\". However, pipeline metadata is retained."""
        base_url = self._server_url
        
        url = utils.generate_url(operations.DatapipelinesProjectsLocationsPipelinesStopRequest, base_url, '/v1/{name}:stop', request)
        
        headers = {}
        req_content_type, data, form = utils.serialize_request_body(request, "request_body", 'json')
        if req_content_type not in ('multipart/form-data', 'multipart/mixed'):
            headers['content-type'] = req_content_type
        query_params = utils.get_query_params(operations.DatapipelinesProjectsLocationsPipelinesStopRequest, request)
        
        client = utils.configure_security_client(self._client, security)
        
        http_res = client.request('POST', url, params=query_params, data=data, files=form, headers=headers)
        content_type = http_res.headers.get('Content-Type')

        res = operations.DatapipelinesProjectsLocationsPipelinesStopResponse(status_code=http_res.status_code, content_type=content_type, raw_response=http_res)
        
        if http_res.status_code == 200:
            if utils.match_content_type(content_type, 'application/json'):
                out = utils.unmarshal_json(http_res.text, Optional[shared.GoogleCloudDatapipelinesV1Pipeline])
                res.google_cloud_datapipelines_v1_pipeline = out

        return res

    