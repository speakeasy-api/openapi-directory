/*
 * Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.
 */

import { SpeakeasyBase, SpeakeasyMetadata } from "../../../internal/utils";
import { AgeRange } from "./agerange";
import { Beard } from "./beard";
import { BoundingBox } from "./boundingbox";
import { Emotion } from "./emotion";
import { Eyeglasses } from "./eyeglasses";
import { EyeOpen } from "./eyeopen";
import { Gender } from "./gender";
import { ImageQuality } from "./imagequality";
import { Landmark } from "./landmark";
import { MouthOpen } from "./mouthopen";
import { Mustache } from "./mustache";
import { Pose } from "./pose";
import { Smile } from "./smile";
import { Sunglasses } from "./sunglasses";
import { Expose, Type } from "class-transformer";

/**
 * <p>Structure containing attributes of the face that the algorithm detected.</p> <p>A <code>FaceDetail</code> object contains either the default facial attributes or all facial attributes. The default attributes are <code>BoundingBox</code>, <code>Confidence</code>, <code>Landmarks</code>, <code>Pose</code>, and <code>Quality</code>.</p> <p> <a>GetFaceDetection</a> is the only Amazon Rekognition Video stored video operation that can return a <code>FaceDetail</code> object with all attributes. To specify which attributes to return, use the <code>FaceAttributes</code> input parameter for <a>StartFaceDetection</a>. The following Amazon Rekognition Video operations return only the default attributes. The corresponding Start operations don't have a <code>FaceAttributes</code> input parameter:</p> <ul> <li> <p>GetCelebrityRecognition</p> </li> <li> <p>GetPersonTracking</p> </li> <li> <p>GetFaceSearch</p> </li> </ul> <p>The Amazon Rekognition Image <a>DetectFaces</a> and <a>IndexFaces</a> operations can return all facial attributes. To specify which attributes to return, use the <code>Attributes</code> input parameter for <code>DetectFaces</code>. For <code>IndexFaces</code>, use the <code>DetectAttributes</code> input parameter.</p>
 */
export class FaceDetail extends SpeakeasyBase {
  @SpeakeasyMetadata()
  @Expose({ name: "AgeRange" })
  @Type(() => AgeRange)
  ageRange?: AgeRange;

  @SpeakeasyMetadata()
  @Expose({ name: "Beard" })
  @Type(() => Beard)
  beard?: Beard;

  @SpeakeasyMetadata()
  @Expose({ name: "BoundingBox" })
  @Type(() => BoundingBox)
  boundingBox?: BoundingBox;

  @SpeakeasyMetadata()
  @Expose({ name: "Confidence" })
  confidence?: number;

  @SpeakeasyMetadata({ elemType: Emotion })
  @Expose({ name: "Emotions" })
  @Type(() => Emotion)
  emotions?: Emotion[];

  @SpeakeasyMetadata()
  @Expose({ name: "Eyeglasses" })
  @Type(() => Eyeglasses)
  eyeglasses?: Eyeglasses;

  @SpeakeasyMetadata()
  @Expose({ name: "EyesOpen" })
  @Type(() => EyeOpen)
  eyesOpen?: EyeOpen;

  @SpeakeasyMetadata()
  @Expose({ name: "Gender" })
  @Type(() => Gender)
  gender?: Gender;

  @SpeakeasyMetadata({ elemType: Landmark })
  @Expose({ name: "Landmarks" })
  @Type(() => Landmark)
  landmarks?: Landmark[];

  @SpeakeasyMetadata()
  @Expose({ name: "MouthOpen" })
  @Type(() => MouthOpen)
  mouthOpen?: MouthOpen;

  @SpeakeasyMetadata()
  @Expose({ name: "Mustache" })
  @Type(() => Mustache)
  mustache?: Mustache;

  @SpeakeasyMetadata()
  @Expose({ name: "Pose" })
  @Type(() => Pose)
  pose?: Pose;

  @SpeakeasyMetadata()
  @Expose({ name: "Quality" })
  @Type(() => ImageQuality)
  quality?: ImageQuality;

  @SpeakeasyMetadata()
  @Expose({ name: "Smile" })
  @Type(() => Smile)
  smile?: Smile;

  @SpeakeasyMetadata()
  @Expose({ name: "Sunglasses" })
  @Type(() => Sunglasses)
  sunglasses?: Sunglasses;
}
