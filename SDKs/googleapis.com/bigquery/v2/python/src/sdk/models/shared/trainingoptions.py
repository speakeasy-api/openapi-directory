"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
from ..shared import arimaorder as shared_arimaorder
from dataclasses_json import Undefined, dataclass_json
from enum import Enum
from sdk import utils
from typing import Optional

class TrainingOptionsBoosterTypeEnum(str, Enum):
    r"""Booster type for boosted tree models."""
    BOOSTER_TYPE_UNSPECIFIED = 'BOOSTER_TYPE_UNSPECIFIED'
    GBTREE = 'GBTREE'
    DART = 'DART'

class TrainingOptionsColorSpaceEnum(str, Enum):
    r"""Enums for color space, used for processing images in Object Table. See more details at https://www.tensorflow.org/io/tutorials/colorspace."""
    COLOR_SPACE_UNSPECIFIED = 'COLOR_SPACE_UNSPECIFIED'
    RGB = 'RGB'
    HSV = 'HSV'
    YIQ = 'YIQ'
    YUV = 'YUV'
    GRAYSCALE = 'GRAYSCALE'

class TrainingOptionsDartNormalizeTypeEnum(str, Enum):
    r"""Type of normalization algorithm for boosted tree models using dart booster."""
    DART_NORMALIZE_TYPE_UNSPECIFIED = 'DART_NORMALIZE_TYPE_UNSPECIFIED'
    TREE = 'TREE'
    FOREST = 'FOREST'

class TrainingOptionsDataFrequencyEnum(str, Enum):
    r"""The data frequency of a time series."""
    DATA_FREQUENCY_UNSPECIFIED = 'DATA_FREQUENCY_UNSPECIFIED'
    AUTO_FREQUENCY = 'AUTO_FREQUENCY'
    YEARLY = 'YEARLY'
    QUARTERLY = 'QUARTERLY'
    MONTHLY = 'MONTHLY'
    WEEKLY = 'WEEKLY'
    DAILY = 'DAILY'
    HOURLY = 'HOURLY'
    PER_MINUTE = 'PER_MINUTE'

class TrainingOptionsDataSplitMethodEnum(str, Enum):
    r"""The data split type for training and evaluation, e.g. RANDOM."""
    DATA_SPLIT_METHOD_UNSPECIFIED = 'DATA_SPLIT_METHOD_UNSPECIFIED'
    RANDOM = 'RANDOM'
    CUSTOM = 'CUSTOM'
    SEQUENTIAL = 'SEQUENTIAL'
    NO_SPLIT = 'NO_SPLIT'
    AUTO_SPLIT = 'AUTO_SPLIT'

class TrainingOptionsDistanceTypeEnum(str, Enum):
    r"""Distance type for clustering models."""
    DISTANCE_TYPE_UNSPECIFIED = 'DISTANCE_TYPE_UNSPECIFIED'
    EUCLIDEAN = 'EUCLIDEAN'
    COSINE = 'COSINE'

class TrainingOptionsFeedbackTypeEnum(str, Enum):
    r"""Feedback type that specifies which algorithm to run for matrix factorization."""
    FEEDBACK_TYPE_UNSPECIFIED = 'FEEDBACK_TYPE_UNSPECIFIED'
    IMPLICIT = 'IMPLICIT'
    EXPLICIT = 'EXPLICIT'

class TrainingOptionsHolidayRegionEnum(str, Enum):
    r"""The geographical region based on which the holidays are considered in time series modeling. If a valid value is specified, then holiday effects modeling is enabled."""
    HOLIDAY_REGION_UNSPECIFIED = 'HOLIDAY_REGION_UNSPECIFIED'
    GLOBAL = 'GLOBAL'
    NA = 'NA'
    JAPAC = 'JAPAC'
    EMEA = 'EMEA'
    LAC = 'LAC'
    AE = 'AE'
    AR = 'AR'
    AT = 'AT'
    AU = 'AU'
    BE = 'BE'
    BR = 'BR'
    CA = 'CA'
    CH = 'CH'
    CL = 'CL'
    CN = 'CN'
    CO = 'CO'
    CS = 'CS'
    CZ = 'CZ'
    DE = 'DE'
    DK = 'DK'
    DZ = 'DZ'
    EC = 'EC'
    EE = 'EE'
    EG = 'EG'
    ES = 'ES'
    FI = 'FI'
    FR = 'FR'
    GB = 'GB'
    GR = 'GR'
    HK = 'HK'
    HU = 'HU'
    ID = 'ID'
    IE = 'IE'
    IL = 'IL'
    IN = 'IN'
    IR = 'IR'
    IT = 'IT'
    JP = 'JP'
    KR = 'KR'
    LV = 'LV'
    MA = 'MA'
    MX = 'MX'
    MY = 'MY'
    NG = 'NG'
    NL = 'NL'
    NO = 'NO'
    NZ = 'NZ'
    PE = 'PE'
    PH = 'PH'
    PK = 'PK'
    PL = 'PL'
    PT = 'PT'
    RO = 'RO'
    RS = 'RS'
    RU = 'RU'
    SA = 'SA'
    SE = 'SE'
    SG = 'SG'
    SI = 'SI'
    SK = 'SK'
    TH = 'TH'
    TR = 'TR'
    TW = 'TW'
    UA = 'UA'
    US = 'US'
    VE = 'VE'
    VN = 'VN'
    ZA = 'ZA'

class TrainingOptionsHparamTuningObjectivesEnum(str, Enum):
    HPARAM_TUNING_OBJECTIVE_UNSPECIFIED = 'HPARAM_TUNING_OBJECTIVE_UNSPECIFIED'
    MEAN_ABSOLUTE_ERROR = 'MEAN_ABSOLUTE_ERROR'
    MEAN_SQUARED_ERROR = 'MEAN_SQUARED_ERROR'
    MEAN_SQUARED_LOG_ERROR = 'MEAN_SQUARED_LOG_ERROR'
    MEDIAN_ABSOLUTE_ERROR = 'MEDIAN_ABSOLUTE_ERROR'
    R_SQUARED = 'R_SQUARED'
    EXPLAINED_VARIANCE = 'EXPLAINED_VARIANCE'
    PRECISION = 'PRECISION'
    RECALL = 'RECALL'
    ACCURACY = 'ACCURACY'
    F1_SCORE = 'F1_SCORE'
    LOG_LOSS = 'LOG_LOSS'
    ROC_AUC = 'ROC_AUC'
    DAVIES_BOULDIN_INDEX = 'DAVIES_BOULDIN_INDEX'
    MEAN_AVERAGE_PRECISION = 'MEAN_AVERAGE_PRECISION'
    NORMALIZED_DISCOUNTED_CUMULATIVE_GAIN = 'NORMALIZED_DISCOUNTED_CUMULATIVE_GAIN'
    AVERAGE_RANK = 'AVERAGE_RANK'

class TrainingOptionsKmeansInitializationMethodEnum(str, Enum):
    r"""The method used to initialize the centroids for kmeans algorithm."""
    KMEANS_INITIALIZATION_METHOD_UNSPECIFIED = 'KMEANS_INITIALIZATION_METHOD_UNSPECIFIED'
    RANDOM = 'RANDOM'
    CUSTOM = 'CUSTOM'
    KMEANS_PLUS_PLUS = 'KMEANS_PLUS_PLUS'

class TrainingOptionsLearnRateStrategyEnum(str, Enum):
    r"""The strategy to determine learn rate for the current iteration."""
    LEARN_RATE_STRATEGY_UNSPECIFIED = 'LEARN_RATE_STRATEGY_UNSPECIFIED'
    LINE_SEARCH = 'LINE_SEARCH'
    CONSTANT = 'CONSTANT'

class TrainingOptionsLossTypeEnum(str, Enum):
    r"""Type of loss function used during training run."""
    LOSS_TYPE_UNSPECIFIED = 'LOSS_TYPE_UNSPECIFIED'
    MEAN_SQUARED_LOSS = 'MEAN_SQUARED_LOSS'
    MEAN_LOG_LOSS = 'MEAN_LOG_LOSS'

class TrainingOptionsOptimizationStrategyEnum(str, Enum):
    r"""Optimization strategy for training linear regression models."""
    OPTIMIZATION_STRATEGY_UNSPECIFIED = 'OPTIMIZATION_STRATEGY_UNSPECIFIED'
    BATCH_GRADIENT_DESCENT = 'BATCH_GRADIENT_DESCENT'
    NORMAL_EQUATION = 'NORMAL_EQUATION'

class TrainingOptionsTreeMethodEnum(str, Enum):
    r"""Tree construction algorithm for boosted tree models."""
    TREE_METHOD_UNSPECIFIED = 'TREE_METHOD_UNSPECIFIED'
    AUTO = 'AUTO'
    EXACT = 'EXACT'
    APPROX = 'APPROX'
    HIST = 'HIST'


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class TrainingOptions:
    r"""Options used in model training."""
    
    adjust_step_changes: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('adjustStepChanges'), 'exclude': lambda f: f is None }})
    r"""If true, detect step changes and make data adjustment in the input time series."""  
    auto_arima: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('autoArima'), 'exclude': lambda f: f is None }})
    r"""Whether to enable auto ARIMA or not."""  
    auto_arima_max_order: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('autoArimaMaxOrder'), 'exclude': lambda f: f is None }})
    r"""The max value of non-seasonal p and q."""  
    batch_size: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('batchSize'), 'exclude': lambda f: f is None }})
    r"""Batch size for dnn models."""  
    booster_type: Optional[TrainingOptionsBoosterTypeEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('boosterType'), 'exclude': lambda f: f is None }})
    r"""Booster type for boosted tree models."""  
    calculate_p_values: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('calculatePValues'), 'exclude': lambda f: f is None }})
    r"""Whether or not p-value test should be computed for this model. Only available for linear and logistic regression models."""  
    clean_spikes_and_dips: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('cleanSpikesAndDips'), 'exclude': lambda f: f is None }})
    r"""If true, clean spikes and dips in the input time series."""  
    color_space: Optional[TrainingOptionsColorSpaceEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('colorSpace'), 'exclude': lambda f: f is None }})
    r"""Enums for color space, used for processing images in Object Table. See more details at https://www.tensorflow.org/io/tutorials/colorspace."""  
    colsample_bylevel: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('colsampleBylevel'), 'exclude': lambda f: f is None }})
    r"""Subsample ratio of columns for each level for boosted tree models."""  
    colsample_bynode: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('colsampleBynode'), 'exclude': lambda f: f is None }})
    r"""Subsample ratio of columns for each node(split) for boosted tree models."""  
    colsample_bytree: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('colsampleBytree'), 'exclude': lambda f: f is None }})
    r"""Subsample ratio of columns when constructing each tree for boosted tree models."""  
    dart_normalize_type: Optional[TrainingOptionsDartNormalizeTypeEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('dartNormalizeType'), 'exclude': lambda f: f is None }})
    r"""Type of normalization algorithm for boosted tree models using dart booster."""  
    data_frequency: Optional[TrainingOptionsDataFrequencyEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('dataFrequency'), 'exclude': lambda f: f is None }})
    r"""The data frequency of a time series."""  
    data_split_column: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('dataSplitColumn'), 'exclude': lambda f: f is None }})
    r"""The column to split data with. This column won't be used as a feature. 1. When data_split_method is CUSTOM, the corresponding column should be boolean. The rows with true value tag are eval data, and the false are training data. 2. When data_split_method is SEQ, the first DATA_SPLIT_EVAL_FRACTION rows (from smallest to largest) in the corresponding column are used as training data, and the rest are eval data. It respects the order in Orderable data types: https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#data-type-properties"""  
    data_split_eval_fraction: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('dataSplitEvalFraction'), 'exclude': lambda f: f is None }})
    r"""The fraction of evaluation data over the whole input data. The rest of data will be used as training data. The format should be double. Accurate to two decimal places. Default value is 0.2."""  
    data_split_method: Optional[TrainingOptionsDataSplitMethodEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('dataSplitMethod'), 'exclude': lambda f: f is None }})
    r"""The data split type for training and evaluation, e.g. RANDOM."""  
    decompose_time_series: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('decomposeTimeSeries'), 'exclude': lambda f: f is None }})
    r"""If true, perform decompose time series and save the results."""  
    distance_type: Optional[TrainingOptionsDistanceTypeEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('distanceType'), 'exclude': lambda f: f is None }})
    r"""Distance type for clustering models."""  
    dropout: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('dropout'), 'exclude': lambda f: f is None }})
    r"""Dropout probability for dnn models."""  
    early_stop: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('earlyStop'), 'exclude': lambda f: f is None }})
    r"""Whether to stop early when the loss doesn't improve significantly any more (compared to min_relative_progress). Used only for iterative training algorithms."""  
    enable_global_explain: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('enableGlobalExplain'), 'exclude': lambda f: f is None }})
    r"""If true, enable global explanation during training."""  
    feedback_type: Optional[TrainingOptionsFeedbackTypeEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('feedbackType'), 'exclude': lambda f: f is None }})
    r"""Feedback type that specifies which algorithm to run for matrix factorization."""  
    hidden_units: Optional[list[str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('hiddenUnits'), 'exclude': lambda f: f is None }})
    r"""Hidden units for dnn models."""  
    holiday_region: Optional[TrainingOptionsHolidayRegionEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('holidayRegion'), 'exclude': lambda f: f is None }})
    r"""The geographical region based on which the holidays are considered in time series modeling. If a valid value is specified, then holiday effects modeling is enabled."""  
    horizon: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('horizon'), 'exclude': lambda f: f is None }})
    r"""The number of periods ahead that need to be forecasted."""  
    hparam_tuning_objectives: Optional[list[TrainingOptionsHparamTuningObjectivesEnum]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('hparamTuningObjectives'), 'exclude': lambda f: f is None }})
    r"""The target evaluation metrics to optimize the hyperparameters for."""  
    include_drift: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('includeDrift'), 'exclude': lambda f: f is None }})
    r"""Include drift when fitting an ARIMA model."""  
    initial_learn_rate: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('initialLearnRate'), 'exclude': lambda f: f is None }})
    r"""Specifies the initial learning rate for the line search learn rate strategy."""  
    input_label_columns: Optional[list[str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('inputLabelColumns'), 'exclude': lambda f: f is None }})
    r"""Name of input label columns in training data."""  
    integrated_gradients_num_steps: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('integratedGradientsNumSteps'), 'exclude': lambda f: f is None }})
    r"""Number of integral steps for the integrated gradients explain method."""  
    item_column: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('itemColumn'), 'exclude': lambda f: f is None }})
    r"""Item column specified for matrix factorization models."""  
    kmeans_initialization_column: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('kmeansInitializationColumn'), 'exclude': lambda f: f is None }})
    r"""The column used to provide the initial centroids for kmeans algorithm when kmeans_initialization_method is CUSTOM."""  
    kmeans_initialization_method: Optional[TrainingOptionsKmeansInitializationMethodEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('kmeansInitializationMethod'), 'exclude': lambda f: f is None }})
    r"""The method used to initialize the centroids for kmeans algorithm."""  
    l1_regularization: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('l1Regularization'), 'exclude': lambda f: f is None }})
    r"""L1 regularization coefficient."""  
    l2_regularization: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('l2Regularization'), 'exclude': lambda f: f is None }})
    r"""L2 regularization coefficient."""  
    label_class_weights: Optional[dict[str, float]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('labelClassWeights'), 'exclude': lambda f: f is None }})
    r"""Weights associated with each label class, for rebalancing the training data. Only applicable for classification models."""  
    learn_rate: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('learnRate'), 'exclude': lambda f: f is None }})
    r"""Learning rate in training. Used only for iterative training algorithms."""  
    learn_rate_strategy: Optional[TrainingOptionsLearnRateStrategyEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('learnRateStrategy'), 'exclude': lambda f: f is None }})
    r"""The strategy to determine learn rate for the current iteration."""  
    loss_type: Optional[TrainingOptionsLossTypeEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('lossType'), 'exclude': lambda f: f is None }})
    r"""Type of loss function used during training run."""  
    max_iterations: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('maxIterations'), 'exclude': lambda f: f is None }})
    r"""The maximum number of iterations in training. Used only for iterative training algorithms."""  
    max_parallel_trials: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('maxParallelTrials'), 'exclude': lambda f: f is None }})
    r"""Maximum number of trials to run in parallel."""  
    max_time_series_length: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('maxTimeSeriesLength'), 'exclude': lambda f: f is None }})
    r"""Get truncated length by last n points in time series. Use separately from time_series_length_fraction and min_time_series_length."""  
    max_tree_depth: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('maxTreeDepth'), 'exclude': lambda f: f is None }})
    r"""Maximum depth of a tree for boosted tree models."""  
    min_relative_progress: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('minRelativeProgress'), 'exclude': lambda f: f is None }})
    r"""When early_stop is true, stops training when accuracy improvement is less than 'min_relative_progress'. Used only for iterative training algorithms."""  
    min_split_loss: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('minSplitLoss'), 'exclude': lambda f: f is None }})
    r"""Minimum split loss for boosted tree models."""  
    min_time_series_length: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('minTimeSeriesLength'), 'exclude': lambda f: f is None }})
    r"""Set fast trend ARIMA_PLUS model minimum training length. Use in pair with time_series_length_fraction."""  
    min_tree_child_weight: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('minTreeChildWeight'), 'exclude': lambda f: f is None }})
    r"""Minimum sum of instance weight needed in a child for boosted tree models."""  
    model_uri: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('modelUri'), 'exclude': lambda f: f is None }})
    r"""Google Cloud Storage URI from which the model was imported. Only applicable for imported models."""  
    non_seasonal_order: Optional[shared_arimaorder.ArimaOrder] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('nonSeasonalOrder'), 'exclude': lambda f: f is None }})
    r"""Arima order, can be used for both non-seasonal and seasonal parts."""  
    num_clusters: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('numClusters'), 'exclude': lambda f: f is None }})
    r"""Number of clusters for clustering models."""  
    num_factors: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('numFactors'), 'exclude': lambda f: f is None }})
    r"""Num factors specified for matrix factorization models."""  
    num_parallel_tree: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('numParallelTree'), 'exclude': lambda f: f is None }})
    r"""Number of parallel trees constructed during each iteration for boosted tree models."""  
    num_trials: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('numTrials'), 'exclude': lambda f: f is None }})
    r"""Number of trials to run this hyperparameter tuning job."""  
    optimization_strategy: Optional[TrainingOptionsOptimizationStrategyEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('optimizationStrategy'), 'exclude': lambda f: f is None }})
    r"""Optimization strategy for training linear regression models."""  
    preserve_input_structs: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('preserveInputStructs'), 'exclude': lambda f: f is None }})
    r"""Whether to preserve the input structs in output feature names. Suppose there is a struct A with field b. When false (default), the output feature name is A_b. When true, the output feature name is A.b."""  
    sampled_shapley_num_paths: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('sampledShapleyNumPaths'), 'exclude': lambda f: f is None }})
    r"""Number of paths for the sampled Shapley explain method."""  
    subsample: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('subsample'), 'exclude': lambda f: f is None }})
    r"""Subsample fraction of the training data to grow tree to prevent overfitting for boosted tree models."""  
    time_series_data_column: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('timeSeriesDataColumn'), 'exclude': lambda f: f is None }})
    r"""Column to be designated as time series data for ARIMA model."""  
    time_series_id_column: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('timeSeriesIdColumn'), 'exclude': lambda f: f is None }})
    r"""The time series id column that was used during ARIMA model training."""  
    time_series_id_columns: Optional[list[str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('timeSeriesIdColumns'), 'exclude': lambda f: f is None }})
    r"""The time series id columns that were used during ARIMA model training."""  
    time_series_length_fraction: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('timeSeriesLengthFraction'), 'exclude': lambda f: f is None }})
    r"""Get truncated length by fraction in time series."""  
    time_series_timestamp_column: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('timeSeriesTimestampColumn'), 'exclude': lambda f: f is None }})
    r"""Column to be designated as time series timestamp for ARIMA model."""  
    tree_method: Optional[TrainingOptionsTreeMethodEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('treeMethod'), 'exclude': lambda f: f is None }})
    r"""Tree construction algorithm for boosted tree models."""  
    trend_smoothing_window_size: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('trendSmoothingWindowSize'), 'exclude': lambda f: f is None }})
    r"""The smoothing window size for the trend component of the time series."""  
    user_column: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('userColumn'), 'exclude': lambda f: f is None }})
    r"""User column specified for matrix factorization models."""  
    wals_alpha: Optional[float] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('walsAlpha'), 'exclude': lambda f: f is None }})
    r"""Hyperparameter for matrix factoration when implicit feedback type is specified."""  
    warm_start: Optional[bool] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('warmStart'), 'exclude': lambda f: f is None }})
    r"""Whether to train a model from the last checkpoint."""  
    