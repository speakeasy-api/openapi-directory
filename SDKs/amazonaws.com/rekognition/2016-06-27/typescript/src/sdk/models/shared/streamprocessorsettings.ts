/*
 * Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.
 */

import { SpeakeasyBase, SpeakeasyMetadata } from "../../../internal/utils";
import { ConnectedHomeSettings } from "./connectedhomesettings";
import { FaceSearchSettings } from "./facesearchsettings";
import { Expose, Type } from "class-transformer";

/**
 * Input parameters used in a streaming video analyzed by a Amazon Rekognition stream processor. You can use <code>FaceSearch</code> to recognize faces in a streaming video, or you can use <code>ConnectedHome</code> to detect labels.
 */
export class StreamProcessorSettings extends SpeakeasyBase {
  /**
   *  Label detection settings to use on a streaming video. Defining the settings is required in the request parameter for <a>CreateStreamProcessor</a>. Including this setting in the <code>CreateStreamProcessor</code> request enables you to use the stream processor for label detection. You can then select what you want the stream processor to detect, such as people or pets. When the stream processor has started, one notification is sent for each object class specified. For example, if packages and pets are selected, one SNS notification is published the first time a package is detected and one SNS notification is published the first time a pet is detected, as well as an end-of-session summary.
   */
  @SpeakeasyMetadata()
  @Expose({ name: "ConnectedHome" })
  @Type(() => ConnectedHomeSettings)
  connectedHome?: ConnectedHomeSettings;

  @SpeakeasyMetadata()
  @Expose({ name: "FaceSearch" })
  @Type(() => FaceSearchSettings)
  faceSearch?: FaceSearchSettings;
}
