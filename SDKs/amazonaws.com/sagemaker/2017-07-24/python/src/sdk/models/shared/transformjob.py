"""Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT."""

from __future__ import annotations
import dataclasses
import dateutil.parser
from ..shared import batchstrategy_enum as shared_batchstrategy_enum
from ..shared import dataprocessing as shared_dataprocessing
from ..shared import experimentconfig as shared_experimentconfig
from ..shared import modelclientconfig as shared_modelclientconfig
from ..shared import tag as shared_tag
from ..shared import transforminput as shared_transforminput
from ..shared import transformjobstatus_enum as shared_transformjobstatus_enum
from ..shared import transformoutput as shared_transformoutput
from ..shared import transformresources as shared_transformresources
from dataclasses_json import Undefined, dataclass_json
from datetime import datetime
from marshmallow import fields
from sdk import utils
from typing import Optional


@dataclass_json(undefined=Undefined.EXCLUDE)
@dataclasses.dataclass
class TransformJob:
    r"""A batch transform job. For information about SageMaker batch transform, see <a href=\\"https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html\\">Use Batch Transform</a>."""
    
    auto_ml_job_arn: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('AutoMLJobArn'), 'exclude': lambda f: f is None }})  
    batch_strategy: Optional[shared_batchstrategy_enum.BatchStrategyEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('BatchStrategy'), 'exclude': lambda f: f is None }})  
    creation_time: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('CreationTime'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})  
    data_processing: Optional[shared_dataprocessing.DataProcessing] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('DataProcessing'), 'exclude': lambda f: f is None }})
    r"""The data structure used to specify the data to be used for inference in a batch transform job and to associate the data that is relevant to the prediction results in the output. The input filter provided allows you to exclude input data that is not needed for inference in a batch transform job. The output filter provided allows you to include input data relevant to interpreting the predictions in the output from the job. For more information, see <a href=\\"https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform-data-processing.html\\">Associate Prediction Results with their Corresponding Input Records</a>."""  
    environment: Optional[dict[str, str]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('Environment'), 'exclude': lambda f: f is None }})  
    experiment_config: Optional[shared_experimentconfig.ExperimentConfig] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ExperimentConfig'), 'exclude': lambda f: f is None }})
    r"""<p>Associates a SageMaker job as a trial component with an experiment and trial. Specified when you call the following APIs:</p> <ul> <li> <p> <a>CreateProcessingJob</a> </p> </li> <li> <p> <a>CreateTrainingJob</a> </p> </li> <li> <p> <a>CreateTransformJob</a> </p> </li> </ul>"""  
    failure_reason: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('FailureReason'), 'exclude': lambda f: f is None }})  
    labeling_job_arn: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('LabelingJobArn'), 'exclude': lambda f: f is None }})  
    max_concurrent_transforms: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('MaxConcurrentTransforms'), 'exclude': lambda f: f is None }})  
    max_payload_in_mb: Optional[int] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('MaxPayloadInMB'), 'exclude': lambda f: f is None }})  
    model_client_config: Optional[shared_modelclientconfig.ModelClientConfig] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ModelClientConfig'), 'exclude': lambda f: f is None }})
    r"""Configures the timeout and maximum number of retries for processing a transform job invocation."""  
    model_name: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('ModelName'), 'exclude': lambda f: f is None }})  
    tags: Optional[list[shared_tag.Tag]] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('Tags'), 'exclude': lambda f: f is None }})  
    transform_end_time: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('TransformEndTime'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})  
    transform_input: Optional[shared_transforminput.TransformInput] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('TransformInput'), 'exclude': lambda f: f is None }})
    r"""Describes the input source of a transform job and the way the transform job consumes it."""  
    transform_job_arn: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('TransformJobArn'), 'exclude': lambda f: f is None }})  
    transform_job_name: Optional[str] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('TransformJobName'), 'exclude': lambda f: f is None }})  
    transform_job_status: Optional[shared_transformjobstatus_enum.TransformJobStatusEnum] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('TransformJobStatus'), 'exclude': lambda f: f is None }})  
    transform_output: Optional[shared_transformoutput.TransformOutput] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('TransformOutput'), 'exclude': lambda f: f is None }})
    r"""Describes the results of a transform job."""  
    transform_resources: Optional[shared_transformresources.TransformResources] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('TransformResources'), 'exclude': lambda f: f is None }})
    r"""Describes the resources, including ML instance types and ML instance count, to use for transform job."""  
    transform_start_time: Optional[datetime] = dataclasses.field(default=None, metadata={'dataclasses_json': { 'letter_case': utils.get_field_name('TransformStartTime'), 'encoder': utils.datetimeisoformat(True), 'decoder': dateutil.parser.isoparse, 'mm_field': fields.DateTime(format='iso'), 'exclude': lambda f: f is None }})  
    